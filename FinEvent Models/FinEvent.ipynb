{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b839b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsettings:\\n    matplotlib==3.5.1\\n    networkx==2.6.3\\n    numpy==1.22.0\\n    pandas==1.3.5\\n    scikit-learn==1.0.1\\n    scipy==1.7.3\\n    torch==1.10.0\\n    torch-cluster==1.5.9\\n    torch-geometric==2.0.2\\n    torch-scatter==2.0.9\\n    torch-sparse==0.6.12\\n    torch-spline-conv==1.2.1\\n    tqdm==4.62.3\\n    dgl==0.4.3\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2022.10.6ÔºåÂ§çÁé∞FinEvent Model\n",
    "paper: from Reinforced, Incremental and Cross-lingual Event Detection From Social Messages\n",
    "github address: https://github.com/RingBDStack/FinEvent\n",
    "'''\n",
    "'''\n",
    "settings:\n",
    "    matplotlib==3.5.1\n",
    "    networkx==2.6.3\n",
    "    numpy==1.22.0\n",
    "    pandas==1.3.5\n",
    "    scikit-learn==1.0.1\n",
    "    scipy==1.7.3\n",
    "    torch==1.10.0\n",
    "    torch-cluster==1.5.9\n",
    "    torch-geometric==2.0.2\n",
    "    torch-scatter==2.0.9\n",
    "    torch-sparse==0.6.12\n",
    "    torch-spline-conv==1.2.1\n",
    "    tqdm==4.62.3\n",
    "    dgl==0.4.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cec4d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "project_path = os.path.abspath(os.path.dirname(os.getcwd()))  # # Ëé∑Âèñ‰∏äÁ∫ßË∑ØÂæÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b6e88b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27c2f2",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40212d7c",
   "metadata": {},
   "source": [
    "## step 1: load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "101b1f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis file generates the initial message features (please see Figure 1(b) and Section 3.2 of the paper for more details).\\nTo leverage the semantics in the data, we generate document feature for each message,\\nwhich is calculated as an average of the pre-trained word embeddings of all the words in the message\\nWe use the word embeddings pre-trained by en_core_web_lg, while other options, \\nsuch as word embeddings pre-trained by BERT, are also applicable.\\nTo leverage the temporal information in the data, we generate temporal feature for each message,\\nwhich is calculated by encoding the times-tamps: we convert each timestamp to OLE date, \\nwhose fractional and integral components form a 2-d vector.\\nThe initial feature of a message is the concatenation of its document feature and temporal feature.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the initial features for the messages\n",
    "'''\n",
    "This file generates the initial message features (please see Figure 1(b) and Section 3.2 of the paper for more details).\n",
    "To leverage the semantics in the data, we generate document feature for each message,\n",
    "which is calculated as an average of the pre-trained word embeddings of all the words in the message\n",
    "We use the word embeddings pre-trained by en_core_web_lg, while other options, \n",
    "such as word embeddings pre-trained by BERT, are also applicable.\n",
    "To leverage the temporal information in the data, we generate temporal feature for each message,\n",
    "which is calculated by encoding the times-tamps: we convert each timestamp to OLE date, \n",
    "whose fractional and integral components form a 2-d vector.\n",
    "The initial feature of a message is the concatenation of its document feature and temporal feature.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8000e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg  # spacyÊèê‰æõÁöÑÈ¢ÑËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÔºåÂ∞ÜÊñáÊú¨Ê†áËÆ∞ÂåñÂ∑≤ÁîüÊàêdocÂØπË±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a03ac16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7794e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = project_path + '/data/FinEvent_datasets/raw dataset/'\n",
    "save_path = project_path + '/result/FinEvent result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6adc640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\GNN_Event_Detection_models/data/FinEvent_datasets/raw dataset/\n",
      "D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/\n"
     ]
    }
   ],
   "source": [
    "print(load_path)\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79eebee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data.\n",
      "Data converted to dataframe.\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "p_part1 = load_path + '68841_tweets_multiclasses_filtered_0722_part1.npy'\n",
    "p_part2 = load_path + '68841_tweets_multiclasses_filtered_0722_part2.npy'\n",
    "# Python ‰∏≠ÁöÑ pickle Áî®‰∫éÂú®‰øùÂ≠òÂà∞Á£ÅÁõòÊñá‰ª∂Êàñ‰ªéÁ£ÅÁõòÊñá‰ª∂ËØªÂèñ‰πãÂâçÔºåÂØπÂØπË±°ËøõË°åÂ∫èÂàóÂåñÂíåÂèçÂ∫èÂàóÂåñ\n",
    "df_np_part1 = np.load(p_part1, allow_pickle=True)  # ndarray, (35000, 16) allow_pickle, Allow loading pickled object arrays stored in npy files\n",
    "df_np_part2 = np.load(p_part2, allow_pickle=True)  # ndarray, (33841, 16)\n",
    "df = np.concatenate((df_np_part1, df_np_part2),axis=0) # ÊåâË°åÊãºÊé•; ndarray, (68841, 16)\n",
    "print('loaded data.')\n",
    "df = pd.DataFrame(data=df, columns=['event_id','tweet_id','text','user_id','created_at','user_loc','place_type',\n",
    "                                      'place_full_name','place_country_code','hashtags','user_mentions','image_urls',\n",
    "                                      'entities','words','filtered_words','sampled_words'])\n",
    "print('Data converted to dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93787f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort date by time\n",
    "df = df.sort_values(by='created_at').reset_index(drop=True)\n",
    "\n",
    "df['date'] = [d.date() for d in df['created_at']]\n",
    "# Âõ†‰∏∫graphÂ§™Â§ßÔºåÁàÜ‰∫ÜÂÜÖÂ≠òÔºåÊâÄ‰ª•Âèñ4Â§©ÁöÑtwitter dataÂÅödemoÔºåÂêéÈù¢Áî®nci server\n",
    "init_day = df.loc[0, 'date']\n",
    "df_4days = df[(df['date']>= init_day) & (df['date']<= init_day + datetime.timedelta(days=3))].reset_index()  # Ôºà11971Ôºå 18Ôºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f05e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11971, 18)\n",
      "89\n",
      "10905\n"
     ]
    }
   ],
   "source": [
    "print(df_4days.shape)\n",
    "print(df_4days.event_id.nunique())\n",
    "print(df_4days.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e7cbfc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>entities</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>sampled_words</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>255819992157786112</td>\n",
       "      <td>HipHop awards bout to be live!!</td>\n",
       "      <td>250870763</td>\n",
       "      <td>2012-10-10 00:00:13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[award, live, bout, hiphop]</td>\n",
       "      <td>[award, live, bout, hiphop]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "      <td>255820118095978496</td>\n",
       "      <td>HIPHOP AWARDS TIME!</td>\n",
       "      <td>28026779</td>\n",
       "      <td>2012-10-10 00:00:43</td>\n",
       "      <td>SoundCloud/RaRaSupaStar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[HIPHOP, AWARDS, time]</td>\n",
       "      <td>[hiphop, awards, time]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>255820147489636353</td>\n",
       "      <td>Bet hiphop awards</td>\n",
       "      <td>566825483</td>\n",
       "      <td>2012-10-10 00:00:50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Bet, GPE)]</td>\n",
       "      <td>[award, bet, hiphop]</td>\n",
       "      <td>[award, bet, hiphop]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>394</td>\n",
       "      <td>255820164023595008</td>\n",
       "      <td>BET HipHop awards is on!!!</td>\n",
       "      <td>197834311</td>\n",
       "      <td>2012-10-10 00:00:54</td>\n",
       "      <td>Saint Lucia ‚òÄÔ∏èüå¥üá±üá®</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[HipHop, BET, award]</td>\n",
       "      <td>[hiphop, bet, award]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>394</td>\n",
       "      <td>255820180884701184</td>\n",
       "      <td>Watchin Da BET Hiphop Awards</td>\n",
       "      <td>439490861</td>\n",
       "      <td>2012-10-10 00:00:58</td>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hiphop, Watchin, Awards, Da, BET]</td>\n",
       "      <td>[hiphop, watchin, awards, da, bet]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index event_id            tweet_id                             text  \\\n",
       "0      0      394  255819992157786112  HipHop awards bout to be live!!   \n",
       "1      1      394  255820118095978496              HIPHOP AWARDS TIME!   \n",
       "2      2      394  255820147489636353                Bet hiphop awards   \n",
       "3      3      394  255820164023595008       BET HipHop awards is on!!!   \n",
       "4      4      394  255820180884701184     Watchin Da BET Hiphop Awards   \n",
       "\n",
       "     user_id          created_at                 user_loc place_type  \\\n",
       "0  250870763 2012-10-10 00:00:13                                       \n",
       "1   28026779 2012-10-10 00:00:43  SoundCloud/RaRaSupaStar              \n",
       "2  566825483 2012-10-10 00:00:50                                       \n",
       "3  197834311 2012-10-10 00:00:54        Saint Lucia ‚òÄÔ∏èüå¥üá±üá®              \n",
       "4  439490861 2012-10-10 00:00:58            Michigan, USA              \n",
       "\n",
       "  place_full_name place_country_code hashtags user_mentions image_urls  \\\n",
       "0                                          []            []         []   \n",
       "1                                          []            []         []   \n",
       "2                                          []            []         []   \n",
       "3                                          []            []         []   \n",
       "4                                          []            []         []   \n",
       "\n",
       "       entities                               words  \\\n",
       "0            []         [award, live, bout, hiphop]   \n",
       "1            []              [HIPHOP, AWARDS, time]   \n",
       "2  [(Bet, GPE)]                [award, bet, hiphop]   \n",
       "3            []                [HipHop, BET, award]   \n",
       "4            []  [Hiphop, Watchin, Awards, Da, BET]   \n",
       "\n",
       "                       filtered_words sampled_words        date  \n",
       "0         [award, live, bout, hiphop]            []  2012-10-10  \n",
       "1              [hiphop, awards, time]            []  2012-10-10  \n",
       "2                [award, bet, hiphop]            []  2012-10-10  \n",
       "3                [hiphop, bet, award]            []  2012-10-10  \n",
       "4  [hiphop, watchin, awards, da, bet]            []  2012-10-10  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4days.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5819f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple orange'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['apple','orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f9468b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0110998 , -1.1696801 , -1.836925  ,  3.62435   , -0.38999498,\n",
       "       -4.14575   , -2.7551    ,  4.432     , -3.6439    ,  1.56774   ,\n",
       "        5.17155   , -2.1609    , -3.04495   ,  1.418985  ,  0.385655  ,\n",
       "       -1.35931   ,  0.6796    , -1.65807   ,  2.4508    , -3.6395502 ,\n",
       "       -1.361265  ,  3.3911    , -2.3505502 , -2.64425   , -1.4074149 ,\n",
       "       -2.9309    , -2.8713    ,  0.45424998,  0.494435  ,  1.3266001 ,\n",
       "       -1.1863351 , -0.805145  , -1.74835   , -2.51085   ,  1.7619    ,\n",
       "       -1.5734999 ,  2.69375   ,  2.93885   ,  2.39905   , -1.84745   ,\n",
       "        1.80935   ,  0.02054995, -0.08278999,  1.805665  ,  1.297785  ,\n",
       "        4.19905   ,  1.0158501 , -0.53619003,  0.36874998,  0.88796496,\n",
       "        1.3213301 ,  0.95765996,  0.53971505, -1.07363   , -2.0834498 ,\n",
       "        1.16805   ,  0.513239  ,  1.7584    ,  2.365     ,  0.45940998,\n",
       "        1.114205  ,  2.19576   , -0.65239   , -0.8655875 , -1.4635    ,\n",
       "       -1.12686   , -0.654125  , -5.0572    ,  1.706955  ,  0.7140905 ,\n",
       "        0.18399003,  1.214605  , -0.55937   , -0.03608499,  1.72783   ,\n",
       "        1.5109501 , -3.2747498 , -2.4126    ,  2.8046498 , -0.69925   ,\n",
       "        0.08292501,  1.4252    , -1.40222   , -0.161405  ,  1.9577    ,\n",
       "        2.92315   ,  3.92705   ,  2.37919   , -3.4520998 ,  1.21405   ,\n",
       "       -0.72452   ,  2.89295   ,  3.7947998 , -2.253     ,  0.39468   ,\n",
       "       -0.74540997,  4.6324997 , -3.07635   , -0.97773004, -2.5821    ,\n",
       "       -1.0297451 , -1.5957999 ,  3.0032    , -3.8875499 ,  0.983415  ,\n",
       "        4.0956    , -2.3144    ,  1.100465  , -2.66325   ,  0.755045  ,\n",
       "       -0.945415  , -1.6505    ,  1.4755    , -0.088165  , -0.92186004,\n",
       "        0.83010995,  2.4917998 , -4.87885   ,  0.368615  , -2.51565   ,\n",
       "       -1.196195  ,  0.345475  , -3.4098    ,  0.98731005, -1.8608999 ,\n",
       "       -1.7764101 , -0.792635  , -4.7539    ,  5.4427004 , -1.714245  ,\n",
       "       -2.767     ,  2.11765   ,  2.9257002 , -0.9242001 ,  1.317845  ,\n",
       "        0.6444555 , -2.2532501 , -3.84      ,  1.241415  , -1.1724349 ,\n",
       "       -0.8314105 ,  1.2356    , -0.5785445 , -0.124265  , -1.6407499 ,\n",
       "       -2.37737   ,  0.23260003, -0.49001503,  0.91589   , -0.337985  ,\n",
       "       -1.2370551 ,  3.1024    , -1.47059   ,  0.3114925 , -1.09988   ,\n",
       "        2.1496    ,  4.91815   ,  1.0532701 , -0.13689995, -1.3814449 ,\n",
       "       -0.83028495, -2.74435   ,  0.575295  , -0.07805   ,  0.349875  ,\n",
       "       -0.70633   , -1.8892545 ,  3.17795   , -0.34900498, -0.97155   ,\n",
       "       -2.4014502 , -0.308645  ,  1.5397    ,  2.39539   , -3.4741    ,\n",
       "        0.742038  ,  0.36888   , -1.424945  ,  2.16179   , -1.774455  ,\n",
       "       -3.6488001 ,  1.2621999 , -3.5694    , -0.45152003, -1.023715  ,\n",
       "       -3.16575   ,  1.47891   , -0.366     ,  2.3464    , -1.9343    ,\n",
       "       -0.066103  , -1.373405  , -0.16980004,  0.34351003,  0.45071998,\n",
       "       -0.4579    , -3.0018501 ,  2.3866    ,  2.66955   ,  0.66981   ,\n",
       "        0.246895  , -1.1091499 ,  1.7041001 , -2.36015   , -0.343955  ,\n",
       "        2.025655  , -1.59215   ,  1.84497   ,  1.85645   ,  0.01043001,\n",
       "        2.21935   , -0.76988   , -0.7163283 ,  3.43885   ,  2.9425    ,\n",
       "       -1.69526   ,  4.17135   , -0.775475  , -1.14217   ,  0.86177504,\n",
       "        2.9757    , -0.511155  , -2.33185   ,  1.3068    ,  2.4316    ,\n",
       "       -2.1859    , -1.322525  ,  3.00665   ,  2.26965   ,  3.3906999 ,\n",
       "        0.04269999, -1.9162251 ,  0.93624   ,  0.253317  , -4.1192503 ,\n",
       "        3.60775   , -2.28615   ,  4.163     , -0.11091504, -1.35395   ,\n",
       "        0.15709999, -0.45066503, -0.54945   ,  4.1812    , -0.940665  ,\n",
       "        2.8109999 , -1.23508   ,  0.18045002, -0.961135  , -4.4705    ,\n",
       "       -1.360445  ,  2.95925   , -1.6655099 , -1.434475  , -0.84205997,\n",
       "       -2.84745   , -0.60528   ,  5.0722504 , -2.9237    ,  0.1990025 ,\n",
       "       -2.34521   ,  2.42525   , -2.0008001 ,  2.011255  , -0.51383   ,\n",
       "        1.3772999 , -1.6201451 , -0.06687498, -4.8313    ,  0.36800003,\n",
       "        4.0598    ,  2.41745   ,  2.2585    , -0.456413  ,  0.44165003,\n",
       "       -3.7245002 ,  1.2915499 ,  0.19281998,  1.6036    , -0.82016   ,\n",
       "        1.929595  ,  0.439953  ,  2.9638002 , -0.4986975 ,  1.60965   ,\n",
       "       -1.9485999 , -1.72883   , -0.09885001, -2.4696    ,  2.35475   ,\n",
       "        0.04689997, -0.47034252,  1.7963    , -2.9976501 , -2.3356    ,\n",
       "        0.14620501,  3.59445   , -0.83054507,  0.06312001, -0.912935  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = en_core_web_lg.load()\n",
    "nlp(' '.join(['apple','orange'])).vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8a51db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['award', 'live', 'bout', 'hiphop']),\n",
       "       list(['hiphop', 'awards', 'time']),\n",
       "       list(['award', 'bet', 'hiphop']), ...,\n",
       "       list(['election', 'watch', 'presentation']),\n",
       "       list(['anything', 'damascus', 'rock', 'kill', 'brother', 'co', 'parliament', 'get', 'man', 'anything', 'speaker', 'bombing']),\n",
       "       list(['not', 'cuz', 'afford', 'idk', 'country', 'can', 'whole', 'win', 'leave', 'take', 'fam', 'romney', 'could'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filtered_words.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9074551",
   "metadata": {},
   "source": [
    "### document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0abd390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the embeddings of all the documents in the dataframe\n",
    "# the embeddings of each document is an average of the pre-trained embeddings of all the words in it\n",
    "def documents_to_features(df):\n",
    "    nlp = en_core_web_lg.load()\n",
    "    '''\n",
    "    filtered_words: ['literature', 'nobel', 'prize', 'announce']\n",
    "    features, ndarray, (68841,)„ÄÇÂÖ∂‰∏≠ÔºåÂçï‰∏™ÂÖÉÁ¥†ÊòØ300Áª¥ÁöÑÂêëÈáè\n",
    "    [-7.0156753e-01 -2.4638350e+00  9.9222124e-01 -1.6435424e+00,  2.2959824e+00 -9.4725072e-02 ...]\n",
    "    '''\n",
    "    features = df.filtered_words.apply(lambda x: nlp(' '.join(x)).vector).values  # nlpÁîüÊàê300Áª¥ÂêëÈáèÔºõjoinÂáΩÊï∞Â∞ÜÂàóË°®ËøûÊé•ÊàêÂ≠óÁ¨¶‰∏≤\n",
    "    return np.stack(features, axis=0)  # stackÂáΩÊï∞Ê≤øaxisÈÇªÊé•Êï∞ÁªÑÂ∫èÂàó"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb6b8b",
   "metadata": {},
   "source": [
    "### time featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57876cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode one times-tamp\n",
    "# t_str: a string of format '2012-10-11 07:19:34'\n",
    "def extract_time_feature(t_str):\n",
    "    t = datetime.datetime.fromisoformat(str(t_str)) # ÂàÜÂà´ËøîÂõûÂπ¥ÊúàÊó•Êó∂ÂàÜÁßíÂàóË°®\n",
    "    OLE_TIME_ZERO = datetime.datetime(1899, 12, 30)\n",
    "    delta = t - OLE_TIME_ZERO  # datetime.timedelta(days=41193, seconds=26374)\n",
    "    return [(float(delta.days)/10000.), (float(delta.seconds)/86400)] # 86400 seconds in day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed571763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the times-tamps of all the messages in the dateframe\n",
    "def df_to_t_features(df):\n",
    "    t_features = np.asarray([extract_time_feature(t_str) for t_str in df['created_at']])\n",
    "    return t_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccc13c4",
   "metadata": {},
   "source": [
    "### combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4919b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document features generated\n",
      "Time features generated.\n",
      "Concatenated document features and time features.\n",
      "Initial features saved.\n",
      "Initial features loaded.\n",
      "(11971, 302)\n"
     ]
    }
   ],
   "source": [
    "# ÁîüÊàêÊñáÊ°£embedding\n",
    "d_features = documents_to_features(df_4days)\n",
    "print('Document features generated')\n",
    "\n",
    "# ÁîüÊàêÊó∂Èó¥ÁâπÂæÅdaysÂíåseconds\n",
    "t_features = df_to_t_features(df_4days)  # ndarray,(11971, 2)\n",
    "print('Time features generated.')\n",
    "\n",
    "combined_features = np.concatenate((d_features, t_features), axis=1)  # Ôºà11971Ôºå 302Ôºâ\n",
    "print('Concatenated document features and time features.')\n",
    "\n",
    "np.save(save_path + 'combined_features.npy', combined_features)\n",
    "print('Initial features saved.')\n",
    "\n",
    "combined_features = np.load(save_path + 'combined_features.npy')\n",
    "print('Initial features loaded.')\n",
    "print(combined_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d461187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 300)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93f075c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5251225 , -1.2804475 , -1.67361   , ..., -0.10845   ,\n",
       "        -1.2274101 , -1.1007351 ],\n",
       "       [-0.08792333, -0.6259634 , -0.9900033 , ..., -2.038623  ,\n",
       "        -1.2348766 ,  0.46889666],\n",
       "       [-0.7383423 , -2.3103633 , -1.5300802 , ...,  1.8419999 ,\n",
       "         0.25515997,  0.3208867 ],\n",
       "       ...,\n",
       "       [ 0.82871836,  1.8417288 , -1.7910568 , ..., -1.1083716 ,\n",
       "        -0.07446832,  0.07849339],\n",
       "       [-0.37493247, -0.04668879, -1.7778028 , ...,  0.10513129,\n",
       "         0.5673075 ,  0.60081255],\n",
       "       [-3.7216501 , -1.1870999 ,  3.4422648 , ..., -7.9503    ,\n",
       "        -1.2189649 , -4.237005  ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3ae0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5323c7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.11920000e+00, 1.50462963e-04],\n",
       "       [4.11920000e+00, 4.97685185e-04],\n",
       "       [4.11920000e+00, 5.78703704e-04],\n",
       "       ...,\n",
       "       [4.11950000e+00, 9.96261574e-01],\n",
       "       [4.11950000e+00, 9.97430556e-01],\n",
       "       [4.11950000e+00, 9.99652778e-01]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c402ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 302)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73a8ec6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.52512252e+00, -1.28044748e+00, -1.67360997e+00, ...,\n",
       "        -1.10073507e+00,  4.11920000e+00,  1.50462963e-04],\n",
       "       [-8.79233256e-02, -6.25963390e-01, -9.90003288e-01, ...,\n",
       "         4.68896657e-01,  4.11920000e+00,  4.97685185e-04],\n",
       "       [-7.38342285e-01, -2.31036329e+00, -1.53008020e+00, ...,\n",
       "         3.20886701e-01,  4.11920000e+00,  5.78703704e-04],\n",
       "       ...,\n",
       "       [ 8.28718364e-01,  1.84172881e+00, -1.79105675e+00, ...,\n",
       "         7.84933940e-02,  4.11950000e+00,  9.96261574e-01],\n",
       "       [-3.74932468e-01, -4.66887876e-02, -1.77780282e+00, ...,\n",
       "         6.00812554e-01,  4.11950000e+00,  9.97430556e-01],\n",
       "       [-3.72165012e+00, -1.18709993e+00,  3.44226480e+00, ...,\n",
       "        -4.23700523e+00,  4.11950000e+00,  9.99652778e-01]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec3b46",
   "metadata": {},
   "source": [
    "## step 2: construct message graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a07ad4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis file splits the Twitter dataset into 21 message blocks (please see Section 4.3 of the paper for more details), \\nuse the message blocks to construct heterogeneous social graphs (please see Figure 1(a) and Section 3.2 of the paper for more details) \\nand maps them into homogeneous message graphs (Figure 1(c)).\\nNote that:\\n# 1) We adopt the Latest Message Strategy (which is the most efficient and gives the strongest performance. See Section 4.4 of the paper for more details) here, \\n# as a consequence, each message graph only contains the messages of the date and all previous messages are removed from the graph;\\n# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)' inside construct_incremental_dataset_0922().\\n# 2) For test purpose, when calling construct_incremental_dataset_0922(), set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\\n# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct incremental message graphs\n",
    "'''\n",
    "This file splits the Twitter dataset into 21 message blocks (please see Section 4.3 of the paper for more details), \n",
    "use the message blocks to construct heterogeneous social graphs (please see Figure 1(a) and Section 3.2 of the paper for more details) \n",
    "and maps them into homogeneous message graphs (Figure 1(c)).\n",
    "Note that:\n",
    "# 1) We adopt the Latest Message Strategy (which is the most efficient and gives the strongest performance. See Section 4.4 of the paper for more details) here, \n",
    "# as a consequence, each message graph only contains the messages of the date and all previous messages are removed from the graph;\n",
    "# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)' inside construct_incremental_dataset_0922().\n",
    "# 2) For test purpose, when calling construct_incremental_dataset_0922(), set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\n",
    "# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f00bb",
   "metadata": {},
   "source": [
    "### graph examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b2e59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "from time import time\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d845505",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "tweet_list = ['t_123', 't_456', 't_789']\n",
    "G.add_nodes_from(tweet_list)\n",
    "for i in tweet_list:\n",
    "    G.nodes[i]['tweet_id'] = True\n",
    "user_list = ['Sydney', 'Beijing', 'Melbourne']\n",
    "entity_list = ['me', 'bing', 'zhen']\n",
    "G.add_nodes_from(user_list)\n",
    "G.add_nodes_from(entity_list)\n",
    "\n",
    "for i in entity_list:\n",
    "    G.nodes[i]['entity_id'] = True\n",
    "for i in user_list:\n",
    "    G.nodes[i]['user_id'] = True\n",
    "G.add_edges_from([['t_123', 't_456'],['t_123', 't_789'], ['t_123', 'Sydney'], ['t_456', 'Melbourne'], ['t_456', 'Beijing']])\n",
    "G.add_edges_from([['t_123', 'me'], ['t_123', 'bing'], ['t_789', 'zhen']])\n",
    "G.nodes['t_123']['tweet_id'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4acf4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec4da07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_idÂíåuser_idÁªìÊûÑÂÖ≥Á≥ª\n",
    "tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
    "userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys())\n",
    "all_nodes = list(G.nodes)\n",
    "indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
    "indices_userid = [all_nodes.index(x) for x in userid_nodes]\n",
    "A = nx.to_numpy_matrix(G)\n",
    "w_tid_userid = A[np.ix_(indices_tid, indices_userid)]\n",
    "s_w_tid_userid = sparse.csr_matrix(w_tid_userid)\n",
    "s_w_userid_tid = s_w_tid_userid.transpose()\n",
    "homo_s_w_tid_userid = s_w_tid_userid * s_w_userid_tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7482c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 2., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_s_w_tid_userid.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2918594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_idÂíåentity ÁªìÊûÑÂÖ≥Á≥ª\n",
    "tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
    "entity_nodes = list(nx.get_node_attributes(G, 'entity_id').keys())\n",
    "all_nodes = list(G.nodes)\n",
    "indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
    "indices_entityid = [all_nodes.index(x) for x in entity_nodes]\n",
    "A = nx.to_numpy_matrix(G)\n",
    "w_tid_userid = A[np.ix_(indices_tid, indices_entityid)]\n",
    "s_w_tid_userid = sparse.csr_matrix(w_tid_userid)\n",
    "s_w_userid_tid = s_w_tid_userid.transpose()\n",
    "homo_s_w_tid_entityid = s_w_tid_userid * s_w_userid_tid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a1430",
   "metadata": {},
   "source": [
    "### construct heterogeneous graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24f968f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>entities</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>sampled_words</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>256292946331181056</td>\n",
       "      <td>Nobel prize in literature to be announced http...</td>\n",
       "      <td>47667947</td>\n",
       "      <td>2012-10-11 07:19:34</td>\n",
       "      <td>Munich, Germany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[literature, Nobel, prize, announce]</td>\n",
       "      <td>[literature, nobel, prize, announce]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>256333064467279872</td>\n",
       "      <td>‚Äú@marvicleonen: Is it true that UP won UAAP ba...</td>\n",
       "      <td>67518107</td>\n",
       "      <td>2012-10-11 09:58:59</td>\n",
       "      <td>Philippines</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[28775032]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(UP, ORG), (Next year, DATE), (Dean, PERSON)]</td>\n",
       "      <td>[Dean, Sure, year, yan, na, \", basketball, tru...</td>\n",
       "      <td>[dean, sure, year, yan, na, basketball, true, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>256334302034399232</td>\n",
       "      <td>Congrats, Ateneo! Last na yan ha. Season 76 wi...</td>\n",
       "      <td>97449266</td>\n",
       "      <td>2012-10-11 10:03:54</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Ateneo, PERSON), (Season 76, PERSON)]</td>\n",
       "      <td>[yan, ‚ò∫, na, ha, different, last, Ateneo, cong...</td>\n",
       "      <td>[yan, na, ha, different, last, ateneo, congrat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>256335853738160128</td>\n",
       "      <td>\"@SMARTPromos: SMART never wants you to be lef...</td>\n",
       "      <td>405138197</td>\n",
       "      <td>2012-10-11 10:10:04</td>\n",
       "      <td>Lost in Dreamland</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[106915372]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(BIG, ORG), (BIG, ORG)]</td>\n",
       "      <td>[never, s, yan, next, na, thing, Ano, leave, t...</td>\n",
       "      <td>[never, yan, next, na, thing, ano, leave, that...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>256346272506712064</td>\n",
       "      <td>CCTV invite hints at Nobel literature prize fo...</td>\n",
       "      <td>197326414</td>\n",
       "      <td>2012-10-11 10:51:28</td>\n",
       "      <td>Taiwan(R.O.C)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...</td>\n",
       "      <td>[invite, prize, Yan, literature, hint, CCTV, N...</td>\n",
       "      <td>[invite, prize, yan, literature, hint, cctv, n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_id            tweet_id  \\\n",
       "0        0  256292946331181056   \n",
       "1        0  256333064467279872   \n",
       "2        0  256334302034399232   \n",
       "3        0  256335853738160128   \n",
       "4        0  256346272506712064   \n",
       "\n",
       "                                                text    user_id  \\\n",
       "0  Nobel prize in literature to be announced http...   47667947   \n",
       "1  ‚Äú@marvicleonen: Is it true that UP won UAAP ba...   67518107   \n",
       "2  Congrats, Ateneo! Last na yan ha. Season 76 wi...   97449266   \n",
       "3  \"@SMARTPromos: SMART never wants you to be lef...  405138197   \n",
       "4  CCTV invite hints at Nobel literature prize fo...  197326414   \n",
       "\n",
       "           created_at           user_loc place_type place_full_name  \\\n",
       "0 2012-10-11 07:19:34    Munich, Germany                              \n",
       "1 2012-10-11 09:58:59        Philippines                              \n",
       "2 2012-10-11 10:03:54                                                 \n",
       "3 2012-10-11 10:10:04  Lost in Dreamland                              \n",
       "4 2012-10-11 10:51:28      Taiwan(R.O.C)                              \n",
       "\n",
       "  place_country_code hashtags user_mentions image_urls  \\\n",
       "0                          []            []         []   \n",
       "1                          []    [28775032]         []   \n",
       "2                          []            []         []   \n",
       "3                          []   [106915372]         []   \n",
       "4                          []            []         []   \n",
       "\n",
       "                                            entities  \\\n",
       "0                                                 []   \n",
       "1     [(UP, ORG), (Next year, DATE), (Dean, PERSON)]   \n",
       "2            [(Ateneo, PERSON), (Season 76, PERSON)]   \n",
       "3                           [(BIG, ORG), (BIG, ORG)]   \n",
       "4  [(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...   \n",
       "\n",
       "                                               words  \\\n",
       "0               [literature, Nobel, prize, announce]   \n",
       "1  [Dean, Sure, year, yan, na, \", basketball, tru...   \n",
       "2  [yan, ‚ò∫, na, ha, different, last, Ateneo, cong...   \n",
       "3  [never, s, yan, next, na, thing, Ano, leave, t...   \n",
       "4  [invite, prize, Yan, literature, hint, CCTV, N...   \n",
       "\n",
       "                                      filtered_words sampled_words        date  \n",
       "0               [literature, nobel, prize, announce]            []  2012-10-11  \n",
       "1  [dean, sure, year, yan, na, basketball, true, ...            []  2012-10-11  \n",
       "2  [yan, na, ha, different, last, ateneo, congrat...            []  2012-10-11  \n",
       "3  [never, yan, next, na, thing, ano, leave, that...            []  2012-10-11  \n",
       "4  [invite, prize, yan, literature, hint, cctv, n...            []  2012-10-11  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc6c99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a heterogeneous graph using tweet ids, user_ids, entities and rare(sampled) words(4 modalitiesÊ®°ÊÄÅ)\n",
    "# if G is not None then insert new nodes to G\n",
    "# ÂàõÂª∫heterogeneous graph\n",
    "def construct_graph_from_df(df, G=None):  # df: (11971, 18)\n",
    "    if G is None:\n",
    "        G = nx.Graph()  # ÂàõÂª∫Êó†ÂêëÂõæ\n",
    "    for _, row in df.iterrows():  # ËøîÂõûÂèØËø≠‰ª£ÂÖÉÁªÑ(index,row)\n",
    "        # 1st modality: tweet_id\n",
    "        tid = 't_' + str(row['tweet_id'])\n",
    "        G.add_node(tid) # ‰∏ÄÊ¨°Ê∑ªÂä†‰∏Ä‰∏™ËäÇÁÇπÔºåÂ≠óÁ¨¶‰∏≤‰Ωú‰∏∫ËäÇÁÇπid\n",
    "        G.nodes[tid]['tweet_id'] = True  # ËÆæÁΩÆËäÇÁÇπÂ±ûÊÄßÔºõright-hand side value is irrelevant for the lookup\n",
    "        \n",
    "        # 2nd modality: user_id\n",
    "        user_ids = row['user_mentions']  # list.apend(str)\n",
    "        user_ids.append(row['user_id'])\n",
    "        user_ids = ['u_' + str(each) for each in user_ids]\n",
    "        G.add_nodes_from(user_ids) # Ê∑ªÂä†Â§ö‰∏™ËäÇÁÇπ\n",
    "        for each in user_ids:\n",
    "            G.nodes[each]['user_id'] = True \n",
    "        \n",
    "        # 3rd modality: entities\n",
    "        entities = row['entities']  # ÂëΩÂêçÂÆû‰ΩìËØÜÂà´ÁöÑÂÆû‰Ωì\n",
    "#         words = ['e_' + each for each in entities]\n",
    "        G.add_nodes_from(entities)\n",
    "        for each in entities:\n",
    "            G.nodes[each]['entity'] = True\n",
    "        \n",
    "        # 4th modality:sampled_words\n",
    "        words = row['sampled_words']\n",
    "        words = ['w_' + each for each in words]\n",
    "        G.add_nodes_from(words)\n",
    "        for each in words:\n",
    "            G.nodes[each]['word'] = True\n",
    "        \n",
    "        edges =[]\n",
    "        edges += [(tid, each) for each in user_ids]\n",
    "        edges += [(tid, each) for each in entities]\n",
    "        edges += [(tid, each) for each in words]\n",
    "        G.add_edges_from(edges) # ÂêåÊó∂Ê∑ªÂä†Â§öÊù°Ëæπ\n",
    "    return G  # 30427 nodes and 40238 edges,Âõ†‰∏∫‰ª•tweet_id‰∏∫‰∏ªÔºåÂä†‰∏äuser_id, entities, wordsÂÖ±Êúâ30427‰∏™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b15f26",
   "metadata": {},
   "source": [
    "### converting hete-graph to homo-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "767a10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a heterogeneous social graph G to a homogeneous message graph following eq. 1 of the paper, \n",
    "# and store the sparse binary adjacency matrix of the homogeneous message graph.\n",
    "# DGL(Deep Graph Library)ÊûÑÂª∫Êõ¥È´òÊïàÁöÑÂõæÁ•ûÁªèÁΩëÁªú\n",
    "\n",
    "def dgl_hetegraph_to_homograph(G, save_path=None):\n",
    "    '''\n",
    "    doc_embeddings: (11971, 302)\n",
    "    df: (11971, 18)\n",
    "    30427 nodes and 40238 edges,Âõ†‰∏∫‰ª•tweet_id‰∏∫‰∏ªÔºåÂä†‰∏äuser_id, entities, wordsÂÖ±Êúâ30427‰∏™\n",
    "    '''\n",
    "    message = ''\n",
    "    print('Start converting heterogeneous networks graph to homogeneous dgl graph.')\n",
    "    message += 'Start converting heterogeneous networks graph to homogeneous dgl graph.\\n'\n",
    "    all_start = time()\n",
    "    \n",
    "    print('\\tGetting a list of all nodes ...')\n",
    "    message += '\\tGetting a list of all nodes ...\\n'\n",
    "    start = time()\n",
    "    all_nodes = list(G.nodes)  # 30427‰∏™\n",
    "    mins = (time() - start) /60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\tGetting adjacency matrix ...')\n",
    "    message += '\\tGetting adjacency matrix ...\\n'\n",
    "    start = time()\n",
    "    A = nx.to_numpy_matrix(G) # Returns the graph adjacency matrix as a Numpy matrix, Êï¥‰ΩìÂºÇÊûÑÂõæÈÇªÊé•Áü©ÈòµÔºå(30427, 30427)\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # compute commuting matrices\n",
    "    print('\\tGetting lists of nodes of various types ...')\n",
    "    message += '\\tGetting lists of nodes of various types ...\\n'\n",
    "    start = time()\n",
    "    '''\n",
    "    all_nodes: 30427‰∏™\n",
    "    tweet_id: 11971\n",
    "    user_id: 11520\n",
    "    entity_id: 5401\n",
    "    word: 1535\n",
    "    '''\n",
    "    tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys()) # get_node_attributes return node and its attributes;Ëé∑Âæótweet_idÂàóË°®\n",
    "    userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys()) # ÂêåÁêÜÔºåËé∑Âæóuser_idÂàóË°®\n",
    "    word_nodes = list(nx.get_node_attributes(G, 'word').keys())\n",
    "    entity_nodes = list(nx.get_node_attributes(G, 'entity').keys())\n",
    "    del G  # Âà†Èô§original Êó†ÂêëÂõæ\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # Â∞ÜËäÇÁÇπËΩ¨Êç¢Êàêall_nodes‰∏≠ÁöÑÁ¥¢Âºïindex\n",
    "    print('\\tConverting node lists to index lists ...')\n",
    "    message += '\\tConverting node lists to index lists ...\\n'\n",
    "    start = time()\n",
    "    # fineÁªÜÂåñ the index of target nodes in the list of all nodes\n",
    "    indices_tid = [all_nodes.index(x) for x in tid_nodes]        # 11971\n",
    "    indices_userid = [all_nodes.index(x) for x in userid_nodes]  # 11520\n",
    "    indices_word = [all_nodes.index(x) for x in word_nodes]      # 1535\n",
    "    indices_entity = [all_nodes.index(x) for x in entity_nodes]  # 5401\n",
    "    del tid_nodes\n",
    "    del userid_nodes\n",
    "    del word_nodes\n",
    "    del entity_nodes\n",
    "    mins = (time() -start)/60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # ----------------tweet-user-tweet------------------\n",
    "    print('\\tStart constructing tweet-user-tweet commuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-user matrix ...')\n",
    "    message += '\\tStart constructing tweet-user-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-user matrix ...\\n'\n",
    "    start = time()\n",
    "    # Á¨õÂç°Â∞îÁßØÂÆûÈôÖ‰∏äÊòØÁîüÊàê‰∏Ä‰∏™‰∫åÁª¥ÂùêÊ†áÁü©ÈòµÔºåÂÖ∂‰ΩúÁî®ÊòØ‰ªéA‰∏≠ÊäΩÂèñÂá∫xÂíåyËøô‰∏§Á±ªËäÇÁÇπÁöÑ‰∏Ä‰∏™Â≠êÈÇªÊé•Áü©Èòµ\n",
    "    w_tid_userid = A[np.ix_(indices_tid, indices_userid)]  # np.ix_(list1, list2)ÁîüÊàê‰∏Ä‰∏™Á¨õÂç°Â∞îÁßØÁöÑÊò†Â∞ÑÂÖ≥Á≥ªÔºõ\n",
    "    # return a N(indiced_tid)*N(indices_userid) matrix, representing the weight of edges between tid and userid\n",
    "    mins = (time() - start)/60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
    "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_userid = sparse.csr_matrix(w_tid_userid) # ÂÖ∂ÂÆûÂ∞±ÊòØÂ∞ÜÈÇªÊé•Áü©ÈòµËΩ¨Êç¢ÊàêÁ®ÄÁñèÁü©Èòµ„ÄÇmatrix compression\n",
    "    del w_tid_userid\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_userid_tid = s_w_tid_userid.transpose()  # ËΩ¨ÁΩÆ\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-user * user-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-user * user-tweet ...\\n'\n",
    "    start = time()\n",
    "    '''\n",
    "    Â∞Ümeta-path: tweet-user-tweetËΩ¨Êç¢Êàêtweet-tweetÁü©ÈòµÔºåËøôÊ†∑ÊâçËÉΩÂæóÂà∞tweet_id0ÁöÑÁõ¥Êé•ÈÇªÂ±ÖËäÇÁÇπtweet_id1,2,3...Ôºå‰∏çÁî®ÂÜçÈöîÁùÄuserÂÖ≥Á≥ª„ÄÇ\n",
    "    '''\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_userid_tid = s_w_tid_userid * s_w_userid_tid #  Ê†πÊçÆuser_idÁîüÊàêtweet_id homogeneous message graph\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_userid_tid.npz\", s_m_tid_userid_tid)\n",
    "        print('sparse binary userid commuting matrix saved.')\n",
    "        del s_m_tid_userid_tid\n",
    "    del s_w_tid_userid\n",
    "    del s_w_userid_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # ----------tweet-ent-tweet-----------------\n",
    "    print('\\tStart constructing tweet-ent-tweet conmuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-ent matrix ...')\n",
    "    message += '\\tStart constructing tweet-ent-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-ent matrix ...\\n'\n",
    "    start = time()\n",
    "    w_tid_entity = A[np.ix_(indices_tid, indices_entity)]  # ÊäΩÂèñtweet_idÂíåentityÁöÑÈÇªÊé•Áü©Èòµ\n",
    "    mins = (time() - start) / 60\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
    "    message += '\\t\\t\\tConver ting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_entity = sparse.csr_matrix(w_tid_entity)  # ÈÇªÊé•Áü©ÈòµËΩ¨Êç¢ÊàêcsrÁ®ÄÁñèÁü©Èòµ\n",
    "    del w_tid_entity\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed : ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_entity_tid = s_w_tid_entity.transpose()  # ËΩ¨ÁΩÆ\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-ent * ent-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-ent * ent-tweet ...\\n'\n",
    "    start = time()\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_entity_tid = s_w_tid_entity * s_w_entity_tid  # Ê†πÊçÆentityÁîüÊàêtweet_id homogeneous message graph\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_entity_tid.npz\", s_m_tid_entity_tid)\n",
    "        print('Sparse binary entity commuting matrix saved.')\n",
    "        del s_m_tid_entity_tid\n",
    "    del s_w_tid_entity\n",
    "    del s_w_entity_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # --------tweet-word-tweet------------------\n",
    "    print('\\tStart constructing tweet-word-tweet commuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-word matrix ...')\n",
    "    message +='\\tStart constructing tweet-wrod-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-word matrix ...'\n",
    "    start = time()\n",
    "    w_tid_word = A[np.ix_(indices_tid, indices_word)]\n",
    "    del A\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to Sparse matrix ...')\n",
    "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_word = sparse.csr_matrix(w_tid_word)  # tweet_idÂíåwordÁ®ÄÁñèÁü©Èòµ\n",
    "    del w_tid_word\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_word_tid = s_w_tid_word.transpose()\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-word * word-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-word * word-tweet ...\\n'\n",
    "    start = time()\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_word_tid = s_w_tid_word * s_w_word_tid  # Ê†πÊçÆwordÁîüÊàêÁöÑtweet_id homogeneous message graph\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_word_tid.npz\", s_m_tid_word_tid)\n",
    "        print(\"Sparse binary word commuting matrix saved.\")\n",
    "        del s_m_tid_word_tid\n",
    "    del s_w_tid_word\n",
    "    del s_w_word_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # -----------compute tweet-tweet adjacency matrix --------\n",
    "    print('\\tComputing tweet-tweet adjacency matrix ...')\n",
    "    message += '\\tComputing tweet-tweet adjacency matrix ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        s_m_tid_userid_tid = sparse.load_npz(save_path + 's_m_tid_userid_tid.npz')\n",
    "        print(\"Sparse binary userid commuting matrix loaded.\")\n",
    "        s_m_tid_entity_tid = sparse.load_npz(save_path + \"s_m_tid_entity_tid.npz\")\n",
    "        print(\"Sparse binary entity commuting matrix loaded.\")\n",
    "        s_m_tid_word_tid = sparse.load_npz(save_path + \"s_m_tid_word_tid.npz\")\n",
    "        print(\"Sparse binary word commuting matrix loaded.\")\n",
    "    \n",
    "    # ÂêàÂπ∂‰∏â‰∏™user_id, entity, wordÁîüÊàêÁöÑtweet_id homogeneous graph\n",
    "    s_A_tid_tid = s_m_tid_userid_tid + s_m_tid_entity_tid\n",
    "    del s_m_tid_userid_tid\n",
    "    del s_m_tid_entity_tid\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_bool_A_tid_tid = (s_A_tid_tid + s_m_tid_word_tid).astype('bool')  # confirm the connect between tweets\n",
    "    del s_m_tid_word_tid\n",
    "    del s_A_tid_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    all_mins = (time() - all_start) / 60\n",
    "    print('\\tOver all time elapsed: ', all_mins, ' mins\\n')\n",
    "    message += '\\tOver all time elapsed: '\n",
    "    message += str(all_mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_bool_A_tid_tid.npz\", s_bool_A_tid_tid)\n",
    "        print(\"Sparse binary adjacency matrix saved.\")\n",
    "        s_bool_A_tid_tid = sparse.load_npz(save_path + \"s_bool_A_tid_tid.npz\")\n",
    "        print(\"Sparse binary adjacency matrix loaded.\")\n",
    "        \n",
    "    # create correspoinding dgl graph\n",
    "    G = dgl.DGLGraph(s_bool_A_tid_tid)  # ‰º†ÂÖ•Á®ÄÁñèÁü©ÈòµÔºåËΩ¨Êç¢ÊàêÂõæÁ•ûÁªèÁΩëÁªú\n",
    "    print('We have %d nodes.' % G.number_of_nodes())\n",
    "    print('We have %d edges' % G.number_of_edges())\n",
    "    print()\n",
    "    message += 'We have '\n",
    "    message += str(G.number_of_nodes())\n",
    "    message += ' nodes.'\n",
    "    message += 'We have '\n",
    "    message += str(G.number_of_edges())\n",
    "    message += ' edges.\\n'\n",
    "    \n",
    "    return all_mins, message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2ae39",
   "metadata": {},
   "source": [
    "### construct offline dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20157f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c9e8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)'.\n",
    "# 2) For test purpose, set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\n",
    "# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\n",
    "def construct_offline_dataset(df, save_path, features_embeddings, test=True):\n",
    "    '''\n",
    "    df: (11971, 18)\n",
    "    feature_embeddings: (68841, 302)\n",
    "    '''\n",
    "    # If test equals true, construct the initial graph using test_ini_size_tweets\n",
    "    # and increment the graph by test_incr_size tweets each day\n",
    "    test_ini_size = 500\n",
    "    test_incr_size = 100\n",
    "    \n",
    "    # save data splits for training/validate/test mask generation\n",
    "    data_split = []\n",
    "    # save time spent for the heterogeneous -> homogeneous conversion of each graph\n",
    "    all_graph_mins = []\n",
    "    message = ''\n",
    "    # extract distingct dates\n",
    "    distinct_dates = df.date.unique() # ÊâÄÊúâuniqueÁöÑdate\n",
    "    print('Number of distinct dates: ', len(distinct_dates))\n",
    "    message += 'Number of distinct dates: '\n",
    "    message += str(len(distinct_dates))\n",
    "    message += '\\n'\n",
    "    \n",
    "    # split data by dates and construct graphs\n",
    "    # first week -> initial graph (20254 tweets)\n",
    "    print('Start constructing initial graph ...')\n",
    "    message += '\\nStart constructing initial graph ...\\n'\n",
    "#     ini_df = df.loc[df['date'].isin(distinct_dates[:7])]  # find top 7 days\n",
    "#     if test:\n",
    "#         ini_df = ini_df[: test_ini_size]  # top test_ini_size dates\n",
    "    G = construct_graph_from_df(df)  # graph with 30427 nodes and 40238 edges\n",
    "    path = save_path\n",
    "    if path is None:\n",
    "        os.mkdir(path)  # ÂàõÂª∫ÁõÆÂΩï\n",
    "    graph_mins, graph_message = dgl_hetegraph_to_homograph(G, save_path=path)  # convert a heterogeneous social graph to a homogeneous message graph\n",
    "    message += graph_message\n",
    "    print('Initial graph saved')\n",
    "    message += 'Initial graph saved\\n'\n",
    "    # record the totoal number of tweets\n",
    "    all_graph_mins.append(graph_mins)\n",
    "    # extract and save the labels of corresponding tweets\n",
    "    labels = [int(each) for each in df['event_id'].values]  # 11971\n",
    "    np.save(path + 'labels.npy', np.asarray(labels))  # ndarrayÂØπË±°ÔºåÂÆûÈôÖÂè™ÂàõÂª∫‰∏Ä‰∏™ÊåáÈíà\n",
    "    print('Labels saved.')\n",
    "    message += 'Labels saved.\\n'\n",
    "    # extract and save the features of corresponding tweets\n",
    "    indices = df['index'].values.tolist()  # 11971\n",
    "    x = features_embeddings[indices, :]  # (11971, 302), featuresÊòØÊåácombined_features: document_embeddings + time_features\n",
    "    np.save(path + 'features_embeddings.npy', x)\n",
    "    print('Features saved.')\n",
    "    message += 'Features saved. \\n\\n'\n",
    "    \n",
    "#     # subsequent days -> insert tweets day by day(skip the last day because it only contains on tweet)\n",
    "#     for i in range(7, len(distinct_dates) -1):\n",
    "#         print('Start constructing graph', str(i - 6), '...')\n",
    "#         message += '\\nStart constructing graph'\n",
    "#         message += str(i-6)\n",
    "#         message += '...\\n'\n",
    "#         incr_df = df.loc[df['date']==distinct_dates[i]]\n",
    "#         if test:\n",
    "            \n",
    "    return message, all_graph_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "590f8dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 68838, 68839, 68840], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35e483",
   "metadata": {},
   "source": [
    "### run-offline dataset: 4days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7dab4bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51113bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Data converted to dataframe.\n",
      "Number of distinct dates:  4\n",
      "Start constructing initial graph ...\n",
      "Start converting heterogeneous networks graph to homogeneous dgl graph.\n",
      "\tGetting a list of all nodes ...\n",
      "\tDone. Time elapsed:  1.6542275746663413e-05  mins\n",
      "\n",
      "\tGetting adjacency matrix ...\n",
      "\tDone. Time elapsed:  0.07835565805435181  mins\n",
      "\n",
      "\tGetting lists of nodes of various types ...\n",
      "\tDone. Time elapsed:  0.0017293771107991537  mins\n",
      "\n",
      "\tConverting node lists to index lists ...\n",
      "\tDone. Time elapsed:  0.41532753308614095  mins\n",
      "\n",
      "\tStart constructing tweet-user-tweet commuting matrix ...\n",
      "\t\t\tStart constructing tweet-user matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.018926910559336343  mins\n",
      "\n",
      "\t\t\tConverting to sparse matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.021055559317270916  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-user * user-tweet ...\n",
      "\t\t\tDone. Time elapsed:  1.6756852467854817e-05  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "sparse binary userid commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  0.0003055055936177572  mins\n",
      "\n",
      "\tStart constructing tweet-ent-tweet conmuting matrix ...\n",
      "\t\t\tStart constructing tweet-ent matrix ...\n",
      "\t\t\tConverting to sparse matrix ...\n",
      "\t\t\tDone. Time elapsed :  0.0  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-ent * ent-tweet ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "Sparse binary entity commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  1.6585985819498697e-05  mins\n",
      "\n",
      "\tStart constructing tweet-word-tweet commuting matrix ...\n",
      "\t\t\tStart constructing tweet-word matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.020923487345377603  mins\n",
      "\n",
      "\t\t\tConverting to Sparse matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.0028400818506876626  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-word * word-tweet ...\n",
      "\t\t\tDone. Time elapsed:  3.3235549926757814e-05  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "Sparse binary word commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  0.0002493580182393392  mins\n",
      "\n",
      "\tComputing tweet-tweet adjacency matrix ...\n",
      "Sparse binary userid commuting matrix loaded.\n",
      "Sparse binary entity commuting matrix loaded.\n",
      "Sparse binary word commuting matrix loaded.\n",
      "\t\t\tDone. Time elapsed:  0.0009699900945027669  mins\n",
      "\n",
      "\tOver all time elapsed:  0.5608330845832825  mins\n",
      "\n",
      "Sparse binary adjacency matrix saved.\n",
      "Sparse binary adjacency matrix loaded.\n",
      "We have 11971 nodes.\n",
      "We have 167017 edges\n",
      "\n",
      "Initial graph saved\n",
      "Labels saved.\n",
      "Features saved.\n",
      "Time spent on heterogeneous -> homogeneous graph conversions:  [0.5608330845832825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "offline_save_path = project_path + '/result/FinEvent result/offline dataset/'\n",
    "if not os.path.exists(offline_save_path):\n",
    "    os.mkdir(offline_save_path)\n",
    "\n",
    "# load data (68841 tweets, multiclasses filtered)\n",
    "p_part1 = load_path + '68841_tweets_multiclasses_filtered_0722_part1.npy'\n",
    "p_part2 = load_path + '68841_tweets_multiclasses_filtered_0722_part2.npy'\n",
    "# allow_pickle: ÂèØÈÄâÔºåÂ∏ÉÂ∞îÂÄºÔºåÂÖÅËÆ∏‰ΩøÁî® Python pickles ‰øùÂ≠òÂØπË±°Êï∞ÁªÑÔºåPython ‰∏≠ÁöÑ pickle Áî®‰∫éÂú®‰øùÂ≠òÂà∞Á£ÅÁõòÊñá‰ª∂Êàñ‰ªéÁ£ÅÁõòÊñá‰ª∂ËØªÂèñ‰πãÂâçÔºåÂØπÂØπË±°ËøõË°åÂ∫èÂàóÂåñÂíåÂèçÂ∫èÂàóÂåñ„ÄÇ\n",
    "df_np_part1 = np.load(p_part1, allow_pickle=True)  \n",
    "df_np_part2 = np.load(p_part2, allow_pickle=True)\n",
    "df_np = np.concatenate((df_np_part1, df_np_part2), axis=0)  # (68840, 16)\n",
    "print('Data loaded.')\n",
    "df = pd.DataFrame(data=df_np, columns=['event_id', 'tweet_id', 'text', 'user_id', 'created_at', 'user_loc',\n",
    "                                      'place_type', 'place_full_name', 'place_country_code', 'hashtags',\n",
    "                                      'user_mentions', 'image_urls', 'entities', 'words', 'filtered_words', 'sampled_words'])\n",
    "print('Data converted to dataframe.')\n",
    "\n",
    "# sort date by time\n",
    "df = df.sort_values(by='created_at').reset_index(drop=True)\n",
    "# append date\n",
    "df['date'] = [d.date() for d in df['created_at']]\n",
    "# Âõ†‰∏∫graphÂ§™Â§ßÔºåÁàÜ‰∫ÜÂÜÖÂ≠òÔºåÊâÄ‰ª•Âèñ4Â§©ÁöÑtwitter dataÂÅödemoÔºåÂêéÈù¢Áî®nci server\n",
    "init_day = df.loc[0, 'date']\n",
    "df = df[(df['date']>= init_day) & (df['date']<= init_day + datetime.timedelta(days=3))].reset_index()  # (11971, 18)\n",
    "# load features\n",
    "# the dimension of combined_feature is 302 in this dataset: document_features-300 + time_features-2\n",
    "f = np.load(project_path + '/result/FinEvent result/combined_features.npy')  # (11971, 302)\n",
    "\n",
    "# generate test graphs, features, and labels\n",
    "message, all_graph_mins = construct_offline_dataset(df, offline_save_path, f, True)\n",
    "with open(offline_save_path + 'node_edge_statistics.txt', 'w') as text_file:\n",
    "    text_file.write(message)\n",
    "np.save(offline_save_path + 'all_graph_min.npy', np.asarray(all_graph_mins))\n",
    "print('Time spent on heterogeneous -> homogeneous graph conversions: ', all_graph_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1460ff81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c52d3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2012, 10, 10), datetime.date(2012, 10, 11),\n",
       "       datetime.date(2012, 10, 12), datetime.date(2012, 10, 13)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a99adad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82dadfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 18)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c3d15",
   "metadata": {},
   "source": [
    "#### data_split: 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb18b893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "986d33dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# data_split‰øùÂ≠òÁöÑÊòØmessage_blockÁöÑÊï∞ÊçÆÈáè„ÄÇe.g. data_split = [  500  ,   100, ...,  100]\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#                                                         block_0  block_1    block_n\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# demo: data_split\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dividing_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      6\u001b[0m data_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m data_split \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# data_split‰øùÂ≠òÁöÑÊòØmessage_blockÁöÑÊï∞ÊçÆÈáè„ÄÇe.g. data_split = [  500  ,   100, ...,  100]\n",
    "#                                                         block_0  block_1    block_n\n",
    "# demo: data_split\n",
    "import math\n",
    "dividing_point = int(df.shape[0] / 6)\n",
    "data_amount = 0\n",
    "\n",
    "data_split = []\n",
    "for i in range(5):\n",
    "    data_amount += dividing_point\n",
    "    if i < 2:\n",
    "        continue\n",
    "    else:\n",
    "        data_split.append(data_amount)\n",
    "data_split.append(df.shape[0])\n",
    "# save data_split.npy\n",
    "np.save(save_path + '/offline dataset/data_split.npy', np.array(data_split))\n",
    "# save edge_index_[entity, userid, word].pt Êñá‰ª∂\n",
    "data_path_temp = project_path + '/result/FinEvent result/offline dataset/'\n",
    "relations = ['entity', 'userid', 'word']\n",
    "for relation in relations:\n",
    "    relation_edge_index = sparse_trans(os.path.join(data_path_temp, 's_m_tid_%s_tid.npz' % relation))\n",
    "    torch.save(relation_edge_index, data_path_temp + '/edge_index_%s.pt' % relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b2388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05442cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2289c536",
   "metadata": {},
   "source": [
    "### run-incremental dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5ab1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_multi_relational_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m22\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43msave_multi_relational_graph\u001b[49m(data_path, relation_ids, [\u001b[38;5;241m0\u001b[39m,i])\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge index saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall edge index saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_multi_relational_graph' is not defined"
     ]
    }
   ],
   "source": [
    "# acclerate the training process\n",
    "import torch\n",
    "\n",
    "data_path = save_path\n",
    "relation_ids = ['entity', 'userid', 'word']\n",
    "for i in range(22):\n",
    "    print(i)\n",
    "    save_multi_relational_graph(data_path, relation_ids, [0,i])\n",
    "    print('edge index saved')\n",
    "print('all edge index saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd09919",
   "metadata": {},
   "source": [
    "# FinEvent Model Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cb4fa",
   "metadata": {},
   "source": [
    "## Fundemental models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265ad59",
   "metadata": {},
   "source": [
    "### GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61021ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.functional import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv  # PyGÂ∞ÅË£ÖÂ•ΩÁöÑGATConvÂáΩÊï∞\n",
    "from torch.nn import Linear, BatchNorm1d, Sequential, ModuleList, ReLU, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c066594",
   "metadata": {},
   "source": [
    "#### GAT model for mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f1a8a7e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    '''\n",
    "    adopt this module when using mini-batch\n",
    "    '''\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, heads) -> None:\n",
    "        super(GAT, self).__init__()\n",
    "        self.GAT1 = GATConv(in_channels=in_dim, out_channels=hid_dim, heads=heads, add_self_loops=False)  # ËæìÂÖ•ËäÇÁÇπÁöÑÁâπÂæÅÁª¥Â∫¶ÔºåÈöêËóèÂ±ÇËäÇÁÇπÁöÑÁª¥Â∫¶\n",
    "        self.GAT2 = GATConv(in_channels=hid_dim*heads, out_channels=out_dim, add_self_loops=False)  # ÈöêËóèÂ±ÇÁª¥Â∫¶ÔºåËæìÂá∫Áª¥Â∫¶\n",
    "        self.layers = ModuleList([self.GAT1, self.GAT2])\n",
    "        self.norm = BatchNorm1d(heads * hid_dim)  # Â∞Ünum_featuresÈÇ£‰∏ÄÁª¥ËøõË°åÂΩí‰∏ÄÂåñÔºåÈò≤Ê≠¢Ê¢ØÂ∫¶Êâ©Êï£\n",
    "    \n",
    "    def forward(self, x, adjs, device):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs): # ËøîÂõû‰∏Ä‰∏™ÂèØÈÅçÂéÜÂØπË±°ÔºåÂêåÊó∂ÂàóÂá∫Êï∞ÊçÆÂíåÊï∞ÊçÆ‰∏ãÊ†á\n",
    "            # x: Tensor, edge_index: Tensor\n",
    "            x, edge_index = x.to(device), edge_index.to(device)\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first\n",
    "            x = self.layers[i]((x,x_target), edge_index)\n",
    "            if i == 0:\n",
    "                x = self.norm(x)  # ÂΩí‰∏ÄÂåñÊìç‰ΩúÔºåÈò≤Ê≠¢Ê¢ØÂ∫¶Êï£Â∞Ñ\n",
    "                x = F.elu(x)  # ÈùûÁ∫øÊÄßÊøÄÊ¥ªÂáΩÊï∞elu\n",
    "                x = F.dropout(x, training=self.training)\n",
    "            del edge_index\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd62de1",
   "metadata": {},
   "source": [
    "#### Intra_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7f1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT model\n",
    "class Intra_AGG(nn.Module):  # intra-aggregation\n",
    "    def __init__(self, GAT_args):\n",
    "        super(Intra_AGG, self).__init__()\n",
    "        in_dim, hid_dim, out_dim, heads = GAT_args\n",
    "        self.gnn = GAT(in_dim, hid_dim, out_dim, heads)\n",
    "    \n",
    "    def forward(self, x, adjs, device):\n",
    "        x = self.gnn(x, adjs, device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abb144",
   "metadata": {},
   "source": [
    "#### Inter_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0328ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp model\n",
    "class Inter_AGG(nn.Module):  # inter-aggregation\n",
    "    def __init__(self, mlp_args=None):\n",
    "        super(Inter_AGG, self).__init__()\n",
    "        if mlp_args is not None:\n",
    "            hid_dim, out_dim = mlp_args\n",
    "            self.mlp = nn.Sequential(\n",
    "                        Linear(hid_dim, hid_dim),\n",
    "                        BatchNorm1d(hid_dim),\n",
    "                        ReLU(inplace=True),\n",
    "                        Dropout(),\n",
    "                        Linear(hid_dim, out_dim),\n",
    "                        )\n",
    "    def forward(self, features, thresholds, inter_opt):\n",
    "        batch_size = features[0].size(0)\n",
    "        features = torch.transpose(features, dim0=0, dim1=1)\n",
    "        if inter_opt == 'cat_wo_avg':\n",
    "            features = features.reshape(batch_size, -1)\n",
    "        elif inter_opt == 'cat_w_avg':\n",
    "            # weighted average and concatenate\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "        elif inter_opt == 'cat_w_avg_mlp':\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "            features = self.mlp(features)\n",
    "        elif inter_opt == 'cat_wo_avg_mlp':\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "            features = self.mlp(features)\n",
    "        elif inter_opt == 'add_wo_avg':\n",
    "            features = features.sum(dim=1)\n",
    "        elif inter_opt == 'add_w_avg':\n",
    "            features = torch.mul(features, thresholds).sum(dim=1)\n",
    "        return features\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d44c28",
   "metadata": {},
   "source": [
    "### TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee84cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3cf771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies an average on seq, of shape(nodes, features)\n",
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgReadout, self).__init__()\n",
    "    def forward(self, seq):\n",
    "        return torch.mean(seq, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2dd4e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):  # Èâ¥Âà´Âô®\n",
    "    def __init__(self, n_h):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)  # ÂèåÂêëÁé∞Ë°åÂèòÊç¢x1*A*x2\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "    \n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, m.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)  # ÊùÉÂÄºÂàùÂßãÂåñÊñπÊ≥ïÔºåÂùáÂàÜÂàÜÂ∏É\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n",
    "        c_x = torch.unsqueeze(c, 0)\n",
    "        c_x = c_x.expand_as(h_pl)  # torch.randn(size*)ÁîüÊàêsizeÁª¥Êï∞ÁªÑÔºõexpandÊòØÊâ©Â±ïÂà∞size_newÊï∞ÁªÑÔºõexpand_asÊòØÊâ©Â±ïÂà∞ÂÉèyÁöÑÊï∞ÁªÑ\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n",
    "        if s_bias1 is not None:\n",
    "            sc_1 += s_bias1\n",
    "        if s_bias2 is not None:\n",
    "            sc_2 += s_bias2\n",
    "        logits = torch.cat((sc_1, sc_2), 0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dee20b",
   "metadata": {},
   "source": [
    "#### triplet_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12d86760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆ°ÁÆótriplet_lossÊçüÂ§±ÂáΩÊï∞\n",
    "class OnlineTripletLoss(nn.Module):\n",
    "    '''\n",
    "    Online Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels\n",
    "    Triplets are generated using triplet_selector objects that take embeddings and targets and return indices of triplets\n",
    "    '''\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(OnlineTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector  # selectorÈÄâÊã©Âô®ÂØπË±°ÔºåÂê´Êúâget_tripletsÊñπÊ≥ï\n",
    "    \n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)  # Ê†πÊçÆembeddingsÂíålabelsËøîÂõûÊúÄÂ§ßloss index list\n",
    "        # if embeddings.is_cuda():\n",
    "        #     triplets = triplets.cuda()\n",
    "        # embeddingsÁü©ÈòµÁ¥¢ÂºïÊòØÂçï‰∏™ÂÖÉÁ¥†ÔºåÂèñË°åÂêëÈáèÔºåÂ§ö‰∏™Ë°åÂêëÈáèÂèàÁªÑÊàêÁü©ÈòµÔºÅÔºÅ\n",
    "        ap_distances = (embeddings[triplets[:,0]] - embeddings[triplets[:,1]]).pow(2).sum(1) # .pow(.5); \n",
    "        an_distances = (embeddings[triplets[:,0]] - embeddings[triplets[:,2]]).pow(2).sum(1) # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "        \n",
    "        return losses.mean(), len(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c98105e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f03e8c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletSelector:\n",
    "    '''\n",
    "    Implementation should return indices of anchors, positive and negative samples\n",
    "    return np array of shape [N_triplets * 3]\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        raise NotImplementedError  # Â¶ÇÊûúËøô‰∏™ÊñπÊ≥ïÊ≤°ÊúâË¢´Â≠êÁ±ªÈáçÂÜôÔºå‰ΩÜÊòØË∞ÉÁî®‰∫ÜÔºåÂ∞±‰ºöÊä•Èîô„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48daa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_demo = [1,0,0,1,2,3]\n",
    "for label in set(labels_demo):\n",
    "    label_mask_demo = (labels_demo == label)\n",
    "    label_indices_demo = np.where(label_mask_demo)[0]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b2526c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_indices_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f39c267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_mask_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46f63f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_positives = np.array([(0, 2), (0, 3), (2, 3)])\n",
    "anchor_positives[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ba2ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0,2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f288c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_demo = torch.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bd66898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6280,  2.0057, -0.6209,  0.0762],\n",
       "        [ 0.6341,  1.5761, -0.1927,  0.7800],\n",
       "        [ 2.2200, -0.5745,  1.6787, -1.3785],\n",
       "        [-1.6311, -1.0245,  0.4135,  1.5535]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dee99cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2200, -0.5745,  1.6787, -1.3785],\n",
       "        [ 0.6341,  1.5761, -0.1927,  0.7800],\n",
       "        [-1.6311, -1.0245,  0.4135,  1.5535]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_demo[np.array([2,1,3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab874ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Áü©ÈòµËÆ°ÁÆó\n",
    "def distance_matrix_computation(vectors):\n",
    "    distance_matrix=-2*vectors.mm(torch.t(vectors))+vectors.pow(2).sum(dim=1).view(1,-1)+vectors.pow(2).sum(dim=1).view(-1,1)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1efdf8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_demo = torch.tensor([2,1,2,3]).data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6d119",
   "metadata": {},
   "source": [
    "#### triplet_loss_max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4fed9b07",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ÂÖ∑‰ΩìÂÆûÁé∞‰∏âÂÖÉÊçüÂ§±ÂáΩÊï∞triplets_lossÔºåËøîÂõûÊüêÊ†áÁ≠æ‰∏ãithÂÖÉÁ¥†ÂíåjthÂÖÉÁ¥†ÔºåÂÖ∂ÊúÄÂ§ßlossÂØπÂ∫îÁöÑÂÖ∂‰ªñÊ†áÁ≠æÂÖÉÁ¥†Á¥¢Âºï\n",
    "\n",
    "class FunctionNegativeTripletSelector(TripletSelector):\n",
    "    '''\n",
    "    For each positive pair, takes the hardes negative sample (with the greatest triplet loss value) to create a triplet\n",
    "    Margin should match the margin userd in triplet loss.\n",
    "    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples\n",
    "    and return a negative index for that pair\n",
    "    '''\n",
    "    def __init__(self, margin, negative_selection_fn, cpu=True):\n",
    "        super(FunctionNegativeTripletSelector, self).__init__()\n",
    "        self.cpu = cpu\n",
    "        self.margin = margin\n",
    "        self.negative_selection_fn = negative_selection_fn  # ËøîÂõûloss_valuesÊúÄÂ§ßÂÖÉÁ¥†ÂÄºÁöÑindexÁöÑselector\n",
    "    \n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        if self.cpu:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = distance_matrix_computation(embeddings)  # ËÆ°ÁÆódistance matrix\n",
    "        distance_matrix = distance_matrix.cpu()  \n",
    "        \n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "        \n",
    "        # embeddingËÆ°ÁÆóÁöÑdistance matrix‰∏élabelsËÆ°ÁÆólossÔºåÂèñÊúÄÂ§ßloss_index\n",
    "        # ÂØπ‰∫éÊØè‰∏™Ê†áÁ≠ælabel\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)  # numpy array([True, False, True, True])\n",
    "            label_indices = np.where(label_mask)[0]  # Ê†áÁ≠æÁ¥¢Âºï, label_index, array([0, 2, 3], dtype=int64)\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]  # ÂÖ∂‰ªñÊ†áÁ≠æÁ¥¢Âºï, not_label_index, array([1], dtype=int64)\n",
    "            anchor_pos_list = list(combinations(label_indices, 2)) # 2‰∏™ÂÖÉÁ¥†ÁöÑÊ†áÁ≠æÁ¥¢ÂºïÁªÑÂêà, [(0, 2), (0, 3), (2, 3)]\n",
    "            anchor_pos_list = np.array(anchor_pos_list)  # ËΩ¨Êç¢Êàênp.arrayÊâçËÉΩËøõË°åsliceÂàáÁâáÊìç‰Ωú\n",
    "            \n",
    "            # ÊåâÁÖßanchor_positive index‰ªéË∑ùÁ¶ªÁü©Èòµ‰∏≠ÊäΩÂèñdistanceÔºõ0-indexÔºåarray([0, 0, 2]);\n",
    "            # ÊèêÂèñÊ†áÁ≠ælabelÁöÑi-element‰∏éj-elementË∑ùÁ¶ª„ÄÇ\n",
    "            anchor_p_distances = distance_matrix[anchor_pos_list[:,0], anchor_pos_list[:,1]] #Á±ª‰ººÁªÑÊàêÂùêÊ†áÔºåtensor([-1.1761,-0.8381,0.0099])\n",
    "            for anchor_positive, ap_distance in zip(anchor_pos_list, anchor_p_distances): # ÊØè‰∏™Ê†áÁ≠æ‰∏ãÔºåÂÖÉÁ¥†ÁªÑÂêà„ÄÅÂÖÉÁ¥†Ë∑ùÁ¶ª\n",
    "                # 0Ë°®Á§∫ithÂÖÉÁ¥†Âà∞ÂêÑ‰∏™ÂÖ∂‰ªñÊ†áÁ≠æÂÖÉÁ¥†ÁöÑË∑ùÁ¶ª„ÄÇ\n",
    "                # Âêå‰∏ÄÊ†áÁ≠æ‰∏ã(ith,jth)Ë∑ùÁ¶ª - ithÂÖÉÁ¥†Âà∞ÂÖ∂‰ªñÊ†áÁ≠æÂÖÉÁ¥†ÁöÑË∑ùÁ¶ª + self.marginËæπÈôÖÊî∂Áõä\n",
    "                loss_values = ap_distance - distance_matrix[  \n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "                hard_neg_max_index = self.negative_selection_fn(loss_values)  # hardËøîÂõûÊúÄÂ§ßlossÁöÑÁ¥¢Âºï\n",
    "                if hard_neg_max_index is not None:  # if ÊúÄÂ§ßlossÂÄºÈùûÁ©∫ÔºåÂàôËøîÂõûÂÖ∂‰ªñÊ†áÁ≠æÂÖÉÁ¥†ÁöÑÁ¥¢Âºï\n",
    "                    hard_negative = negative_indices[hard_neg_max_index] \n",
    "                    # ÂØπ‰∫éË∞ãÊ†áÁ≠æ‰∏ãithÂÖÉÁ¥†ÂíåjthÂÖÉÁ¥†ÔºåÂÖ∂ÊúÄÂ§ßlossÂØπÂ∫îÁöÑÂÖ∂‰ªñÊ†áÁ≠æÂÖÉÁ¥†Á¥¢Âºï\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative]) \n",
    "        \n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "        \n",
    "        triplets = np.array(triplets)\n",
    "        return torch.LongTensor(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3672739a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÈöèÊú∫-lossÈöèÊú∫Ë¥üÂÄº\n",
    "def random_hard_negative(loss_values):\n",
    "    hard_negatives = np.where(loss_values > 0)[0]\n",
    "    return np.random.choice(hard_negatives) if len(hard_negatives) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f967984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Á°¨-lossÊúÄÂ§ßË¥üÂÄº\n",
    "def hardest_negative(loss_values):\n",
    "    hard_negative = np.argmax(loss_values)\n",
    "    return hard_negative if loss_values[hard_negative] > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef5942",
   "metadata": {},
   "source": [
    "#### hard_tri-loss_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3db1ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Á°¨‰∏âÂÖÉÊçüÂ§±ÂáΩÊï∞\n",
    "def HardestNegativeTripletSelector(margin, cpu=False):\n",
    "    return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=hardest_negative, cpu=cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce64d2",
   "metadata": {},
   "source": [
    "#### random_tri-loss_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d19d6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÈöèÊú∫‰∏âÂÖÉÊçüÂ§±ÂáΩÊï∞\n",
    "def RandomNegativeTripletSelector(margin, cpu=False):\n",
    "    return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=random_hard_negative, cpu=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fef0a5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6396]],\n",
       "\n",
       "        [[-1.4468]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e90faf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5154,  0.0506,  0.3423],\n",
       "         [ 0.8576, -0.1571,  1.4457],\n",
       "         [-0.6813, -1.2860, -1.3743]],\n",
       "\n",
       "        [[-0.1772, -0.4001, -0.8635],\n",
       "         [-1.0015, -2.0096,  0.1044],\n",
       "         [-1.8040,  0.8419,  0.6068]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024f7ef",
   "metadata": {},
   "source": [
    "### NeighborRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0935aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.functional import Tensor\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6203a30",
   "metadata": {},
   "source": [
    "#### cal_similarity_node_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c344fe5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cal_similarity_node_edge(multi_r_data, features, save_path=None):\n",
    "    '''\n",
    "    This is used to culculate the similarity between node and its neighbors in advance \n",
    "    in order to avoid the repetitive computation.\n",
    "    Args:\n",
    "        multi_r_data ([type]): [description]\n",
    "        features ([type]): [description]\n",
    "        save_path ([type], optional): [description]. Defaults to None.\n",
    "    '''\n",
    "    relation_config: Dict[str, Dict[int, Any]] = {}\n",
    "    for relation_id, r_data in enumerate(multi_r_data):\n",
    "        node_config: Dict[int, Any] = {}\n",
    "        r_data: Tensor\n",
    "        unique_nodes = r_data[1].unique()\n",
    "        num_nodes = unique_nodes.size(0)\n",
    "        for node in range(num_nodes):\n",
    "            # get neighbors' index\n",
    "            neighbors_idx = torch.where(r_data[1]==node)[0]\n",
    "            # get neghbors\n",
    "            neighbors = r_data[0, neighbors_idx]\n",
    "            num_neighbors = neighbors.size(0)\n",
    "            neighbors_features = features[neighbors, :]\n",
    "            target_features = features[node, :]\n",
    "            # calculate enclidean distance with broadcast\n",
    "            dist: Tensor = torch.norm(neighbors_features - target_features, p=2, dim=1)  # torch.normÊ±ÇaÂàóÁª¥Â∫¶(dimÊåáÂÆö)ÁöÑ2(pÊåáÂÆö)ËåÉÊï∞(ÈïøÂ∫¶)\n",
    "            # smaller is better and we use 'top p' in our paper\n",
    "            # (threshold * num_neighbors) see RL_neighbor_filter for details\n",
    "            sorted_neighbors, sorted_index = dist.sort(descending=False)\n",
    "            node_config[node] = {'neighbors_idx': neighbors_idx,\n",
    "                                'sorted_neighbors': sorted_neighbors,\n",
    "                                'sorted_index': sorted_index,\n",
    "                                'num_neighbors': num_neighbors}\n",
    "        relation_config['relation_%d' % relation_id] = node_config\n",
    "    if save_path is not None:\n",
    "        print(save_path)\n",
    "        save_path = os.path.join(save_path, 'relation_config.npy')\n",
    "        np.save(save_path, relation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db06b89",
   "metadata": {},
   "source": [
    "#### RL_neighbor_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71a8616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËøîÂõûfiltered neighbor index\n",
    "def RL_neighbor_filter(multi_r_data, RL_thtesholds, load_path):\n",
    "    load_path = os.path.join(load_path, 'relation_config.npy')\n",
    "    relation_config = np.load(load_path, allow_pickle=True)\n",
    "    relation_config = relation_config.tolist()\n",
    "    relations = list(relation_config.keys())\n",
    "    multi_remain_data = []\n",
    "    \n",
    "    for i in range(len(relations)):\n",
    "        edge_index: Tensor = multi_r_data[i]\n",
    "        unique_nodes = edge_index[1].unique()\n",
    "        num_nodes = unique_nodes.size(0)\n",
    "        remain_node_index = torch.tensor([])\n",
    "        for node in range(num_nodes):\n",
    "            # extract config\n",
    "            neighbors_idx = relation_config[relations[i]][node]['neighbors_idx']\n",
    "            num_neighbors = relation_config[relations[i]][node]['num_neighbors']\n",
    "            sorted_neighbors = relation_config[relations[i]][node]['sorted_neighbors']\n",
    "            sorted_index = relation_config[relations[i]][node]['sorted_index']\n",
    "            \n",
    "            if num_neighbors < 5:\n",
    "                remain_node_index = torch.cat((remain_node_index, neighbors_idx))\n",
    "                continue  # add limitations\n",
    "            \n",
    "            threshold = float(RL_thtesholds[i])\n",
    "            \n",
    "            num_kept_neighbors = math.ceil(num_neighbors * threshold) + 1\n",
    "            num_kept_neighbors_idx = neighbors_idx[sorted_index[:num_kept_neighbors]]\n",
    "            filtered_neighbors_idx = neighbors_idx[sorted_index[:num_kept_neighbors]]\n",
    "            remain_node_index = torch.cat((remain_node_index, filtered_neighbors_idx))\n",
    "            \n",
    "        remain_node_index = remain_node_index.type('torch.LongTensor')\n",
    "        edge_index = edge_index[:, remain_node_index]\n",
    "        multi_remain_data.append(edge_index)\n",
    "    \n",
    "    return multi_remain_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d0558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa8ada47",
   "metadata": {},
   "source": [
    "# FinEvent Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071df23",
   "metadata": {},
   "source": [
    "## gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a7f3789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse.tensor import SparseTensor\n",
    "# from .utils import generateMasks, gen_offline_masksÔºåÊòØÊåá‰ªéutils.pyÊñá‰ª∂‰∏≠ÂØºÂÖ•ÂáΩÊï∞: generatemasks, gen_offline_masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1de4b8c",
   "metadata": {},
   "source": [
    "### sparse_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fd5d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relations_ids = ['entity', 'userid', 'word'],ÂàÜÂà´ËØªÂèñËøô‰∏â‰∏™Êñá‰ª∂\n",
    "def sparse_trans(datapath = 'incremental_0808/0/s_m_tid_userid_tid.npz'):\n",
    "    relation = sparse.load_npz(datapath)  # (11971, 11971)\n",
    "    all_edge_index = torch.tensor([], dtype=int)\n",
    "    for node in range(relation.shape[0]):\n",
    "        neighbor = torch.IntTensor(relation[node].toarray()).squeeze()  # IntTensorÊòØtorchÂÆö‰πâÁöÑ7‰∏≠cpu tensorÁ±ªÂûã‰πã‰∏ÄÔºõ\n",
    "                                                                        # squeezeÂØπÊï∞ÊçÆÁª¥Â∫¶ËøõË°åÂéãÁº©ÔºåÂà†Èô§ÊâÄÊúâ‰∏∫1ÁöÑÁª¥Â∫¶\n",
    "        # del self_loop in advance\n",
    "        neighbor[node] = 0\n",
    "        neighbor_idx = neighbor.nonzero()  # ËøîÂõûÈùûÈõ∂ÂÖÉÁ¥†ÁöÑÁ¥¢Âºï\n",
    "        neighbor_sum = neighbor_idx.size(0)  # Ë°®Á§∫Á¨¨0Áª¥Â∫¶ÁöÑÊï∞ÊçÆÈáè\n",
    "        loop = torch.tensor(node).repeat(neighbor_sum, 1)  # repeatË°®Á§∫Ê≤øÁùÄÊåáÂÆöÁöÑÁª¥Â∫¶ÈáçÂ§çtensorÁöÑÊ¨°Êï∞\n",
    "        edge_index_i_j = torch.cat((loop, neighbor_idx), dim=1).t()  # catË°®Á§∫ÊãºÊé•ÔºõtË°®Á§∫ÂØπ‰∫åÁª¥Áü©ÈòµËøõË°åËΩ¨ÁΩÆ\n",
    "        self_loop = torch.tensor([[node], [node]])\n",
    "        all_edge_index = torch.cat((all_edge_index, edge_index_i_j, self_loop), dim=1)\n",
    "        del neighbor, neighbor_idx, loop, self_loop, edge_index_i_j\n",
    "    return all_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8145cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coo_trans(datapath = 'incremental_0808/0/s_m_tid_userid_tid.npz'):\n",
    "    relation: csr_matrix = sparse.load_npz(datapath)\n",
    "    relation: coo_matrix = relation.tocoo()\n",
    "    sparse_edge_index = torch.LongTensor([relation.row, relation.col])  # sparseÁ®ÄÁñèÁü©ÈòµÁî®‰∏âÂÖÉÁªÑ(row,col,data)Êù•Â≠òÂÇ®ÈùûÈõ∂ÂÖÉÁ¥†‰ø°ÊÅØ\n",
    "    return sparse_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d56ffbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(loadpath, relation, mode):\n",
    "    features = np.load(os.path.join(loadpath, str(mode[1]), 'features_embeddings.npy'))\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features laoded')\n",
    "    labels = np.load(os.path.join(loadpath, str(mode[1]), 'labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    relation_edge_index = coo_trans(os.path.join(loadpath, str(mode[1]), 's_m_tid_%s_tid.npz' % relation))\n",
    "    print('edge index laoded')\n",
    "    data = Data(x=features, edge_index=relation_edge_index, y=labels)\n",
    "    data_split = np.load(os.path.join(loadpath, 'data_split.npy'))\n",
    "    train_i, i = mode[0], mode[1]\n",
    "    if train_i == i:\n",
    "        data.train_mask, data.val_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    else:\n",
    "        data.test_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43511c93",
   "metadata": {},
   "source": [
    "### create homodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbae31c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mode: (train_i, i)\n",
    "message block 0-train_i, as training dataset\n",
    "random selection from training dataset, as validation dataset\n",
    "other message blocks between train_i and i, having no labels\n",
    "message block i, as test dataset\n",
    "'''\n",
    "# ËøîÂõûtraining, validation, test data\n",
    "def create_homodataset(loadpath, mode, valid_percent=0.2):\n",
    "    features = np.load(os.path.join(loadpath, 'features_embeddings.npy'))  # features embeddings\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features loaded')\n",
    "    labels = np.load(os.path.join(loadpath, 'labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    \n",
    "    data = Data(x=features, edge_index=None, y=labels)  # torch_geometricÊèê‰æõÁöÑÂõæÊï∞ÊçÆÁ±ªÂûãDataÔºåxË°®Á§∫tensorÁü©ÈòµÔºå\n",
    "                                                        # ÂΩ¢Áä∂‰∏∫[num_nodes, num_node_features]; \n",
    "                                                        # edge_indexË°®Á§∫cooÊ†ºÂºèÁöÑÂõæÁöÑËæπÂÖ≥Á≥ªÔºåÂΩ¢Áä∂‰∏∫[2, num_edge]\n",
    "    data_split = np.load(os.path.join(loadpath, 'data_split.npy'))\n",
    "    # load number of message in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    train_i, i = mode[0], mode[1]\n",
    "    if train_i == i:\n",
    "        data.train_mask, data.val_mask = generateMasks(len(labels), data_split, train_i, i, valid_percent)\n",
    "    else:\n",
    "        data.test_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82a47b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11971, 18)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d86d2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac79406",
   "metadata": {},
   "source": [
    "### create_offline_homodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "09409dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_offline_homodataset(loadpath, mode):\n",
    "    features = np.load(os.path.join(loadpath, 'features_embeddings.npy'))\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features loaded')\n",
    "    labels = np.load(os.path.join(loadpath, 'labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    data = Data(x=features, edge_index=None, y=labels)\n",
    "    data.train_mask, data.val_mask, data.test_mask = gen_offline_masks(len(labels))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b12a7a",
   "metadata": {},
   "source": [
    "### create_multi_relational_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "946dca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edge_index_relation data\n",
    "def create_multi_relational_graph(loadpath, relations, mode):\n",
    "    multi_relation_edge_index = [torch.load(loadpath + '/edge_index_%s.pt' % relation) for relation in relations]\n",
    "    print('sparse trans...')\n",
    "    print('edge index loaded')\n",
    "    \n",
    "    return multi_relation_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96c12141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [5],\n",
       "        [7],\n",
       "        [2]]),\n",
       " array([[0, 3, 1, 2]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ix_([1,5,7,2],[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e696c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multi_relational_graph(loadpath, relations, mode):\n",
    "    for relation in relations:\n",
    "        relation_edge_index = sparse_trans(os.path.join(loadpath, str(mode[1]), 's_m_tid_%s_tid.npz' % relation))\n",
    "        torch.save(relation_edge_index, loadpath + '/' + str(mode[1]) + '/edge_index_%s.pt' % relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "70577d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f977bbf",
   "metadata": {},
   "source": [
    "### generateMasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7436d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËøîÂõûtrainingÔºåvalidation, testÁöÑÁ¥¢Âºïindices\n",
    "def generateMasks(length, data_split, train_i, i, validation_percent=0.2, save_path=None, remove_absolete=2):\n",
    "    '''    \n",
    "    Intro:\n",
    "    This function generates train and validation indices for initial/maintenance epochs and test indices for inference(prediction) epochs\n",
    "    If remove_obsolete mode 0 or 1:\n",
    "    For initial/maintenance epochs:\n",
    "    - The first (train_i + 1) blocks (blocks 0, ..., train_i) are used as training set (with explicit labels)\n",
    "    - Randomly sample validation_percent of the training indices as validation indices\n",
    "    For inference(prediction) epochs:\n",
    "    - The (i + 1)th block (block i) is used as test set.\n",
    "    \n",
    "    Note that other blocks (block train_i + 1, ..., i - 1) are also in the graph (without explicit labels, only their features and structural info are leveraged)\n",
    "\n",
    "    :param length: the length of label list\n",
    "    :param data_split: loaded splited data (generated in custom_message_graph.py)\n",
    "    :param train_i, i: flag, indicating for initial/maintenance stage if train_i == i and inference stage for others\n",
    "    :param validation_percent: the percent of validation data occupied in whole dataset\n",
    "    :param save_path: path to save data\n",
    "    :param num_indices_to_remove: number of indices ought to be removed\n",
    "    :returns train indices, validation indices or test indices\n",
    "    '''\n",
    "    # step1: verify total number of nodes\n",
    "    assert length == data_split[i] # 500\n",
    "    \n",
    "    # step2.0: if is in initial/maintenance epochs, generate train and validation indices\n",
    "    if train_i == i:\n",
    "        # step3: randomly shuffle the graph indices\n",
    "        train_indices = torch.randperm(length)  # ËøîÂõû‰∏Ä‰∏™ÈöèÊú∫ÊâìÊï£ÁöÑ0-n-1 tensorÊï∞ÁªÑ\n",
    "        # step4: get total number of validation indices\n",
    "        n_validation_samples = int(length * validation_percent)\n",
    "        # step5: sample n_validation_samples validation indices and use the rest as training indices\n",
    "        validation_indices = train_indices[:n_validation_samples]\n",
    "        train_indices = train_indices[n_validation_samples:]\n",
    "        # step6: save indices\n",
    "        if save_path is not None:\n",
    "            torch.save(train_indices, save_path + '/train_indices.pt')\n",
    "            torch.save(validation_indices, save_path + '/validation_indices.pt')\n",
    "        return train_indices, validation_indices\n",
    "    # step2.1: if is in inference(prediction) epochs, generate test indices\n",
    "    else:\n",
    "        test_indices = torch.arange(0, (data_split[i]), dtype=torch.long)\n",
    "        if save_path is not None:\n",
    "            torch.save(test_indices, save_path + '/test_indices.pt')\n",
    "        return test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b57ac2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98181995",
   "metadata": {},
   "source": [
    "### gen_offline_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ebd97508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_offline_masks(length, validation_percent=0.2, test_percent=0.1):\n",
    "    test_length = int(length * test_percent)\n",
    "    valid_length = int(length * validation_percent)\n",
    "    train_length = length - valid_length - test_length\n",
    "    \n",
    "    samples = torch.randperm(length)  # ËøîÂõûÈöèÊú∫ÊâìÊï£ÁöÑ0~n-1ÁöÑtensorÊï∞ÁªÑ\n",
    "    train_indices = samples[:train_length]\n",
    "    valid_indices = samples[train_length: train_length + valid_length]\n",
    "    test_indices = samples[train_length + valid_length:]\n",
    "    \n",
    "    return train_indices, valid_indices, test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d824b",
   "metadata": {},
   "source": [
    "### mysampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "feb9e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional, Tuple, NamedTuple, Union, Callable\n",
    "from scipy import sparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.loader import NeighborSampler, RandomNodeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fcac323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NeighborSamplerËøîÂõûÁªìÊûúÔºöbatch_size, n_id,adjs(edge_index,e_id,size)\n",
    "class MySampler(object):\n",
    "    def __init__(self, sampler) -> None:\n",
    "        super().__init__()\n",
    "        self.sampler = sampler\n",
    "    \n",
    "    def sample(self, multi_relational_edge_index: List[Tensor], node_idx, sizes, batch_size):\n",
    "        if self.sampler == 'RL_sampler':\n",
    "            return self._RL_sample(multi_relational_edge_index, node_idx, sizes, batch_size)\n",
    "        elif self.sampler == 'randdom_sampler':\n",
    "            return self._random_sample(multi_relational_edge_index, node_idx, batch_size)\n",
    "        elif self.sampler == 'const_sampler':\n",
    "            return self._const_sample(multi_relational_edge_index, node_idx, batch_size)\n",
    "    \n",
    "    def _RL_sample(self, multi_relational_edge_index: List[Tensor], node_idx, sizes, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        for id, edge_index in enumerate(multi_relational_edge_index):  # ËøîÂõûÊï∞ÊçÆÂíåÊï∞ÊçÆ‰∏ãÊ†á\n",
    "            loader = NeighborSampler(edge_index=edge_index, \n",
    "                                     sizes=sizes, \n",
    "                                     node_idx=node_idx, \n",
    "                                     return_e_id=False,\n",
    "                                     batch_size=batch_size, \n",
    "                                     num_workers=0)  \n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):  # NeighborSamplerËøîÂõûÁªìÊûúÔºöbatch_size, n_id,adjs(edge_index,e_id,size)\n",
    "                outs.append(adjs)  # adjsÂåÖÊã¨Ôºöedge_index, bipartiteÂ≠êÂõæ‰∏≠sourceËäÇÁÇπÂà∞targetËäÇÁÇπÁöÑËæπÔºåe_idÊòØÂú®ÂéüÂßãÂõæ‰∏≠ÁöÑidÔºåsizeÊòØÂ≠êÂõæshape\n",
    "                all_n_ids.append(n_ids)  # n_idsÊòØÂåÖÂê´ÊâÄÊúâÂú®LÂ±ÇÂç∑ÁßØ‰∏≠ÈÅáÂà∞ÁöÑËäÇÁÇπÁöÑlistÔºå‰∏îtargetËäÇÁÇπÂú®n_idsÂâçÂá†‰Ωç\n",
    "            \n",
    "            assert id == 0  # Êñ≠Ë®ÄÔºåÊù°‰ª∂‰∏∫falseÊó∂Ëß¶ÂèëÔºå‰∏≠Êñ≠Á®ãÂ∫è\n",
    "        return outs, all_n_ids\n",
    "    \n",
    "    def _random_sample(self, multi_relational_edge_index: List[Tensor], node_idx, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        sizes = [random.randint(10,100), random.randint(10,50)]\n",
    "        for edge_index in multi_relational_edge_index:\n",
    "            loader = NeighborSampler(edge_index=edge_index, sizes=sizes, node_idx=node_idx, return_e_id=False,\n",
    "                                    batch_size=batch_size, num_workers=0)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):\n",
    "                outs.append(adjs)\n",
    "                all_n_ids.append(n_ids)\n",
    "            assert id == 0\n",
    "        return outs, all_n_ids\n",
    "\n",
    "    def _const_sample(self, multi_relational_edge_index: List[Tensor], node_idx, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        sizes = [25, 15]\n",
    "        for edge_index in multi_relational_edge_index:\n",
    "            loader = NeighborSampler(edge_index=edge_index, sizes=sizes, node_idx=node_idx, return_e_id=False,\n",
    "                                    batch_size=batch_size, num_workers=0)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):\n",
    "                outs.append(adjs)\n",
    "                all_n_ids.append(n_ids)\n",
    "            assert id == 0\n",
    "        return outs, all_n_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37081a9",
   "metadata": {},
   "source": [
    "### save_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3dc97cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(extracted_features, save_path):\n",
    "    torch.save(extracted_features, save_path + '/final_embeddings.pt')\n",
    "    print('extracted features saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8789272a",
   "metadata": {},
   "source": [
    "## MarGNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2356cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import Tensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38dd1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MarGNN model ËøîÂõûnode embedding representation\n",
    "class MarGNN(nn.Module):\n",
    "    def __init__(self, GNN_args, num_relations, inter_opt, is_shared=False):\n",
    "        super(MarGNN, self).__init__()\n",
    "        \n",
    "        self.num_relations = num_relations  \n",
    "        self.inter_opt = inter_opt\n",
    "        self.is_shared = is_shared\n",
    "        if not self.is_shared:\n",
    "            self.intra_aggs = torch.nn.ModuleList([Intra_AGG(GNN_args) for _ in range(self.num_relations)])\n",
    "        else:\n",
    "            self.intra_aggs = Intra_AGG(GNN_args) # shared parameters\n",
    "        \n",
    "        if self.inter_opt == 'cat_w_avg_mlp' or 'cat_wo_avg_mlp':\n",
    "            in_dim, hid_dim, out_dim, heads = GNN_args\n",
    "            mlp_args = self.num_relations * out_dim, out_dim\n",
    "            self.inter_agg = Inter_AGG(mlp_args)\n",
    "        else:\n",
    "            self.inter_agg = Inter_AGG()\n",
    "    \n",
    "    def forward(self, x, adjs, n_ids, device, RL_thresholds):\n",
    "        # RL_threshold: tensor([[.5], [.5], [.5]])\n",
    "        if RL_thresholds is None:\n",
    "            RL_thresholds = torch.FloatTensor([[1.], [1.], [1.]])\n",
    "        if not isinstance(RL_thresholds, Tensor):\n",
    "            RL_thresholds = torch.FloatTensor(RL_thresholds)\n",
    "        RL_thresholds = RL_thresholds.to(device)\n",
    "        \n",
    "        features = []\n",
    "        for i in range(self.num_relations):  \n",
    "            if not self.is_shared:\n",
    "                # print('Intra Aggregation of relation %d' % i)\n",
    "                features.append(self.intra_aggs[i](x[n_ids[i]], adjs[i], device))\n",
    "            else:\n",
    "                # shared parameters\n",
    "                # print('Shared Intra Aggregation ...')\n",
    "                features.append(self.intra_aggs(x[n_ids[i]], adjs[i], device))\n",
    "        \n",
    "        features = torch.stack(features, dim=0)\n",
    "        features = self.inter_agg(features, RL_thresholds, self.inter_opt)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0965f",
   "metadata": {},
   "source": [
    "## HeteGAT_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660589af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HeteGAT_multi((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38afd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteGAT_multi(BaseGAttN):\n",
    "    '''\n",
    "    # forwardÔºõmodel = HeteGAT_multi\n",
    "    logits, final_embedding, att_val = model.inference(ftr_in_list,  # list:3, tensorÔºà1Ôºå 3025Ôºå 1870Ôºâ\n",
    "                                                       nb_classes,   # 3\n",
    "                                                       nb_nodes,     # 3025\n",
    "                                                       is_train,     # bool\n",
    "                                                       attn_drop,    # tensor, ()\n",
    "                                                       ffd_drop,     # tensor, ()\n",
    "                                                        bias_mat_list=bias_in_list,  # list:2, tensor()\n",
    "                                                       hid_units=hid_units,   # hid_units:8\n",
    "                                                       n_heads=n_heads,       # n_heads: [8, 1]\n",
    "                                                       residual=residual,     # residual: False\n",
    "                                                       activation=nonlinearity)  # nonlinearity:tf.nn.elu\n",
    "    \n",
    "    model = HeteGAT_multi((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "    '''\n",
    "    def inference(feat_dim, nb_classes, nb_nodes, training, attn_drop, ffd_drop,\n",
    "                  bias_mat_list, hid_units, n_heads, activation=tf.nn.elu, residual=False,\n",
    "                  mp_att_size=128):\n",
    "        embed_list = []\n",
    "        for features, bias_mat in zip(feat_dim, bias_mat_list):\n",
    "            attns = []\n",
    "            jhy_embeds = []\n",
    "            for _ in range(n_heads[0]):   # [8,1]\n",
    "                # multi-head attention ËÆ°ÁÆó\n",
    "                attns.append(attn_head(features, bias_mat=bias_mat,\n",
    "                                              out_sz=hid_units[0], activation=activation,\n",
    "                                              in_drop=ffd_drop, coef_drop=attn_drop, residual=False))\n",
    "            h_1 = tf.concat(attns, axis=-1)\n",
    "\n",
    "            for i in range(1, len(hid_units)):\n",
    "                h_old = h_1\n",
    "                attns = []\n",
    "                for _ in range(n_heads[i]):\n",
    "                    attns.append(attn_head(h_1, bias_mat=bias_mat,\n",
    "                                                  out_sz=hid_units[i],\n",
    "                                                  activation=activation,\n",
    "                                                  in_drop=ffd_drop,\n",
    "                                                  coef_drop=attn_drop, residual=residual))\n",
    "                h_1 = tf.concat(attns, axis=-1)\n",
    "            embed_list.append(tf.expand_dims(tf.squeeze(h_1), axis=1))  # list:2. ÂÖ∂‰∏≠ÊØè‰∏™ÂÖÉÁ¥†tensor, (3025, 1, 64)\n",
    "\n",
    "        multi_embed = tf.concat(embed_list, axis=1)   # tensor, (3025, 2, 64)\n",
    "        # attentionËæìÂá∫Ôºötensor(3025, 64)„ÄÅsoftmaxÊ¶ÇÁéá\n",
    "        final_embed, att_val = SimpleAttLayer(multi_embed, \n",
    "                                              mp_att_size,\n",
    "                                              time_major=False,\n",
    "                                              return_alphas=True)\n",
    "\n",
    "        out = []\n",
    "        for i in range(n_heads[-1]):  # 1\n",
    "            # Áî®‰∫éÊ∑ªÂä†‰∏Ä‰∏™ÂÖ®ËøûÊé•Â±Ç(input, output) -> (3025, 3)\n",
    "            out.append(tf.compat.v1.layers.dense(final_embed, nb_classes, activation=None))  \n",
    "        #     out.append(attn_head(h_1, bias_mat=bias_mat,\n",
    "        #                                 out_sz=nb_classes, activation=lambda x: x,\n",
    "        #                                 in_drop=ffd_drop, coef_drop=attn_drop, residual=False))\n",
    "        logits = tf.add_n(out) / n_heads[-1]  # add_nÊòØÂàóË°®Áõ∏Âä†„ÄÇtensor,(3025, 3)\n",
    "        # logits_list.append(logits)\n",
    "        print('de')\n",
    "\n",
    "        logits = tf.expand_dims(logits, axis=0)  # (1, 3025, 3)\n",
    "        # attentionÈÄöËøáÂÖ®ËøûÊé•Â±ÇÈ¢ÑÊµã(1, 3025, 3)„ÄÅattention final_embedding tensor(3025, 64)„ÄÅattention Ê¶ÇÁéá\n",
    "        return logits, final_embed, att_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e77a91",
   "metadata": {},
   "source": [
    "## FinEvent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b044c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import gc  # garbage cleaning package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "505fb925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models\\\\FinEvent Models'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "60f4e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_epochs=50, window_size=3, patience=5, margin=3, lr=0.001, batch_size=100, hidden_dim=128, out_dim=64, heads=4, validation_percent=0.2, use_hardest_neg=False, is_shared=False, inter_opt='cat_w_avg', is_initial=True, sampler='RL_sampler', cluster_type='kmeans', threshold_start0=[[0.2], [0.2], [0.2]], RL_step0=0.02, RL_start0=0, eps_start=0.001, eps_step=0.02, min_Pts_start=2, min_Pts_step=1, use_cuda=True, data_path='D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/offline dataset/', mask_path=None, log_interval=10)\n"
     ]
    }
   ],
   "source": [
    "args = args_register()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8391b856",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class FinEvent():\n",
    "    def __init__(self, args) -> None:\n",
    "        # register args\n",
    "        self.args = args\n",
    "    \n",
    "    def inference(self,  # inference = prediction\n",
    "                 train_i, i,\n",
    "                 metrics,\n",
    "                 embedding_save_path,\n",
    "                 loss_fn,\n",
    "                 model: HeteGAT_multi, # MarGNN,  # HeteGAT\n",
    "                 RL_thresholds=None,\n",
    "                 loss_fn_dgi=None):\n",
    "        # make dir for graph i\n",
    "        # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "        save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "        if not os.path.isdir(save_path_i):\n",
    "            os.mkdir(save_path_i)\n",
    "         \n",
    "        # load data\n",
    "        relation_ids: List[str] = ['entity', 'userid', 'word']  # typing package\n",
    "        homo_data = create_homodataset(self.args.data_path, [train_i, i], self.args.validation_percent) # get training,validation,testÊï∞ÊçÆ\n",
    "        multi_r_data = create_multi_relational_graph(self.args.data_path, relation_ids, [train_i, i])  # load relation data\n",
    "        num_relations = len(multi_r_data)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() and self.args.use_cuda else 'cpu')\n",
    "        \n",
    "        # input dimension (300 in our paper)\n",
    "        features = homo_data.x  # xÊòØfeatures embeddings\n",
    "        feat_dim = features.size(1)\n",
    "        \n",
    "        # prepare graph configs for node filtering\n",
    "        if self.args.is_initial:\n",
    "            print('prepare node configures...')\n",
    "            pre_node_dist(multi_r_data, homo_data.x, save_path_i)\n",
    "            filter_path = save_path_i\n",
    "        else:\n",
    "            filter_path = self.args.data_path + str(i)\n",
    "        \n",
    "        if model is None:\n",
    "            assert 'Cannot fine pre-trained model'\n",
    "        \n",
    "        # directly predict\n",
    "        message = '\\n-----------------Directly predict on block' + str(i) + '-----------------\\n'\n",
    "        print(message)\n",
    "        print('RL Threshold using in this block:', RL_thresholds)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        test_indices, labels = homo_data.test_mask, homo_data.y\n",
    "        test_num_samples = test_indices.size(0)\n",
    "        \n",
    "        sampler = MySampler(self.args.sampler)\n",
    "        \n",
    "        # filter neighbor in advance to fit with neighbor sampling\n",
    "        filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) if RL_thresholds is not None and \\\n",
    "                                self.args.sampler == 'RL_sampler' else multi_r_data\n",
    "        \n",
    "        # batch testing\n",
    "        extract_features = torch.FloatTensor([])\n",
    "        num_batches = int(test_num_samples / self.args.batch_size) + 1\n",
    "        with torch.no_grad():  # Âú®ËØ•Ê®°Âùó‰∏ãÔºåÊâÄÊúâËÆ°ÁÆóÂæóÂá∫ÁöÑtensorÁöÑrequires_gradÈÉΩËá™Âä®ËÆæÁΩÆ‰∏∫FalseÔºå‰∏çËá™Âä®ÂèçÂêë‰º†Êí≠Ê±ÇÂØº\n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                \n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch + 1) * self.args.batch_size, test_num_samples)\n",
    "                batch_nodes = test_indices[i_start:i_end]\n",
    "                \n",
    "                # sampling neighbors of batch nodes\n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx= batch_nodes, sizes=[-1, -1], \n",
    "                                             batch_size= self.args.batch_size)\n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                batch_seconds_spent = time.time() - start_batch\n",
    "                \n",
    "                # for we haven't shuffle the test indices(see utils.py)\n",
    "                # the output embeddings can be simply stacked together\n",
    "                extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "                \n",
    "                del pred\n",
    "                gc.collect()  # Ê∏ÖÈô§ÁºìÂ≠ò\n",
    "        \n",
    "        save_embeddings(extract_features, save_path_i)\n",
    "        # ËøîÂõûËØÑ‰ª∑ÊåáÊ†ánmiÔºåamiÔºåari\n",
    "        test_nmi = evaluate(extract_features,\n",
    "                           labels,\n",
    "                           indices=test_indices,\n",
    "                           epoch=-1, # just for test\n",
    "                           num_isolated_nodes=0,\n",
    "                           save_path= save_path_i,\n",
    "                           is_validation= False,\n",
    "                           cluster_type= self.args.cluster_type)\n",
    "        del homo_data, multi_r_data, features, filtered_multi_r_data\n",
    "        torch.cuda.empty_cache()  # ÈáäÊîæÊòæÂ≠ò\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # train on initial/maintenance graphs, t==0 or t % window_size == 0 in this paper\n",
    "    def initial_maintain(self,\n",
    "                        train_i, i,\n",
    "                        metrics,\n",
    "                        embedding_save_path,\n",
    "                        loss_fn,\n",
    "                        model=None,\n",
    "                        loss_fn_dgi=None):\n",
    "        '''\n",
    "        :param i:\n",
    "        :param data_split:\n",
    "        :param metrics:\n",
    "        :param embedding_save_path:\n",
    "        :param loss_fn:\n",
    "        :param model:\n",
    "        :param loss_fn_dgi:\n",
    "        :return:\n",
    "        '''\n",
    "        # make dir for graph i\n",
    "        # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "        save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "        if not os.path.isdir(save_path_i):\n",
    "            os.mkdir(save_path_i)\n",
    "        \n",
    "        # load data\n",
    "        relation_ids: List[str] = ['entity', 'userid', 'word']\n",
    "        homo_data = create_homodataset(self.args.data_path, [train_i, i], self.args.validation_percent)\n",
    "        multi_r_data = create_multi_relational_graph(self.args.data_path, relation_ids, [train_i, i])  # relation data\n",
    "        num_relations = len(multi_r_data)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() and self.args.use_cuda else 'cpu')\n",
    "        \n",
    "        # input dimension (300 in our paper)\n",
    "        num_dim = homo_data.x.size(0)  # embeddings num\n",
    "        feat_dim = homo_data.x.size(1) # embeddings dimension\n",
    "        \n",
    "        # prepare graph configs for node filtering\n",
    "        if self.args.is_initial:\n",
    "            print('prepare node %configures...')\n",
    "            cal_similarity_node_edge(multi_r_data, homo_data.x, save_path_i)\n",
    "            filter_path = save_path_i\n",
    "        else:\n",
    "            filter_path = self.args.data_path + str(i)\n",
    "        \n",
    "        if model is None: # pre-training stage in our paper\n",
    "            # print('Pre-Train Stage')\n",
    "            model = MarGNN((feat_dim, self.args.hidden_dim, self.args.out_dim, self.args.heads),\n",
    "                          num_relations=num_relations, inter_opt=self.args.inter_opt, is_shared=self.args.is_shared)\n",
    "        \n",
    "        # define sampler\n",
    "        sampler = MySampler(self.args.sampler)  # top-p neighbors\n",
    "        # load model to device\n",
    "        model.to(device)\n",
    "        \n",
    "        # initialize RL thresholds\n",
    "        RL_thresholds = torch.FloatTensor(self.args.threshold_start0)  # [[0.2],[0.2],[0.2]]\n",
    "        \n",
    "        # define optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=1e-4)\n",
    "        \n",
    "        # record training log\n",
    "        message = '\\n------------- Start initial training / maintaining using block ' + str(i) + '----------\\n'\n",
    "        print(message)\n",
    "        with open(save_path_i + '/log.txt', 'a') as f:\n",
    "            f.write(message)\n",
    "        \n",
    "        # record the highest validation nmi ever got for early stopping\n",
    "        best_vali_nmi = 1e-9\n",
    "        best_epoch = 0\n",
    "        wait = 0\n",
    "        # record validation nmi of all epochs before early stop\n",
    "        all_vali_nmi = []\n",
    "        # record the time spent in seconds on each batch of all training/maintaining epochs\n",
    "        seconds_train_batches = []\n",
    "        # record the time spent in mins on each epoch\n",
    "        mins_train_epochs = []\n",
    "        \n",
    "        # step13: start epoch training\n",
    "        for epoch in range(self.args.n_epochs):  # n_epochs=50\n",
    "            start_epoch = time.time()\n",
    "            losses = []\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            for metric in metrics:\n",
    "                metric.reset()\n",
    "                \n",
    "            # Multi-Agent\n",
    "            \n",
    "            # filter neighbor in advance to fit with neighbor sampling\n",
    "            if epoch >= self.args.RL_start0 and self.args.sampler == 'RL_sampler':  # RL_start0=0\n",
    "                filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) \n",
    "            else:\n",
    "                filtered_multi_r_data = multi_r_data\n",
    "                \n",
    "            model.train()\n",
    "            train_num_samples, valid_num_samples = homo_data.train_mask.size(0), homo_data.val_mask.size(0)\n",
    "            all_num_samples = train_num_samples + valid_num_samples\n",
    "            \n",
    "            # mini-batch training------------------------------------------------------------------\n",
    "            num_batches = int(train_num_samples / self.args.batch_size) + 1  # batch_size=100\n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch + 1) * self.args.batch_size, train_num_samples)\n",
    "                batch_nodes = homo_data.train_mask[i_start:i_end]  # ‰ªétraining data‰∏≠ÂèñÂá∫mini-batchÁî®‰∫éËÆ≠ÁªÉ\n",
    "                batch_labels = homo_data.y[batch_nodes]\n",
    "                \n",
    "                # sampling neighobrs from mini-batch nodes \n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_ids=batch_nodes, sizes=[-1,-1], batch_size=self.args.batch_size)\n",
    "                \n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                \n",
    "                loss_outputs = loss_fn(pred, batch_labels)\n",
    "                \n",
    "                loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                for metric in metrics:\n",
    "                    metric(pred, batch_labels, loss_outputs)\n",
    "                    \n",
    "                if batch % self.args.log_interval == 0:\n",
    "                    message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(batch * self.args.batch_size, train_num_samples, 100. * batch / ((train_num_samples // self.args.batch_size) + 1), np.mean(losses))\n",
    "                    \n",
    "                    for metric in metrics:\n",
    "                        message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "                    \n",
    "                    with open(save_path_i + '/log.txt', 'a') as f:\n",
    "                        f.write(message)\n",
    "                    losses = []\n",
    "                del pred, loss_outputs\n",
    "                gc.collect()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()  # Êõ¥Êñ∞ÂèÇÊï∞\n",
    "                \n",
    "                batch_seconds_spent = time.time() - start_batch\n",
    "                seconds_train_batches.append(batch_seconds_spent)\n",
    "                \n",
    "                del pred\n",
    "                gc.collect()\n",
    "            \n",
    "            # step 14: print loss\n",
    "            total_loss /= (batch + 1)\n",
    "            message = 'Epoch: {}/{}. Average loss: {:.4f}'.format(epoch, self.args.n_epochs, total_loss)\n",
    "            for metric in metrics:\n",
    "                message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "            mins_spent = (time.time() - start_epoch) / 60\n",
    "            message += '\\nThis epoch took {:.2f} mins'.format(mins_spent)\n",
    "            message += '\\n'\n",
    "            print(message)\n",
    "            \n",
    "            with open(save_path_i + '/log.txt', 'a') as f:\n",
    "                f.write(message)\n",
    "            mins_train_epochs.append(mins_spent)\n",
    "            \n",
    "            # validation-------------------------------------------------------------------------\n",
    "            # infer the representation of all tweets\n",
    "            model.eval()\n",
    "            \n",
    "            # we recommand to forward all nodes and select the validation indices instead\n",
    "            extract_features = torch.FloatTensor([])\n",
    "            \n",
    "            num_batches = int(all_num_samples / self.args.batch_size) + 1\n",
    "            \n",
    "            # all mask are then splited into mini-batch in order\n",
    "            all_mask = torch.arange(0, num_dim, dtype=torch.long)\n",
    "            \n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch+1) * self.args.batch_size, all_num_samples)\n",
    "                batch_nodes = all_mask[i_start:i_end]  # \n",
    "                batch_labels = homo_data.y[batch_nodes]\n",
    "                \n",
    "                # sampling neighbors of batch nodes\n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=self.args.batch_size)\n",
    "                \n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                \n",
    "                extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "                del pred\n",
    "                gc.collect()\n",
    "            # save_embeddings(extract_reatures, save_path_i)\n",
    "            # evaluate the model: conduct kMeans clustering on the validation and report NMI\n",
    "            validation_nmi = evaluate(extract_features[homo_data.val_mask],\n",
    "                                     homo_data.y,\n",
    "                                     epoch=epoch,\n",
    "                                     num_isolated_nodes=0,\n",
    "                                     save_path=save_path_i,\n",
    "                                     is_validation=True,\n",
    "                                     cluster_type=self.args.cluster_type)\n",
    "            all_vali_nmi.append(validation_nmi)\n",
    "            \n",
    "            # step16: early stop\n",
    "            if validation_nmi > best_vali_nmi:\n",
    "                best_vali_nmi = validation_nmi\n",
    "                best_epoch = epoch\n",
    "                wait = 0\n",
    "                # save model\n",
    "                model_path = save_path_i + '/models'\n",
    "                if (epoch == 0) and (not os.path.isdir(model_path)):\n",
    "                    os.mkdir(model_path)\n",
    "                p = model_path + '/best.pt'\n",
    "                torch.save(model.state_dict(), p)  # ‰øùÂ≠òÊ®°ÂûãÔºåOrderDictÂ≠òÂÇ®ÁΩëÁªúÁªìÊûÑÁöÑÂêçÂ≠óÂíåÂØπÂ∫îÁöÑÂèÇÊï∞\n",
    "                print('Best model saved after epoch ', str(epoch))\n",
    "            else:\n",
    "                wait += 1\n",
    "            if wait >= self.args.patience:\n",
    "                print('Saved all_mins_spent')\n",
    "                print('Early stopping at epoch ', str(epoch))\n",
    "                print('Best model was at epoch ', str(best_epoch))\n",
    "                break\n",
    "            # end one epoch\n",
    "        \n",
    "        # save all validation mi\n",
    "        np.save(save_path_i + '/all_vali_nmi.npy', np.asarray(all_vali_nmi))\n",
    "        # save time spent on epochs\n",
    "        np.save(save_path_i + '/mins_train_epochs.npy', np.asarray(mins_train_epochs))\n",
    "        print('Saved mins_train_epochs')\n",
    "        # save time spent on batches\n",
    "        np.save(save_path_i + '/seconds_train_batches.npy', np.asarray(seconds_train_batches))\n",
    "        print('Best model loaded.')\n",
    "        \n",
    "        del homo_data, multi_r_data\n",
    "        torch.cuda.empty_cache()  # ÈáäÊîæÊòæÂ≠ò\n",
    "        \n",
    "        return model, RL_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "24e986c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e48b2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2,43,2,42,12,454])[0]\n",
    "np.where(a<5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb96f8",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "142b5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilityÔºåÂäüËÉΩ\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dd4a1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰∫§ÈõÜ\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cd340",
   "metadata": {},
   "source": [
    "### run kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "76afe613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(extract_features, extract_labels, indices, isoPath=None):\n",
    "    # extract the features and labels of the test tweets\n",
    "    if isoPath is not None:\n",
    "        # Remove isolated points\n",
    "        temp = torch.load(isoPath)\n",
    "        temp = temp.cpu().detach().numpy()  # detach()ÈòªÊñ≠ÂèçÂêë‰º†Êí≠ÔºåËøîÂõûÂÄº‰∏∫tensorÔºõnumpy()Â∞ÜtensorËΩ¨Êç¢‰∏∫numpy\n",
    "        non_isolated_index = list(np.where(temp != 1)[0]) # np.whereËøîÂõûÁ¨¶ÂêàÊù°‰ª∂ÂÖÉÁ¥†ÁöÑÁ¥¢Âºïindex\n",
    "        indices = intersection(indices, non_isolated_index)  # Âèñ‰∫§ÈõÜ\n",
    "    # Extract labels\n",
    "    extract_labels = extract_labels.cpu().numpy()\n",
    "    labels_true = extract_labels[indices]\n",
    "    \n",
    "    # Extrac features\n",
    "    X = extract_features.cpu().detach().numpy()\n",
    "    assert labels_true.shape[0] == X.shape[0]  # assertÊñ≠Ë®ÄÔºåÂú®Âà§Êñ≠ÂºèfalseÊó∂Ëß¶ÂèëÂºÇÂ∏∏\n",
    "    n_test_tweets = X.shape[0]  # 100\n",
    "    \n",
    "    # Get the total number of classes\n",
    "    n_classes = len(set(labels_true.tolist()))  # unique()Âíånunique()‰∏çÈ¶ôÂêóÔºü\n",
    "    \n",
    "    # k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=0).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    nmi = metrics.normalized_mutual_info_score(labels_true, labels)  # ËÆ°ÁÆóÂΩí‰∏ÄÂåñ‰∫í‰ø°ÊÅØ\n",
    "    ami = metrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "    ari = metrics.adjusted_rand_score(labels_true, labels)  # ËÆ°ÁÆóÂÖ∞Âæ∑Á≥ªÊï∞\n",
    "    \n",
    "    # Return number of test tweets, number of classes covered by the test tweets, and KMeans clustering NMI\n",
    "    return n_test_tweets, n_classes, nmi, ami, ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c9b60",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b2f25",
   "metadata": {},
   "source": [
    "### metrics operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ce1718f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d7d6ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        raise NotImplementedError  # Ê≤°ÊúâÈáçÂÜôÔºåÂ∞±‰ºöÊä•Èîô\n",
    "    \n",
    "    def reset(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def value(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def name(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7a5ca",
   "metadata": {},
   "source": [
    "#### accumulate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "531135fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Á¥ØÂä†Âπ≥Âùámetrics\n",
    "class AccumulateAccuracy(Metric):\n",
    "    '''\n",
    "    works with classification model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        pred = outputs[0].data.max(1, keepdim=True)[1]\n",
    "        self.correct += pred.eq(target[0].data.view_as(pred)).cpu().sum()\n",
    "        self.total += target[0].size(0)\n",
    "        return self.value()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def value(self):\n",
    "        return 100 * float(self.correct) / self.total\n",
    "    \n",
    "    def name(self):\n",
    "        return 'Accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f913ab",
   "metadata": {},
   "source": [
    "#### average metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e64e0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÈùûÈõ∂Âπ≥Âùá\n",
    "class AverageNonzeroTripletsMetric(Metric):\n",
    "    '''\n",
    "    Counts average number of nonzero triplets found in minibatches\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.values = []\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        self.values.append(loss[1])\n",
    "        return self.value()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.values = []\n",
    "    \n",
    "    def value(self):\n",
    "        return np.mean(self.values)\n",
    "    \n",
    "    def name(self):\n",
    "        return 'Average nonzero triplets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1e24a",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "29dad01a",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def evaluate(extract_features, extract_labels, indices, epoch, num_isolated_nodes, save_path,\n",
    "             is_validation=True, cluster_type='kmeans'):\n",
    "    message = ''\n",
    "    message += '\\nEpoch '\n",
    "    message += str(epoch)\n",
    "    message += '\\n'\n",
    "    \n",
    "    # with isolated nodes\n",
    "    if cluster_type == 'kmeans':\n",
    "        n_tweets, n_classes, nmi, ami, ari = run_kmeans(extract_features, extract_labels, indices)\n",
    "    elif cluster_type == 'dbscan':\n",
    "        pass\n",
    "    \n",
    "    if is_validation:\n",
    "        mode = 'validation'\n",
    "    else:\n",
    "        mode = 'test'\n",
    "    message += '\\tNumber of ' + mode + ' tweets: '\n",
    "    message += str(n_tweets)\n",
    "    message += '\\n\\tNumber of classes covered by ' + mode + ' tweets: '\n",
    "    message += str(n_classes)\n",
    "    message += '\\n\\t' + mode + ' NMI: '\n",
    "    message += str(nmi)\n",
    "    message += '\\n\\t' + mode + 'AMi: '\n",
    "    message += str(ami)\n",
    "    message += '\\n\\t' + mode + 'ARI'\n",
    "    message += str(ari)\n",
    "    if cluster_type == 'dbscan':\n",
    "        message += '\\n\\t' + mode + ' best_eps: '\n",
    "        message += '\\n\\t' + mode + ' best_min_Pts: '\n",
    "    \n",
    "    if num_isolated_nodes != 0:\n",
    "        # without isolated nodes\n",
    "        message += '\\n\\tWithout isolated nodes:'\n",
    "        n_tweets, n_classes, nmi, ami, ari = run_kmeans(extract_features, extract_labels, indices, \n",
    "                                                       save_path + '/isolated_nodes.pt')\n",
    "        message += '\\tNumber of ' + mode + 'tweets: '\n",
    "        message += str(n_tweets)\n",
    "        message += '\\n\\tNumber of classes covered by ' + mode + ' tweets'\n",
    "        message += str(n_classes)\n",
    "        message += '\\n\\t' + mode + 'NMI: '\n",
    "        message += str(nmi)\n",
    "        message += '\\n\\t' + mode + 'AMI: '\n",
    "        message += str(ami)\n",
    "        message += '\\n\\t' + mode + 'ARI: '\n",
    "        message += str(ari)\n",
    "    message += '\\n'\n",
    "    \n",
    "    with open(save_path + '/evaluate.txt', 'a') as f:\n",
    "        f.write(message)\n",
    "    print(message)\n",
    "    \n",
    "    np.save(save_path + '/%s_metric.npy' % mode, np.asarray([nmi, ami, ari]))\n",
    "    if is_validation:\n",
    "        return nmi\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba64d0f",
   "metadata": {},
   "source": [
    "# Run_FinEvent_Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "step 1. run utils/generate_initial_features.py to generate the initial features for the messages\n",
    "\n",
    "step 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\n",
    "\n",
    "step 3. run utils/save_edge_index.py in advance to acclerate the training process.\n",
    "\n",
    "step 4. run main.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e0aff267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json  # ËΩªÈáèÁ∫ßÁöÑÊï∞ÊçÆ‰∫§Êç¢Ê†ºÂºèÔºåÊòì‰∫éÈòÖËØªÂíåÁºñÂÜô\n",
    "import argparse  # Áî®‰∫éÊõ¥Êñπ‰æøÂú∞ËøõË°åË∂ÖÂèÇÊï∞ÁöÑ‰øùÂ≠òÂíå‰øÆÊîπ\n",
    "import torch\n",
    "\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4b4b7",
   "metadata": {},
   "source": [
    "## set paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ccf6d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_epochs', default=50, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if performance did not improve in the last patience epochs.')\n",
    "    \n",
    "    parser.add_argument('--margin', default=3, type=float, help='Margin for computing triplet losses')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    \n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representations')\n",
    "    parser.add_argument('heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    parser.add_argument('--use_hardest_neg', dest='user_hardes_neg', default=False, action='store_true', \n",
    "                       help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=False)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms') # DBSCAN\n",
    "    \n",
    "    # RL-0\n",
    "    parser.add_argument('--threshod_start0', default=[[0.2],[0.2],[0.2]], type=float, \n",
    "                        help='The initial value of filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The step size of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--user_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default='./incremental_0502/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    args = parser.parse_args()  # Ëß£ÊûêÂèÇÊï∞\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbccc46",
   "metadata": {},
   "source": [
    "## run incremental_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "78c1f8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/offline dataset/'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "67e60b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "embedding save path:  D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/offline dataset//offline_embeddings\n",
      "Batch Size: 100\n",
      "Intra Agg Mode: False\n",
      "Inter Agg Mode: cat_w_avg\n",
      "Reserve node config? True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AverageNonzeroTriplesMetric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [415]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m OnlineTripletLoss(args\u001b[38;5;241m.\u001b[39mmargin, RandomNegativeTripletSelector(args\u001b[38;5;241m.\u001b[39mmargin))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# define metrics\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m BCL_metrics \u001b[38;5;241m=\u001b[39m [\u001b[43mAverageNonzeroTriplesMetric\u001b[49m()]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# define detection stage\u001b[39;00m\n\u001b[0;32m     39\u001b[0m Streaming \u001b[38;5;241m=\u001b[39m FinEvent(args)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AverageNonzeroTriplesMetric' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # define args\n",
    "    args = args_register()\n",
    "    \n",
    "    # check CUDA\n",
    "    print('Using CUDA:', torch.cuda.is_available())\n",
    "    \n",
    "    # create working path\n",
    "#     embedding_save_path = args.data_path + '/embeddings_' + strftime(\"%m%d%H%M%S\", localtime())\n",
    "    embedding_save_path = args.data_path + '/offline_embeddings'\n",
    "    os.mkdir(embedding_save_path)\n",
    "    print('embedding save path: ', embedding_save_path)\n",
    "    \n",
    "    # record hyper-parameters\n",
    "    with open(embedding_save_path + '/args.txt', 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)\n",
    "    \n",
    "    print('Batch Size:', args.batch_size)\n",
    "    print('Intra Agg Mode:', args.is_shared)\n",
    "    print('Inter Agg Mode:', args.inter_opt)\n",
    "    print('Reserve node config?', args.is_initial)\n",
    "    \n",
    "    # load number of messages in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    data_split = np.load(args.data_path + '/data_split.npy')\n",
    "    \n",
    "    # define loss function\n",
    "    # contrastive loss in our paper\n",
    "    if args.use_hardest_neg:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, HardestNegativeTripletSelector(args.margin))\n",
    "    else:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, RandomNegativeTripletSelector(args.margin))\n",
    "        \n",
    "    # define metrics\n",
    "    BCL_metrics = [AverageNonzeroTriplesMetric()]\n",
    "    \n",
    "    # define detection stage\n",
    "    Streaming = FinEvent(args)\n",
    "    \n",
    "    # pre-train stage: train on initial graph\n",
    "    train_i = 0\n",
    "    model, RL_thresholds = Streaming.initial_maintain(train_i = train_i,\n",
    "                                                     i = 0,\n",
    "                                                     metrics = BCL_metrics, \n",
    "                                                     embedding_save_path = embedding_save_path,\n",
    "                                                     loss_fn = loss_fn,\n",
    "                                                     model = None)\n",
    "    \n",
    "    # detection-maintenance stage: incremental training and detection\n",
    "    for i in range(1, data_split.shape[0]):\n",
    "        # infer every block\n",
    "        model = Streaming.inference(train_i=train_i,\n",
    "                                   i=i,\n",
    "                                   metrics=BCL_metrics,\n",
    "                                   embedding_save_path=embedding_save_path,\n",
    "                                   loss_fn=loss_fn,\n",
    "                                   model=model,\n",
    "                                   RL_thresholds=RL_thresholds)\n",
    "        \n",
    "        # maintenance in window size and desert the last block\n",
    "        if i % args.window_size == 0 and i != data_split.shape[0] -1:\n",
    "            model, RL_thresholds = Streaming.initial_maintain(train_i=train_i,\n",
    "                                                             i=i,\n",
    "                                                             metrics=BCL_metrics,\n",
    "                                                             embedding_save_path=embedding_save_path,\n",
    "                                                             loss_fn=loss_fn,\n",
    "                                                             model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823d054",
   "metadata": {},
   "source": [
    "# Run_FinEvent_Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fdaee841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstep 1. run utils/generate_initial_features.py to generate the initial features for the messages\\n\\nstep 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\\n\\nstep 3. run utils/save_edge_index.py in advance to acclerate the training process.\\n\\nstep 4. run offline.py\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "step 1. run utils/generate_initial_features.py to generate the initial features for the messages\n",
    "\n",
    "step 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\n",
    "\n",
    "step 3. run utils/save_edge_index.py in advance to acclerate the training process.\n",
    "\n",
    "step 4. run offline.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "802957b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from time import localtime, strftime  # strftime() ÂáΩÊï∞Áî®‰∫éÊ†ºÂºèÂåñÊó∂Èó¥ÔºåËøîÂõû‰ª•ÂèØËØªÂ≠óÁ¨¶‰∏≤Ë°®Á§∫ÁöÑÂΩìÂú∞Êó∂Èó¥\n",
    "\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import time \n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0185ca5",
   "metadata": {},
   "source": [
    "## define paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb42f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()  # ÂàõÂª∫ÂèÇÊï∞ÂØπË±°\n",
    "    # Ê∑ªÂä†ÂèÇÊï∞\n",
    "    parser.add_argument('--n_epochs', default=50, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if perfermance did not improve in the last patience epochs.')\n",
    "    parser.add_argument('--margin', default=3, type=float, help='Margin for computing triplet losses')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    \n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representation')\n",
    "    parser.add_argument('--heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    parser.add_argument('--use_hardest_neg', dest='use_hardest_neg', default=False, action='store_true', \n",
    "                        help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=True)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms') # DBSCAN\n",
    "    \n",
    "    # RL-0\n",
    "    parser.add_argument('--threshold_start0', default=[[0.2],[0.2],[0.2]], type=float, \n",
    "                        help='The initial value of the filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The starting epoch of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--use_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default=project_path + '/result/FinEvent result/offline dataset/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    \n",
    "    args = parser.parse_args(args=[])  # Ëß£ÊûêÂèÇÊï∞\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d36e98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bc9e0",
   "metadata": {},
   "source": [
    "## offline FinEvent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21115429",
   "metadata": {
    "code_folding": [
     171
    ]
   },
   "outputs": [],
   "source": [
    "def offline_FinEvent_model(train_i, i,\n",
    "                 args,\n",
    "                 metrics,\n",
    "                 embedding_save_path,\n",
    "                 loss_fn,\n",
    "                 model=None,\n",
    "                 loss_fn_dgi=None):\n",
    "    # step1: make dir for graph i\n",
    "    # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "    save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "    if not os.path.isdir(save_path_i):\n",
    "        os.mkdir(save_path_i)\n",
    "    \n",
    "    # step2: load data\n",
    "    relation_ids: List[str] = ['entity', 'userid', 'word']\n",
    "    homo_data = create_offline_homodataset(args.data_path, [train_i, i])\n",
    "    multi_r_data = create_multi_relational_graph(args.data_path, relation_ids, [train_i, i])\n",
    "    num_relations = len(multi_r_data)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and args.use_cuda else 'cpu')\n",
    "    \n",
    "    # input dimension (300 in our paper)\n",
    "    num_dim = homo_data.x.size(0)\n",
    "    feat_dim = homo_data.x.size(1)\n",
    "    \n",
    "    # prepare graph configs for node filtering\n",
    "    if args.is_initial:\n",
    "        print('prepare node configures...')\n",
    "        cal_similarity_node_edge(multi_r_data, homo_data.x, save_path_i)\n",
    "        filter_path = save_path_i\n",
    "    else:\n",
    "        filter_path = args.data_path + str(i)\n",
    "    \n",
    "    if model is None:  # pre-training stage in our paper\n",
    "        # print('Pre-Train Stage...')\n",
    "#         model = MarGNN((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "#                       num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "        model = HeteGAT_multi((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "    \n",
    "    # define sampler\n",
    "    sampler = MySampler(args.sampler)\n",
    "    # load model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # initialize RL thresholds\n",
    "    # RL_threshold: [[.5],[.5],[.5]]\n",
    "    RL_thresholds = torch.FloatTensor(args.threshold_start0)\n",
    "    \n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    \n",
    "    # record training log\n",
    "    message = '\\n------Start initial training /maintaining using block' + str(i) + '------\\n'\n",
    "    print(message)\n",
    "    with open(save_path_i + '/log.txt', 'a') as f:\n",
    "        f.write(message)\n",
    "    \n",
    "    # step12.0: record the highest validation nmi ever got for early stopping\n",
    "    best_vali_nmi = 1e-9\n",
    "    best_epoch = 0\n",
    "    wait = 0\n",
    "    # step12.1: record validation nmi of all epochs before early stop\n",
    "    all_vali_nmi = []\n",
    "    # step12.2: record the time spent in seconds on each batch of all training/maintaining epochs\n",
    "    seconds_train_batches = []\n",
    "    # step12.3: record the time spent in mins on each epoch\n",
    "    mins_train_epochs = []\n",
    "    \n",
    "    # step13: start training------------------------------------------------------------\n",
    "    print('----------------------------------training----------------------------')\n",
    "    for epoch in range(args.n_epochs):\n",
    "        start_epoch = time.time()\n",
    "        losses = []\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "        \n",
    "        # Multi-Agent\n",
    "        \n",
    "        # filter neighbor in adbvance to fit with neighbor sampling, return filtered neighbor index\n",
    "        if epoch >= args.RL_start0 and args.sampler == 'RL_sampler':\n",
    "            filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) \n",
    "        else:\n",
    "            filtered_multi_r_data = multi_r_data\n",
    "        \n",
    "        # step13.0: forward\n",
    "        model.train()\n",
    "        \n",
    "        #     data.train_mask, data.val_mask, data.test_mask = gen_offline_masks(len(labels))\n",
    "        train_num_samples, valid_num_samples, test_num_samples = homo_data.train_mask.size(0), homo_data.val_mask.size(0), homo_data.test_mask.size(0)\n",
    "        all_num_samples = train_num_samples + valid_num_samples + test_num_samples\n",
    "        \n",
    "        torch.save(homo_data.train_mask, save_path_i + '/train_mask.pt')\n",
    "        torch.save(homo_data.val_mask, save_path_i + '/valid_mask.pt')\n",
    "        torch.save(homo_data.test_mask, save_path_i + '/test_mask.pt')\n",
    "        \n",
    "        # mini-batch training\n",
    "        num_batches = int(train_num_samples / args.batch_size) + 1\n",
    "        for batch in range(num_batches):\n",
    "            start_batch = time.time()\n",
    "            # split batch\n",
    "            i_start = args.batch_size * batch\n",
    "            i_end = min((batch + 1) * args.batch_size, train_num_samples)\n",
    "            batch_nodes = homo_data.train_mask[i_start:i_end]\n",
    "            batch_labels = homo_data.y[batch_nodes]\n",
    "            \n",
    "            # sampling neighbors of batch nodes\n",
    "            adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1],batch_size=args.batch_size)\n",
    "            \n",
    "            optimizer.zero_grad()  # Â∞ÜÂèÇÊï∞ÁΩÆ0\n",
    "            \n",
    "            pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "            \n",
    "            loss_outputs = loss_fn(pred, batch_labels)\n",
    "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # step13.1: metrics\n",
    "            for metric in metrics:\n",
    "                metric(pred, batch_labels, loss_outputs)\n",
    "            if batch % args.log_interval == 0:\n",
    "                message = 'Train: [{}/{} ({:.0f}%)] \\tloss: {:.6f}'.format(batch * args.batch_size, train_num_samples,\n",
    "                          100. * batch / ((train_num_samples // args.batch_size) + 1), np.mean(losses))\n",
    "                for metric in metrics:\n",
    "                    message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "                # print(message)\n",
    "                with open(save_path_i + '.log.txt', 'a') as f:\n",
    "                    f.write(message)\n",
    "                losses = []\n",
    "            \n",
    "            # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "            del pred, loss_outputs\n",
    "            gc.collect()\n",
    "            \n",
    "            # step13.2: backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_seconds_spent = time.time() - start_batch\n",
    "            seconds_train_batches.append(batch_seconds_spent)\n",
    "            \n",
    "            del loss\n",
    "            gc.collect()\n",
    "        \n",
    "        # step14: print loss\n",
    "        total_loss /= (batch + 1)\n",
    "        message = 'Epoch: {}/{}. Average loss: {:.4f}'.format(epoch, args.n_epochs, total_loss)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "        mins_spent = (time.time() - start_epoch) / 60\n",
    "        message += '\\nThis epoch took {:.2f} mins'.format(mins_spent)\n",
    "        message += '\\n'\n",
    "        print(message)\n",
    "        with open(save_path_i + '/log.txt', 'a') as f:\n",
    "            f.write(message)\n",
    "        mins_train_epochs.append(mins_spent)\n",
    "        \n",
    "        # step15: validation--------------------------------------------------------\n",
    "        print('---------------------validation-------------------------------------')\n",
    "        # inder the representations of all tweets\n",
    "        model.eval()\n",
    "        \n",
    "        # we recommend to forward all nodes and select the validation indices instead\n",
    "        extract_features = torch.FloatTensor([])\n",
    "        num_batches = int(all_num_samples / args.batch_size) + 1\n",
    "        \n",
    "        # all mask are then splited into mini-batch in order\n",
    "        all_mask = torch.arange(0, num_dim, dtype=torch.long)\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            start_batch = time.time()\n",
    "            \n",
    "            # split batch\n",
    "            i_start = args.batch_size * batch\n",
    "            i_end = min((batch + 1) * args.batch_size, all_num_samples)\n",
    "            batch_nodes = all_mask[i_start:i_end]\n",
    "            \n",
    "            # sampling neighbors of batch nodes\n",
    "            adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=args.batch_size)\n",
    "            \n",
    "            pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "            \n",
    "            extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "            \n",
    "            del pred\n",
    "            gc.collect()\n",
    "        \n",
    "        # evaluate the model: conduct kMeans clustering on the validation and report NMI\n",
    "        validation_nmi = evaluate(extract_features[homo_data.val_mask],\n",
    "                                 homo_data.y,\n",
    "                                 indices=homo_data.val_mask,\n",
    "                                 epoch=epoch,\n",
    "                                 num_isolated_nodes=0,\n",
    "                                 save_path=save_path_i,\n",
    "                                 is_validation=True,\n",
    "                                 cluster_type=args.cluster_type)\n",
    "        all_vali_nmi.append(validation_nmi)\n",
    "        \n",
    "        # step16: early stop\n",
    "        if validation_nmi > best_vali_nmi:\n",
    "            best_vali_nmi = validation_nmi\n",
    "            best_epoch = epoch\n",
    "            wait = 0\n",
    "            # save model\n",
    "            model_path = save_path_i + '/models'\n",
    "            if (epoch == 0) and (not os.path.isdir(model_path)):\n",
    "                os.mkdir(model_path)\n",
    "            p = model_path + '/best.pt'\n",
    "            torch.save(model.state_dict(), p)\n",
    "            print('Best model was at epoch ', str(best_epoch))\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait >= args.patience:\n",
    "            print('Saved all_mins_spent')\n",
    "            print('Early stopping at epoch ', str(epoch))\n",
    "            print('Best model was at epoch ', str(best_epoch))\n",
    "            break\n",
    "        # end one epoch\n",
    "    \n",
    "    # step17: save all validation nmi\n",
    "    np.save(save_path_i + '/all_vali_nmi.npy', np.asarray(all_vali_nmi))\n",
    "    # save time spent on epochs\n",
    "    np.save(save_path_i + '/mins_train_epochs.npy', np.asarray(mins_train_epochs))\n",
    "    print('Saved mins_train_epochs.')\n",
    "    # save time spent on batches\n",
    "    np.save(save_path_i + '/seconds_train_batches.npy', np.asarray(seconds_train_batches))\n",
    "    print('Saved seconds_train_batches.')\n",
    "    \n",
    "    # step18: load the best model of the current block\n",
    "    best_model_path = save_path_i + '/models/best.pt'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print('Best model loaded.')\n",
    "    \n",
    "    # del homo_data, multi_r_data\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test--------------------------------------------------------\n",
    "    print('--------------------test----------------------------')\n",
    "    model.eval()\n",
    "    \n",
    "    # we recommend to forward all nodes and select the validation indices instead\n",
    "    extract_features = torch.FloatTensor([])\n",
    "    num_batches = int(all_num_samples /args.batch_size) + 1\n",
    "    \n",
    "    # all mask are then splited into mini-batch in order\n",
    "    all_mask = torch.arange(0, num_dim, dtype= torch.long)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        start_batch = time.time()\n",
    "        \n",
    "        # split batch\n",
    "        i_start = args.batch_size * batch\n",
    "        i_end = min((batch +1) * args.batch_size, all_num_samples)\n",
    "        batch_nodes = all_mask[i_start:i_end]\n",
    "        batch_labels = homo_data.y[batch_nodes]\n",
    "        \n",
    "        # sampling neighbors of batch nodes\n",
    "        adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=args.batch_size)\n",
    "        \n",
    "        pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "        \n",
    "        extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "        del pred\n",
    "        gc.collect()\n",
    "        \n",
    "    save_embeddings(extract_features, save_path_i)\n",
    "    \n",
    "    test_nmi = evaluate(extract_features[homo_data.test_mask],\n",
    "                       homo_data.y,\n",
    "                       indices=homo_data.test_mask,\n",
    "                       epoch=-1,\n",
    "                       num_isolated_nodes=0,\n",
    "                       save_path=save_path_i,\n",
    "                       is_validation=False,\n",
    "                       cluster_type=args.cluster_type)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f7d87",
   "metadata": {},
   "source": [
    "## run offline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c71060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "embedding save path:  D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/offline dataset//offline_embeddings\n",
      "Batch Size: 100\n",
      "Intra Agg Mode: False\n",
      "Inter Agg Mode: cat_w_avg\n",
      "Reserve node config? True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OnlineTripletLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m OnlineTripletLoss(args\u001b[38;5;241m.\u001b[39mmargin, HardestNegativeTripletSelector(args\u001b[38;5;241m.\u001b[39mmargin))  \u001b[38;5;66;03m# margin used for computing tripletloss\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[43mOnlineTripletLoss\u001b[49m(args\u001b[38;5;241m.\u001b[39mmargin, RandomNegativeTripletSelector(args\u001b[38;5;241m.\u001b[39mmargin))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# define metrics\u001b[39;00m\n\u001b[0;32m     34\u001b[0m BCL_metrics \u001b[38;5;241m=\u001b[39m [AverageNonzeroTripletsMetric()]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OnlineTripletLoss' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # define args\n",
    "    args = args_register()\n",
    "    \n",
    "    # check CUDA\n",
    "    print('Using CUDA:', torch.cuda.is_available())\n",
    "    \n",
    "    # create working path\n",
    "    embedding_save_path = args.data_path + '/offline_embeddings'\n",
    "    if embedding_save_path is None:\n",
    "        os.mkdir(embedding_save_path)\n",
    "    print('embedding save path: ', embedding_save_path)\n",
    "        \n",
    "    # record hyper-parameters\n",
    "    with open(embedding_save_path + '/args.txt', 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)  # __dict__Â∞ÜÊ®°ÂûãÂèÇÊï∞‰øùÂ≠òÊàêÂ≠óÂÖ∏ÂΩ¢ÂºèÔºõindentÁº©ËøõÊâìÂç∞\n",
    "    \n",
    "    print('Batch Size:', args.batch_size)\n",
    "    print('Intra Agg Mode:', args.is_shared)\n",
    "    print('Inter Agg Mode:', args.inter_opt)\n",
    "    print('Reserve node config?', args.is_initial)\n",
    "    \n",
    "    # load number of message in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    # define loss functionÔºåË∞ÉÁî®forward(embeddings, labels)ÊñπÊ≥ïÔºåÊúÄÁªàlossËøîÂõûÂçï‰∏™ÂÄº\n",
    "    # contrastive loss in our paper\n",
    "    if args.use_hardest_neg:\n",
    "        # HardestNegativeTripletSelectorËøîÂõûÊüêÊ†áÁ≠æ‰∏ãithÂÖÉÁ¥†ÂíåjthÂÖÉÁ¥†ÔºåÂÖ∂ÊúÄÂ§ßlossÂØπÂ∫îÁöÑÂÖ∂‰ªñÊ†áÁ≠æÂÖÉÁ¥†Á¥¢Âºï\n",
    "        loss_fn = OnlineTripletLoss(args.margin, HardestNegativeTripletSelector(args.margin))  # margin used for computing tripletloss\n",
    "    else:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, RandomNegativeTripletSelector(args.margin))\n",
    "    # define metrics\n",
    "    BCL_metrics = [AverageNonzeroTripletsMetric()]\n",
    "    # define detection stage\n",
    "    Streaming = FinEvent(args)\n",
    "    # pre-train stage: train on initial graph\n",
    "    train_i = 0\n",
    "    model, RL_thresholds = offline_FinEvent_model(train_i=train_i,\n",
    "                                        args=args,\n",
    "                                        i=0,\n",
    "                                        metrics=BCL_metrics,\n",
    "                                        embedding_save_path=embedding_save_path,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee907c5",
   "metadata": {},
   "source": [
    "# Run_FinEvent_Cross-lingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8e4c0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f7b8d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n_epochs', default=50, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if performance did not improve in the last patience epochs.')\n",
    "    parser.add_argument('--margin', default=3., type=float, help='Margin for computing triplet losses')\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    \n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representations')\n",
    "    parser.add_argument('--heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    \n",
    "    parser.add_argument('--use_hardest_neg', dest='use_hardest_neg', default=False, action='store_true', \n",
    "                       help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=False)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms')  # DBSCAN\n",
    "    \n",
    "    # RL-0\n",
    "    parser.add_argument('--threshold_start0', default=[[0.5],[0.5],[0.5]], type=float, \n",
    "                        help='The initial value of the filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The step size of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--use_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default='./incremental_0502/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--resume_path', default='incremental_cross_English_68841/', type=str, \n",
    "                       help='Resume trained model and directly used to inference')\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    args = parser.parse_args(args=[])  # Ëß£ÊûêÂèÇÊï∞\n",
    "    \n",
    "    return args"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
