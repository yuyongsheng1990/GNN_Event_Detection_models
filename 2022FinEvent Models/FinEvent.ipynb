{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b839b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsettings:\\n    matplotlib==3.5.1\\n    networkx==2.6.3\\n    numpy==1.22.0\\n    pandas==1.3.5\\n    scikit-learn==1.0.1\\n    scipy==1.7.3\\n    torch==1.10.0\\n    torch-cluster==1.5.9\\n    torch-geometric==2.0.2\\n    torch-scatter==2.0.9\\n    torch-sparse==0.6.12\\n    torch-spline-conv==1.2.1\\n    tqdm==4.62.3\\n    dgl==0.4.3\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "2022.10.6，复现FinEvent Model\n",
    "paper: from Reinforced, Incremental and Cross-lingual Event Detection From Social Messages\n",
    "github address: https://github.com/RingBDStack/FinEvent\n",
    "'''\n",
    "'''\n",
    "settings:\n",
    "    matplotlib==3.5.1\n",
    "    networkx==2.6.3\n",
    "    numpy==1.22.0\n",
    "    pandas==1.3.5\n",
    "    scikit-learn==1.0.1\n",
    "    scipy==1.7.3\n",
    "    torch==1.10.0\n",
    "    torch-cluster==1.5.9\n",
    "    torch-geometric==2.0.2\n",
    "    torch-scatter==2.0.9\n",
    "    torch-sparse==0.6.12\n",
    "    torch-spline-conv==1.2.1\n",
    "    tqdm==4.62.3\n",
    "    dgl==0.4.3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cec4d43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "project_path = os.path.abspath(os.path.dirname(os.getcwd()))  # # 获取上级路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e88b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27c2f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec3b46",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## construct message graph functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4a07ad4c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis file splits the Twitter dataset into 21 message blocks (please see Section 4.3 of the paper for more details), \\nuse the message blocks to construct heterogeneous social graphs (please see Figure 1(a) and Section 3.2 of the paper for more details) \\nand maps them into homogeneous message graphs (Figure 1(c)).\\nNote that:\\n# 1) We adopt the Latest Message Strategy (which is the most efficient and gives the strongest performance. See Section 4.4 of the paper for more details) here, \\n# as a consequence, each message graph only contains the messages of the date and all previous messages are removed from the graph;\\n# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)' inside construct_incremental_dataset_0922().\\n# 2) For test purpose, when calling construct_incremental_dataset_0922(), set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\\n# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\\n\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct incremental message graphs\n",
    "'''\n",
    "This file splits the Twitter dataset into 21 message blocks (please see Section 4.3 of the paper for more details), \n",
    "use the message blocks to construct heterogeneous social graphs (please see Figure 1(a) and Section 3.2 of the paper for more details) \n",
    "and maps them into homogeneous message graphs (Figure 1(c)).\n",
    "Note that:\n",
    "# 1) We adopt the Latest Message Strategy (which is the most efficient and gives the strongest performance. See Section 4.4 of the paper for more details) here, \n",
    "# as a consequence, each message graph only contains the messages of the date and all previous messages are removed from the graph;\n",
    "# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)' inside construct_incremental_dataset_0922().\n",
    "# 2) For test purpose, when calling construct_incremental_dataset_0922(), set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\n",
    "# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f00bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### graph examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b2e59d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from scipy import sparse\n",
    "\n",
    "from time import time\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4d845505",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "tweet_list = ['t_123', 't_456', 't_789']\n",
    "G.add_nodes_from(tweet_list)\n",
    "for i in tweet_list:\n",
    "    G.nodes[i]['tweet_id'] = True\n",
    "user_list = ['Sydney', 'Beijing', 'Melbourne']\n",
    "entity_list = ['me', 'bing', 'zhen']\n",
    "G.add_nodes_from(user_list)\n",
    "G.add_nodes_from(entity_list)\n",
    "\n",
    "for i in entity_list:\n",
    "    G.nodes[i]['entity_id'] = True\n",
    "for i in user_list:\n",
    "    G.nodes[i]['user_id'] = True\n",
    "G.add_edges_from([['t_123', 't_456'],['t_123', 't_789'], ['t_123', 'Sydney'], ['t_456', 'Melbourne'], ['t_456', 'Beijing']])\n",
    "G.add_edges_from([['t_123', 'me'], ['t_123', 'bing'], ['t_789', 'zhen']])\n",
    "G.nodes['t_123']['tweet_id'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4acf4b2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "05bc32c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t_123', 't_456', 't_789'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.get_node_attributes(G, 'tweet_id').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec4da07d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweet_id和user_id结构关系\n",
    "tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
    "userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys())\n",
    "all_nodes = list(G.nodes)\n",
    "indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
    "indices_userid = [all_nodes.index(x) for x in userid_nodes]\n",
    "A = nx.to_numpy_matrix(G)\n",
    "w_tid_userid = A[np.ix_(indices_tid, indices_userid)]\n",
    "s_w_tid_userid = sparse.csr_matrix(w_tid_userid)\n",
    "s_w_userid_tid = s_w_tid_userid.transpose()\n",
    "homo_s_w_tid_userid = s_w_tid_userid * s_w_userid_tid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7482c677",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 2., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homo_s_w_tid_userid.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d2918594",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# tweet_id和entity 结构关系\n",
    "tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys())\n",
    "entity_nodes = list(nx.get_node_attributes(G, 'entity_id').keys())\n",
    "all_nodes = list(G.nodes)\n",
    "indices_tid = [all_nodes.index(x) for x in tid_nodes]\n",
    "indices_entityid = [all_nodes.index(x) for x in entity_nodes]\n",
    "A = nx.to_numpy_matrix(G)\n",
    "w_tid_userid = A[np.ix_(indices_tid, indices_entityid)]\n",
    "s_w_tid_userid = sparse.csr_matrix(w_tid_userid)\n",
    "s_w_userid_tid = s_w_tid_userid.transpose()\n",
    "homo_s_w_tid_entityid = s_w_tid_userid * s_w_userid_tid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173516d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5139d076",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse.tensor import SparseTensor\n",
    "# from .utils import generateMasks, gen_offline_masks，是指从utils.py文件中导入函数: generatemasks, gen_offline_masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0042b2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def coo_trans(datapath = None):\n",
    "    relation: csr_matrix = sparse.load_npz(datapath)\n",
    "    relation: coo_matrix = relation.tocoo()\n",
    "    sparse_edge_index = torch.LongTensor([relation.row, relation.col])  # sparse稀疏矩阵用三元组(row,col,data)来存储非零元素信息\n",
    "    return sparse_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "877b03ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(loadpath, relation, mode):\n",
    "    features = np.load(os.path.join(loadpath, str(mode[1]), 'features_embeddings.npy'))\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features laoded')\n",
    "    labels = np.load(os.path.join(loadpath, str(mode[1]), 'sorted_labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    relation_edge_index = coo_trans(os.path.join(loadpath, str(mode[1]), 's_m_tid_%s_tid.npz' % relation))\n",
    "    print('edge index laoded')\n",
    "    data = Data(x=features, edge_index=relation_edge_index, y=labels)\n",
    "    data_split = np.load(os.path.join(loadpath, 'data_split.npy'))\n",
    "    train_i, i = mode[0], mode[1]\n",
    "    if train_i == i:\n",
    "        data.train_mask, data.val_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    else:\n",
    "        data.test_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a1430",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### construct heterogeneous graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc6c99e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# construct a heterogeneous graph using tweet ids, user_ids, entities and rare(sampled) words(4 modalities模态)\n",
    "# if G is not None then insert new nodes to G\n",
    "# 创建heterogeneous graph\n",
    "def construct_graph_from_df(df, G=None):  # df: (11971, 18)\n",
    "    if G is None:\n",
    "        G = nx.Graph()  # 创建无向图\n",
    "    for _, row in df.iterrows():  # 返回可迭代元组(index,row)\n",
    "        # 1st modality: tweet_id\n",
    "        tid = 't_' + str(row['tweet_id'])  # 't_256292946331181056'\n",
    "        G.add_node(tid) # 一次添加一个节点，字符串作为节点id\n",
    "        G.nodes[tid]['tweet_id'] = True  # 设置节点属性；right-hand side value is irrelevant for the lookup\n",
    "        \n",
    "        # 2nd modality: user_id\n",
    "        user_ids = row['user_mentions']  # list.apend(str), [250870763]\n",
    "        user_ids.append(row['user_id'])\n",
    "        user_ids = ['u_' + str(each) for each in user_ids]\n",
    "        G.add_nodes_from(user_ids) # 添加多个节点\n",
    "        for each in user_ids:\n",
    "            G.nodes[each]['user_id'] = True \n",
    "        \n",
    "        # 3rd modality: entities\n",
    "        entities = row['entities']  # 命名实体识别的实体\n",
    "#         words = ['e_' + each for each in entities]\n",
    "        G.add_nodes_from(entities)\n",
    "        for each in entities:\n",
    "            G.nodes[each]['entity'] = True\n",
    "        \n",
    "        # 4th modality:sampled_words\n",
    "        words = row['sampled_words']\n",
    "        words = ['w_' + each for each in words]\n",
    "        G.add_nodes_from(words)\n",
    "        for each in words:\n",
    "            G.nodes[each]['word'] = True\n",
    "        \n",
    "        # 将each tweet message与user、entity、words相连\n",
    "        edges =[]\n",
    "        edges += [(tid, each) for each in user_ids]\n",
    "        edges += [(tid, each) for each in entities]\n",
    "        edges += [(tid, each) for each in words]\n",
    "        G.add_edges_from(edges) # 同时添加多条边\n",
    "    return G  # 30427 nodes and 40238 edges,因为以tweet_id为主，加上user_id, entities, words共有30427个"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b15f26",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### converting hete-graph to homo-graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "767a10d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert a heterogeneous social graph G to a homogeneous message graph following eq. 1 of the paper, \n",
    "# and store the sparse binary adjacency matrix of the homogeneous message graph.\n",
    "# DGL(Deep Graph Library)构建更高效的图神经网络\n",
    "\n",
    "def dgl_hetegraph_to_homograph(G, save_path=None):\n",
    "    '''\n",
    "    doc_embeddings: (11971, 302)\n",
    "    df: (11971, 18)\n",
    "    30427 nodes and 40238 edges,因为以tweet_id为主，加上user_id, entities, words共有30427个\n",
    "    '''\n",
    "    message = ''\n",
    "    print('Start converting heterogeneous networks graph to homogeneous dgl graph.')\n",
    "    message += 'Start converting heterogeneous networks graph to homogeneous dgl graph.\\n'\n",
    "    all_start = time()\n",
    "    \n",
    "    print('\\tGetting a list of all nodes ...')\n",
    "    message += '\\tGetting a list of all nodes ...\\n'\n",
    "    start = time()\n",
    "    all_nodes = list(G.nodes)  # 30427个\n",
    "    mins = (time() - start) /60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\tGetting adjacency matrix ...')\n",
    "    message += '\\tGetting adjacency matrix ...\\n'\n",
    "    start = time()\n",
    "    A = nx.to_numpy_matrix(G) # Returns the graph adjacency matrix as a Numpy matrix, 整体异构图邻接矩阵，(30427, 30427)\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # compute commuting matrices\n",
    "    print('\\tGetting lists of nodes of various types ...')\n",
    "    message += '\\tGetting lists of nodes of various types ...\\n'\n",
    "    start = time()\n",
    "    \n",
    "    # all_nodes: 30427个\n",
    "    # tweet_id,list, 11971个,['t_255819992157786112', 't_255820118095978496', 't_255820147489636353', 't_255820164023595008',...]\n",
    "    tid_nodes = list(nx.get_node_attributes(G, 'tweet_id').keys()) # get_node_attributes return node and its attributes;获得tweet_id列表\n",
    "    userid_nodes = list(nx.get_node_attributes(G, 'user_id').keys()) # 同理，获得user_id列表，11520个\n",
    "    word_nodes = list(nx.get_node_attributes(G, 'word').keys())      # 1535个\n",
    "    entity_nodes = list(nx.get_node_attributes(G, 'entity').keys())  # 5401个\n",
    "    del G  # 删除original 无向图\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # 将节点转换成all_nodes中的索引index\n",
    "    print('\\tConverting node lists to index lists ...')\n",
    "    message += '\\tConverting node lists to index lists ...\\n'\n",
    "    start = time()\n",
    "    # fine细化 the index of target nodes in the list of all nodes\n",
    "    indices_tid = [all_nodes.index(x) for x in tid_nodes]        # 11971\n",
    "    indices_userid = [all_nodes.index(x) for x in userid_nodes]  # 11520\n",
    "    indices_word = [all_nodes.index(x) for x in word_nodes]      # 1535\n",
    "    indices_entity = [all_nodes.index(x) for x in entity_nodes]  # 5401\n",
    "    del tid_nodes\n",
    "    del userid_nodes\n",
    "    del word_nodes\n",
    "    del entity_nodes\n",
    "    mins = (time() -start)/60\n",
    "    print('\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # ----------------tweet-user-tweet------------------\n",
    "    print('\\tStart constructing tweet-user-tweet commuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-user matrix ...')\n",
    "    message += '\\tStart constructing tweet-user-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-user matrix ...\\n'\n",
    "    start = time()\n",
    "    # 笛卡尔积实际上是生成一个二维坐标矩阵，其作用是从A中抽取出x和y这两类节点的一个子邻接矩阵\n",
    "    w_tid_userid = A[np.ix_(indices_tid, indices_userid)]  # np.ix_(list1, list2)生成一个笛卡尔积的映射关系；（11971， 11520）\n",
    "    # return a N(indiced_tid)*N(indices_userid) matrix, representing the weight of edges between tid and userid\n",
    "    mins = (time() - start)/60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
    "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    # 其实就是将邻接矩阵转换成稀疏矩阵。matrix compression，节省内存\n",
    "    s_w_tid_userid = sparse.csr_matrix(w_tid_userid)  # s代表sparse，(11971, 11520)\n",
    "    del w_tid_userid\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_userid_tid = s_w_tid_userid.transpose()  # 转置\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-user * user-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-user * user-tweet ...\\n'\n",
    "    start = time()\n",
    "    '''\n",
    "    将meta-path: tweet-user-tweet转换成tweet-tweet矩阵，这样才能得到tweet_id0的直接邻居节点tweet_id1,2,3...，不用再隔着user关系。\n",
    "    '''\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_userid_tid = s_w_tid_userid * s_w_userid_tid #  根据user_id生成tweet_id homogeneous message graph\n",
    "    mins = (time() - start)/ 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_userid_tid_matrix.npz\", s_m_tid_userid_tid)\n",
    "        print('sparse binary userid commuting matrix saved.')\n",
    "        del s_m_tid_userid_tid\n",
    "    del s_w_tid_userid\n",
    "    del s_w_userid_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # ----------tweet-ent-tweet-----------------\n",
    "    print('\\tStart constructing tweet-ent-tweet conmuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-ent matrix ...')\n",
    "    message += '\\tStart constructing tweet-ent-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-ent matrix ...\\n'\n",
    "    start = time()\n",
    "    w_tid_entity = A[np.ix_(indices_tid, indices_entity)]  # 抽取tweet_id和entity的邻接矩阵，(11971，5401)\n",
    "    mins = (time() - start) / 60\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to sparse matrix ...')\n",
    "    message += '\\t\\t\\tConver ting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_entity = sparse.csr_matrix(w_tid_entity)  # 邻接矩阵转换成csr稀疏矩阵\n",
    "    del w_tid_entity\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed : ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_entity_tid = s_w_tid_entity.transpose()  # 转置，(5401, 11971)\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-ent * ent-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-ent * ent-tweet ...\\n'\n",
    "    start = time()\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_entity_tid = s_w_tid_entity * s_w_entity_tid  # 根据entity生成tweet_id homogeneous message graph\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_entity_tid_matrix.npz\", s_m_tid_entity_tid)\n",
    "        print('Sparse binary entity commuting matrix saved.')\n",
    "        del s_m_tid_entity_tid\n",
    "    del s_w_tid_entity\n",
    "    del s_w_entity_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # --------tweet-word-tweet------------------\n",
    "    print('\\tStart constructing tweet-word-tweet commuting matrix ...')\n",
    "    print('\\t\\t\\tStart constructing tweet-word matrix ...')\n",
    "    message +='\\tStart constructing tweet-wrod-tweet commuting matrix ...\\n\\t\\t\\tStart constructing tweet-word matrix ...'\n",
    "    start = time()\n",
    "    w_tid_word = A[np.ix_(indices_tid, indices_word)]  # (11971, 1535)\n",
    "    del A\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # convert to scipy sparse matrix\n",
    "    print('\\t\\t\\tConverting to Sparse matrix ...')\n",
    "    message += '\\t\\t\\tConverting to sparse matrix ...\\n'\n",
    "    start = time()\n",
    "    s_w_tid_word = sparse.csr_matrix(w_tid_word)  # tweet_id和word稀疏矩阵\n",
    "    del w_tid_word\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tTransposing ...')\n",
    "    message += '\\t\\t\\tTransposing ...\\n'\n",
    "    start = time()\n",
    "    s_w_word_tid = s_w_tid_word.transpose()  # 转置，（1535,11971）\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tCalculating tweet-word * word-tweet ...')\n",
    "    message += '\\t\\t\\tCalculating tweet-word * word-tweet ...\\n'\n",
    "    start = time()\n",
    "    # csr_matrix, (11971, 11971)\n",
    "    s_m_tid_word_tid = s_w_tid_word * s_w_word_tid  # 根据word生成的tweet_id homogeneous message graph\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    print('\\t\\t\\tSaving ...')\n",
    "    message += '\\t\\t\\tSaving ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_m_tid_word_tid_matrix.npz\", s_m_tid_word_tid)\n",
    "        print(\"Sparse binary word commuting matrix saved.\")\n",
    "        del s_m_tid_word_tid\n",
    "    del s_w_tid_word\n",
    "    del s_w_word_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    # -----------compute tweet-tweet adjacency matrix --------\n",
    "    print('\\tComputing tweet-tweet adjacency matrix ...')\n",
    "    message += '\\tComputing tweet-tweet adjacency matrix ...\\n'\n",
    "    start = time()\n",
    "    if save_path is not None:\n",
    "        s_m_tid_userid_tid = sparse.load_npz(save_path + 's_m_tid_userid_tid_matrix.npz')\n",
    "        print(\"Sparse binary userid commuting matrix loaded.\")\n",
    "        s_m_tid_entity_tid = sparse.load_npz(save_path + \"s_m_tid_entity_tid_matrix.npz\")\n",
    "        print(\"Sparse binary entity commuting matrix loaded.\")\n",
    "        s_m_tid_word_tid = sparse.load_npz(save_path + \"s_m_tid_word_tid_matrix.npz\")\n",
    "        print(\"Sparse binary word commuting matrix loaded.\")\n",
    "    \n",
    "    # 合并三个user_id, entity, word生成的tweet_id homogeneous graph\n",
    "    s_A_tid_tid = s_m_tid_userid_tid + s_m_tid_entity_tid\n",
    "    del s_m_tid_userid_tid\n",
    "    del s_m_tid_entity_tid\n",
    "    # confirm the connect between tweets\n",
    "    s_bool_A_tid_tid = (s_A_tid_tid + s_m_tid_word_tid).astype('bool')  # csr_matrix, (11971, 11971)\n",
    "    del s_m_tid_word_tid\n",
    "    del s_A_tid_tid\n",
    "    mins = (time() - start) / 60\n",
    "    print('\\t\\t\\tDone. Time elapsed: ', mins, ' mins\\n')\n",
    "    message += '\\t\\t\\tDone. Time elapsed: '\n",
    "    message += str(mins)\n",
    "    message += ' mins\\n'\n",
    "    all_mins = (time() - all_start) / 60\n",
    "    print('\\tOver all time elapsed: ', all_mins, ' mins\\n')\n",
    "    message += '\\tOver all time elapsed: '\n",
    "    message += str(all_mins)\n",
    "    message += ' mins\\n'\n",
    "    \n",
    "    if save_path is not None:\n",
    "        sparse.save_npz(save_path + \"s_bool_A_tid_tid_matrix.npz\", s_bool_A_tid_tid)\n",
    "        print(\"Sparse binary adjacency matrix saved.\")\n",
    "        s_bool_A_tid_tid = sparse.load_npz(save_path + \"s_bool_A_tid_tid_matrix.npz\")\n",
    "        print(\"Sparse binary adjacency matrix loaded.\")\n",
    "        \n",
    "    # create correspoinding dgl graph\n",
    "    G = dgl.DGLGraph(s_bool_A_tid_tid)  # 传入稀疏矩阵，转换成图,DGLHeteroGraph:11971，nodes=11971；edges=3825369\n",
    "    print('We have %d nodes.' % G.number_of_nodes())\n",
    "    print('We have %d edges' % G.number_of_edges())\n",
    "    print()\n",
    "    message += 'We have '\n",
    "    message += str(G.number_of_nodes())\n",
    "    message += ' nodes.'\n",
    "    message += 'We have '\n",
    "    message += str(G.number_of_edges())\n",
    "    message += ' edges.\\n'\n",
    "    \n",
    "    return all_mins, message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc07d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35e483",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### offline dataset: 4days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7dab4bb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7b34c1e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load_path = project_path + '/data/FinEvent_datasets/raw dataset/'\n",
    "save_path = project_path + '/result/FinEvent result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e6560832",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\GNN_Event_Detection_models/data/FinEvent_datasets/raw dataset/\n",
      "D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/\n"
     ]
    }
   ],
   "source": [
    "print(load_path)\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cd22719",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Data converted to dataframe.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "offline_dataset_savepath = project_path + '/result/FinEvent result/offline dataset/'\n",
    "if not os.path.exists(offline_dataset_savepath):\n",
    "    os.mkdir(offline_dataset_savepath)\n",
    "\n",
    "# load data (68841 tweets, multiclasses filtered)\n",
    "p_part1 = load_path + '68841_tweets_multiclasses_filtered_0722_part1.npy'\n",
    "p_part2 = load_path + '68841_tweets_multiclasses_filtered_0722_part2.npy'\n",
    "# allow_pickle: 可选，布尔值，允许使用 Python pickles 保存对象数组，Python 中的 pickle 用于在保存到磁盘文件或从磁盘文件读取之前，对对象进行序列化和反序列化。\n",
    "np_part1 = np.load(p_part1, allow_pickle=True)   # (35000, 16)\n",
    "np_part2 = np.load(p_part2, allow_pickle=True)   # (33841, 16)\n",
    "\n",
    "np_tweets = np.concatenate((np_part1, np_part2), axis=0)  # (68841, 16)\n",
    "print('Data loaded.')\n",
    "\n",
    "df = pd.DataFrame(data=np_tweets, columns=['event_id', 'tweet_id', 'text', 'user_id', 'created_at', 'user_loc',\n",
    "                                      'place_type', 'place_full_name', 'place_country_code', 'hashtags',\n",
    "                                      'user_mentions', 'image_urls', 'entities', 'words', 'filtered_words', 'sampled_words'])\n",
    "print('Data converted to dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c045c7cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "       23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
       "       40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56,\n",
       "       57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73,\n",
       "       74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n",
       "       91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105,\n",
       "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
       "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
       "       132, 133, 134, 135, 136, 137, 138, 139, 2, 3, 4, 5, 6, 140, 141,\n",
       "       142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
       "       155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "       168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
       "       181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193,\n",
       "       194, 195, 196, 197, 199, 200, 201, 203, 204, 205, 206, 207, 208,\n",
       "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
       "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
       "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
       "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
       "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
       "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
       "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
       "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
       "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 441, 442, 443,\n",
       "       444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456,\n",
       "       457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469,\n",
       "       470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
       "       483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
       "       496, 497, 498, 499, 500, 501, 502, 503, 504, 505], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.event_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "86e566e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>entities</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>sampled_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>256292946331181056</td>\n",
       "      <td>Nobel prize in literature to be announced http...</td>\n",
       "      <td>47667947</td>\n",
       "      <td>2012-10-11 07:19:34</td>\n",
       "      <td>Munich, Germany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[literature, Nobel, prize, announce]</td>\n",
       "      <td>[literature, nobel, prize, announce]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>256333064467279872</td>\n",
       "      <td>“@marvicleonen: Is it true that UP won UAAP ba...</td>\n",
       "      <td>67518107</td>\n",
       "      <td>2012-10-11 09:58:59</td>\n",
       "      <td>Philippines</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[28775032]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(UP, ORG), (Next year, DATE), (Dean, PERSON)]</td>\n",
       "      <td>[Dean, Sure, year, yan, na, \", basketball, tru...</td>\n",
       "      <td>[dean, sure, year, yan, na, basketball, true, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>256334302034399232</td>\n",
       "      <td>Congrats, Ateneo! Last na yan ha. Season 76 wi...</td>\n",
       "      <td>97449266</td>\n",
       "      <td>2012-10-11 10:03:54</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Ateneo, PERSON), (Season 76, PERSON)]</td>\n",
       "      <td>[yan, ☺, na, ha, different, last, Ateneo, cong...</td>\n",
       "      <td>[yan, na, ha, different, last, ateneo, congrat...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>256335853738160128</td>\n",
       "      <td>\"@SMARTPromos: SMART never wants you to be lef...</td>\n",
       "      <td>405138197</td>\n",
       "      <td>2012-10-11 10:10:04</td>\n",
       "      <td>Lost in Dreamland</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[106915372]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(BIG, ORG), (BIG, ORG)]</td>\n",
       "      <td>[never, s, yan, next, na, thing, Ano, leave, t...</td>\n",
       "      <td>[never, yan, next, na, thing, ano, leave, that...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>256346272506712064</td>\n",
       "      <td>CCTV invite hints at Nobel literature prize fo...</td>\n",
       "      <td>197326414</td>\n",
       "      <td>2012-10-11 10:51:28</td>\n",
       "      <td>Taiwan(R.O.C)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...</td>\n",
       "      <td>[invite, prize, Yan, literature, hint, CCTV, N...</td>\n",
       "      <td>[invite, prize, yan, literature, hint, cctv, n...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_id            tweet_id  \\\n",
       "0        0  256292946331181056   \n",
       "1        0  256333064467279872   \n",
       "2        0  256334302034399232   \n",
       "3        0  256335853738160128   \n",
       "4        0  256346272506712064   \n",
       "\n",
       "                                                text    user_id  \\\n",
       "0  Nobel prize in literature to be announced http...   47667947   \n",
       "1  “@marvicleonen: Is it true that UP won UAAP ba...   67518107   \n",
       "2  Congrats, Ateneo! Last na yan ha. Season 76 wi...   97449266   \n",
       "3  \"@SMARTPromos: SMART never wants you to be lef...  405138197   \n",
       "4  CCTV invite hints at Nobel literature prize fo...  197326414   \n",
       "\n",
       "           created_at           user_loc place_type place_full_name  \\\n",
       "0 2012-10-11 07:19:34    Munich, Germany                              \n",
       "1 2012-10-11 09:58:59        Philippines                              \n",
       "2 2012-10-11 10:03:54                                                 \n",
       "3 2012-10-11 10:10:04  Lost in Dreamland                              \n",
       "4 2012-10-11 10:51:28      Taiwan(R.O.C)                              \n",
       "\n",
       "  place_country_code hashtags user_mentions image_urls  \\\n",
       "0                          []            []         []   \n",
       "1                          []    [28775032]         []   \n",
       "2                          []            []         []   \n",
       "3                          []   [106915372]         []   \n",
       "4                          []            []         []   \n",
       "\n",
       "                                            entities  \\\n",
       "0                                                 []   \n",
       "1     [(UP, ORG), (Next year, DATE), (Dean, PERSON)]   \n",
       "2            [(Ateneo, PERSON), (Season 76, PERSON)]   \n",
       "3                           [(BIG, ORG), (BIG, ORG)]   \n",
       "4  [(CCTV, ORG), (Nobel, WORK_OF_ART), (Mo Yan, P...   \n",
       "\n",
       "                                               words  \\\n",
       "0               [literature, Nobel, prize, announce]   \n",
       "1  [Dean, Sure, year, yan, na, \", basketball, tru...   \n",
       "2  [yan, ☺, na, ha, different, last, Ateneo, cong...   \n",
       "3  [never, s, yan, next, na, thing, Ano, leave, t...   \n",
       "4  [invite, prize, Yan, literature, hint, CCTV, N...   \n",
       "\n",
       "                                      filtered_words sampled_words  \n",
       "0               [literature, nobel, prize, announce]            []  \n",
       "1  [dean, sure, year, yan, na, basketball, true, ...            []  \n",
       "2  [yan, na, ha, different, last, ateneo, congrat...            []  \n",
       "3  [never, yan, next, na, thing, ano, leave, that...            []  \n",
       "4  [invite, prize, yan, literature, hint, cctv, n...            []  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e13c0f31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sort date by time\n",
    "df = df.sort_values(by='created_at').reset_index(drop=True)\n",
    "\n",
    "# append date\n",
    "df['date'] = [d.date() for d in df['created_at']]\n",
    "# 因为graph太大，爆了内存，所以取4天的twitter data做demo，后面用nci server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "df7cb3fc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2950, 18)\n",
      "32\n",
      "2825\n"
     ]
    }
   ],
   "source": [
    "init_day = df.loc[0, 'date']\n",
    "df = df[(df['date']>= init_day) & (df['date']<= init_day + datetime.timedelta(days=3))].reset_index() # (11971, 18)\n",
    "print(df.shape)\n",
    "print(df.event_id.nunique())\n",
    "print(df.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1cca61be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(offline_dataset_savepath + 'df_4days.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c3bc91",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### data_split_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fb1261ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/offline dataset/'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_dataset_savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "162a2705",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473\n",
      "491\n",
      "491\n"
     ]
    }
   ],
   "source": [
    "# data_split保存的是message_block的数据量。e.g. data_split = [  500  ,   100, ...,  100]\n",
    "#                                                         block_0  block_1    block_n\n",
    "# demo: data_split\n",
    "import math\n",
    "dividing_point = int(df.shape[0] / 6)\n",
    "data_amount = 0\n",
    "\n",
    "data_split = []\n",
    "for i in range(5):\n",
    "    data_amount += dividing_point\n",
    "    if i < 2:\n",
    "        continue\n",
    "    else:\n",
    "        data_split.append(data_amount)\n",
    "        print(data_amount)\n",
    "        data_amount = 0\n",
    "data_split.append(df.shape[0] - sum(data_split))   # [5985, 1995, 1995, 1996]\n",
    "\n",
    "# save data_split.npy\n",
    "np.save(offline_dataset_savepath + '/data_split.npy', np.array(data_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8599c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d1c7638d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the embeddings of all the documents in the dataframe\n",
    "# the embeddings of each document is an average of the pre-trained embeddings of all the words in it\n",
    "import en_core_web_lg\n",
    "def documents_to_features(df):\n",
    "    nlp = en_core_web_lg.load()\n",
    "    # filtered_words:[literature, nobel, prize, announce]\n",
    "    features = df.filtered_words.apply(lambda x: nlp(' '.join(x)).vector).values  # nlp生成300维向量；join函数将列表连接成字符串\n",
    "    return np.stack(features, axis=0)  # stack函数沿axis邻接数组序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1a0ba28d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.333     ,  1.010385  ,  1.3869    , -2.0851998 ,  0.65377   ,\n",
       "        0.77485496,  1.4145    ,  0.04524994, -0.15902498,  0.43670005,\n",
       "        5.587075  ,  1.772975  , -2.8684502 ,  3.2695498 ,  1.9184499 ,\n",
       "       -0.87336004,  2.1017    , -1.3273749 , -0.649345  , -3.7304    ,\n",
       "        3.5642002 ,  2.334095  , -0.85600007, -4.06075   , -1.044575  ,\n",
       "        0.210985  , -0.745705  , -3.173335  ,  0.15617001,  0.9961499 ,\n",
       "       -0.20175004, -1.1       , -1.2834    , -1.489825  , -1.19405   ,\n",
       "       -0.52960503, -1.169955  ,  2.6974502 ,  0.7737    ,  0.56413496,\n",
       "       -3.0388    ,  2.8397648 ,  1.3304    , -1.671     , -1.7590151 ,\n",
       "        1.1868551 , -4.03615   ,  3.214575  ,  1.5632001 ,  2.5416    ,\n",
       "       -2.3411    ,  0.15145004,  1.91345   , -1.7932988 ,  2.6248999 ,\n",
       "       -1.07379   ,  0.99674   ,  2.9787    , -0.28958   ,  2.5019825 ,\n",
       "        3.4578001 ,  2.2038    ,  0.07219002, -1.220875  ,  3.48682   ,\n",
       "        1.5402501 , -6.7129    , -1.78312   ,  2.16976   ,  1.70369   ,\n",
       "       -1.32815   ,  0.51409   ,  0.74152493, -1.978365  ,  1.01157   ,\n",
       "       -1.683225  , -4.32325   ,  0.867745  ,  0.839105  , -0.32477   ,\n",
       "       -4.36424   , -2.1473    ,  4.79775   ,  0.92478347,  1.53355   ,\n",
       "        0.07605499,  0.8187001 , -3.2807999 , -2.29465   , -2.5634    ,\n",
       "       -0.38313502,  1.18186   ,  2.44206   , -3.9298    , -4.16385   ,\n",
       "       -1.764795  ,  0.12800002,  0.13109994,  0.8507    , -1.43539   ,\n",
       "        3.080705  ,  0.530595  ,  2.0681    , -0.84345   , -0.69358504,\n",
       "       -0.5553775 , -0.4871    , -2.260955  , -2.0692    ,  1.244795  ,\n",
       "        2.03715   ,  1.7141001 , -0.76804996, -1.16029   ,  0.32014   ,\n",
       "        2.25415   , -0.9174    , -3.83465   ,  0.689755  ,  0.39304996,\n",
       "       -2.5904    , -0.97017   ,  0.267805  ,  0.01144999,  1.502505  ,\n",
       "       -4.5596504 , -0.3506365 , -2.32638   ,  1.522145  ,  0.47345498,\n",
       "        1.16509   , -0.30841503,  1.82758   , -1.6717    , -0.08765   ,\n",
       "       -2.3148751 , -2.01747   ,  1.1532999 , -1.1034851 , -1.20067   ,\n",
       "       -1.4669001 , -1.871905  ,  2.376     ,  2.105304  , -0.27443498,\n",
       "       -0.326506  , -4.184935  , -1.0866101 , -1.0667735 ,  2.5266645 ,\n",
       "        2.4028199 , -0.5255785 , -0.12515   , -1.08232   , -1.964485  ,\n",
       "        1.92377   ,  4.543815  ,  0.855845  , -1.131175  , -1.519     ,\n",
       "        0.24219996,  0.75790006, -2.42085   ,  3.151725  , -0.99789995,\n",
       "       -0.74026597, -1.226335  , -0.6617    , -1.8474    , -2.92805   ,\n",
       "        0.43699998,  1.0582354 , -0.03799999,  0.54965   ,  0.12935   ,\n",
       "        1.0530701 , -0.57414   ,  2.4809499 ,  0.54464   , -1.9684651 ,\n",
       "       -0.94376504,  0.15329993,  1.541845  , -2.242795  ,  2.159375  ,\n",
       "        2.66005   ,  3.2915    , -2.64925   ,  5.5206    ,  1.67935   ,\n",
       "       -1.55112   ,  1.70599   , -3.0271    ,  1.7105    ,  0.44257998,\n",
       "       -0.58386505, -3.223005  ,  3.1297002 , -0.57758   ,  2.5938    ,\n",
       "        1.09975   ,  0.01424   , -3.254145  , -0.26978502,  0.7945    ,\n",
       "       -0.421745  ,  0.16114998,  0.15605003, -1.60829   , -1.44985   ,\n",
       "        3.9772499 ,  1.63545   , -2.1245003 , -1.39755   ,  2.08096   ,\n",
       "        1.5051296 ,  1.5177851 , -2.8806348 , -1.71632   , -2.6666    ,\n",
       "       -0.86113995,  1.74568   ,  0.707605  ,  0.8657    , -3.2729301 ,\n",
       "        1.115525  ,  2.2393    ,  1.388985  , -0.73241   ,  1.12896   ,\n",
       "       -3.00915   , -0.87179005, -0.14790004,  2.02585   , -1.091735  ,\n",
       "       -2.0499501 , -1.045665  ,  0.247515  ,  1.02566   , -1.467345  ,\n",
       "        0.58329   ,  0.56563   ,  0.40367502, -0.74095005,  0.9816    ,\n",
       "       -2.622     , -3.92259   ,  0.48144498,  3.6101    ,  3.2674    ,\n",
       "       -3.2955    , -2.6741168 , -4.2969503 , -0.71623254,  0.81755   ,\n",
       "       -3.2778    ,  0.8157002 , -0.22670001, -0.73350996,  1.40955   ,\n",
       "        0.864195  , -1.1675    ,  1.1119499 , -1.62495   , -0.18781501,\n",
       "        0.100105  , -3.74085   ,  0.14955002,  1.34314   ,  3.2454    ,\n",
       "        3.3711    ,  0.2270395 ,  0.006735  , -0.216775  , -0.43564498,\n",
       "       -1.717025  ,  2.0725    , -1.377385  , -0.748385  , -0.16938001,\n",
       "       -1.5891999 ,  1.44585   ,  4.73514   , -1.524525  ,  1.01      ,\n",
       "        3.1448002 ,  3.24515   ,  0.62294   , -1.406575  ,  0.8858505 ,\n",
       "        3.5020301 ,  0.03155997,  1.2440599 , -1.000485  ,  1.097225  ,\n",
       "       -3.65455   ,  0.572205  ,  3.0628    , -1.96392   ,  1.4725599 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_core_web_lg.load()('hello world').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f7f2ec62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document features generated\n"
     ]
    }
   ],
   "source": [
    "# 生成文档embedding\n",
    "d_features = documents_to_features(df)\n",
    "print('Document features generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bec3f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "44ac9870",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# encode one times-tamp\n",
    "# t_str: a string of format '2012-10-11 07:19:34'\n",
    "def extract_time_feature(t_str):\n",
    "    t = datetime.datetime.fromisoformat(str(t_str)) # 分别返回年月日时分秒列表\n",
    "    OLE_TIME_ZERO = datetime.datetime(1899, 12, 30)\n",
    "    delta = t - OLE_TIME_ZERO  # datetime.timedelta(days=41193, seconds=26374)\n",
    "    return [(float(delta.days)/10000.), (float(delta.seconds)/86400)] # 86400 seconds in day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "19963216",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_t_features(df):\n",
    "    t_features = np.asarray([extract_time_feature(t_str) for t_str in df['created_at']])  # np.asarray将list列表转换成np.ndarray数组\n",
    "    return t_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c4b31bd4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time features generated.\n"
     ]
    }
   ],
   "source": [
    "# 生成时间特征days和seconds\n",
    "t_features = df_to_t_features(df)\n",
    "print('Time features generated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5b145",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9534abcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated document features and time features.\n"
     ]
    }
   ],
   "source": [
    "combined_features = np.concatenate((d_features, t_features), axis=1)  # （11971，302）\n",
    "print('Concatenated document features and time features.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cd7ec8a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features saved.\n"
     ]
    }
   ],
   "source": [
    "np.save(save_path + 'combined_features_embeddings.npy', combined_features)\n",
    "print('Initial features saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3863d139",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>event_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_full_name</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>image_urls</th>\n",
       "      <th>entities</th>\n",
       "      <th>words</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>sampled_words</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>394</td>\n",
       "      <td>255819992157786112</td>\n",
       "      <td>HipHop awards bout to be live!!</td>\n",
       "      <td>250870763</td>\n",
       "      <td>2012-10-10 00:00:13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[award, live, bout, hiphop]</td>\n",
       "      <td>[award, live, bout, hiphop]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>394</td>\n",
       "      <td>255820118095978496</td>\n",
       "      <td>HIPHOP AWARDS TIME!</td>\n",
       "      <td>28026779</td>\n",
       "      <td>2012-10-10 00:00:43</td>\n",
       "      <td>SoundCloud/RaRaSupaStar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[HIPHOP, AWARDS, time]</td>\n",
       "      <td>[hiphop, awards, time]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>255820147489636353</td>\n",
       "      <td>Bet hiphop awards</td>\n",
       "      <td>566825483</td>\n",
       "      <td>2012-10-10 00:00:50</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[(Bet, GPE)]</td>\n",
       "      <td>[award, bet, hiphop]</td>\n",
       "      <td>[award, bet, hiphop]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>394</td>\n",
       "      <td>255820164023595008</td>\n",
       "      <td>BET HipHop awards is on!!!</td>\n",
       "      <td>197834311</td>\n",
       "      <td>2012-10-10 00:00:54</td>\n",
       "      <td>Saint Lucia ☀️🌴🇱🇨</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[HipHop, BET, award]</td>\n",
       "      <td>[hiphop, bet, award]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>394</td>\n",
       "      <td>255820180884701184</td>\n",
       "      <td>Watchin Da BET Hiphop Awards</td>\n",
       "      <td>439490861</td>\n",
       "      <td>2012-10-10 00:00:58</td>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Hiphop, Watchin, Awards, Da, BET]</td>\n",
       "      <td>[hiphop, watchin, awards, da, bet]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2012-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index event_id            tweet_id                             text  \\\n",
       "0      0      394  255819992157786112  HipHop awards bout to be live!!   \n",
       "1      1      394  255820118095978496              HIPHOP AWARDS TIME!   \n",
       "2      2      394  255820147489636353                Bet hiphop awards   \n",
       "3      3      394  255820164023595008       BET HipHop awards is on!!!   \n",
       "4      4      394  255820180884701184     Watchin Da BET Hiphop Awards   \n",
       "\n",
       "     user_id          created_at                 user_loc place_type  \\\n",
       "0  250870763 2012-10-10 00:00:13                                       \n",
       "1   28026779 2012-10-10 00:00:43  SoundCloud/RaRaSupaStar              \n",
       "2  566825483 2012-10-10 00:00:50                                       \n",
       "3  197834311 2012-10-10 00:00:54        Saint Lucia ☀️🌴🇱🇨              \n",
       "4  439490861 2012-10-10 00:00:58            Michigan, USA              \n",
       "\n",
       "  place_full_name place_country_code hashtags user_mentions image_urls  \\\n",
       "0                                          []            []         []   \n",
       "1                                          []            []         []   \n",
       "2                                          []            []         []   \n",
       "3                                          []            []         []   \n",
       "4                                          []            []         []   \n",
       "\n",
       "       entities                               words  \\\n",
       "0            []         [award, live, bout, hiphop]   \n",
       "1            []              [HIPHOP, AWARDS, time]   \n",
       "2  [(Bet, GPE)]                [award, bet, hiphop]   \n",
       "3            []                [HipHop, BET, award]   \n",
       "4            []  [Hiphop, Watchin, Awards, Da, BET]   \n",
       "\n",
       "                       filtered_words sampled_words        date  \n",
       "0         [award, live, bout, hiphop]            []  2012-10-10  \n",
       "1              [hiphop, awards, time]            []  2012-10-10  \n",
       "2                [award, bet, hiphop]            []  2012-10-10  \n",
       "3                [hiphop, bet, award]            []  2012-10-10  \n",
       "4  [hiphop, watchin, awards, da, bet]            []  2012-10-10  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc4391",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### constructing_offline_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "449fb749",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# To switch to the All Message Strategy or the Relevant Message Strategy, replace 'G = construct_graph_from_df(incr_df)' with 'G = construct_graph_from_df(incr_df, G)'.\n",
    "# 2) For test purpose, set test=True, and the message blocks, as well as the resulted message graphs each will contain 100 messages.\n",
    "# To use all the messages, set test=False, and the number of messages in the message blocks will follow Table. 4 of the paper.\n",
    "def construct_offline_dataset(df, save_path, features_embeddings, test=True):\n",
    "    '''\n",
    "    df: (11971, 18)\n",
    "    feature_embeddings: (68841, 302)\n",
    "    '''\n",
    "    # If test equals true, construct the initial graph using test_ini_size_tweets\n",
    "    # and increment the graph by test_incr_size tweets each day\n",
    "    test_ini_size = 500\n",
    "    test_incr_size = 100\n",
    "    \n",
    "    # save data splits for training/validate/test mask generation\n",
    "    data_split = []\n",
    "    # save time spent for the heterogeneous -> homogeneous conversion of each graph\n",
    "    all_graph_mins = []\n",
    "    message = ''\n",
    "    # extract distingct dates\n",
    "    distinct_dates = df.date.unique() # 所有unique的date, 4\n",
    "    print('Number of distinct dates: ', len(distinct_dates))\n",
    "    message += 'Number of distinct dates: '\n",
    "    message += str(len(distinct_dates))\n",
    "    message += '\\n'\n",
    "    \n",
    "    # split data by dates and construct graphs\n",
    "    # first week -> initial graph (20254 tweets)\n",
    "    print('Start constructing initial graph ...')\n",
    "    message += '\\nStart constructing initial graph ...\\n'\n",
    "#     ini_df = df.loc[df['date'].isin(distinct_dates[:7])]  # find top 7 days\n",
    "#     if test:\n",
    "#         ini_df = ini_df[: test_ini_size]  # top test_ini_size dates\n",
    "    G = construct_graph_from_df(df)  # graph with 30427 nodes and 40238 edges\n",
    "    path = save_path\n",
    "    if path is None:\n",
    "        os.mkdir(path)  # 创建目录\n",
    "    graph_mins, graph_message = dgl_hetegraph_to_homograph(G, save_path=path)  # convert a heterogeneous social graph to a homogeneous message graph\n",
    "    message += graph_message\n",
    "    print('Initial graph saved')\n",
    "    message += 'Initial graph saved\\n'\n",
    "    # record the totoal number of tweets\n",
    "    all_graph_mins.append(graph_mins)\n",
    "    \n",
    "    # 按照索引获得标签label，extract and save the labels of corresponding tweets\n",
    "    labels = [int(each) for each in df['event_id'].values]  # 11971，可以用df.event_id.unique()查看\n",
    "    np.save(path + 'sorted_labels.npy', np.asarray(labels))  # np.asarray()将list转化为ndarray数组，实际只创建一个指针\n",
    "    print('Labels saved.')\n",
    "    message += 'Labels saved.\\n'\n",
    "    \n",
    "    # 按照索引获得doc_embeddings, extract and save the features of corresponding tweets\n",
    "    indices = df['index'].values.tolist()  # 11971\n",
    "    x = features_embeddings[indices, :]  # (11971, 302), combined_features: document_embeddings + time_features\n",
    "    np.save(path + 'sorted_combined_features_embeddings.npy', x)\n",
    "    print('Features saved.')\n",
    "    message += 'Features saved. \\n\\n'\n",
    "    \n",
    "#     # subsequent days -> insert tweets day by day(skip the last day because it only contains on tweet)\n",
    "#     for i in range(7, len(distinct_dates) -1):\n",
    "#         print('Start constructing graph', str(i - 6), '...')\n",
    "#         message += '\\nStart constructing graph'\n",
    "#         message += str(i-6)\n",
    "#         message += '...\\n'\n",
    "#         incr_df = df.loc[df['date']==distinct_dates[i]]\n",
    "#         if test:\n",
    "            \n",
    "    return message, all_graph_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ea490cce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "51113bbc",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct dates:  1\n",
      "Start constructing initial graph ...\n",
      "Start converting heterogeneous networks graph to homogeneous dgl graph.\n",
      "\tGetting a list of all nodes ...\n",
      "\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\tGetting adjacency matrix ...\n",
      "\tDone. Time elapsed:  0.0015126744906107585  mins\n",
      "\n",
      "\tGetting lists of nodes of various types ...\n",
      "\tDone. Time elapsed:  0.00023262500762939454  mins\n",
      "\n",
      "\tConverting node lists to index lists ...\n",
      "\tDone. Time elapsed:  0.010149808724721272  mins\n",
      "\n",
      "\tStart constructing tweet-user-tweet commuting matrix ...\n",
      "\t\t\tStart constructing tweet-user matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.0007313370704650878  mins\n",
      "\n",
      "\t\t\tConverting to sparse matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.001063843568166097  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-user * user-tweet ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "sparse binary userid commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  6.602605183919271e-05  mins\n",
      "\n",
      "\tStart constructing tweet-ent-tweet conmuting matrix ...\n",
      "\t\t\tStart constructing tweet-ent matrix ...\n",
      "\t\t\tConverting to sparse matrix ...\n",
      "\t\t\tDone. Time elapsed :  0.0005650639533996582  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-ent * ent-tweet ...\n",
      "\t\t\tDone. Time elapsed:  3.3243497212727865e-05  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "Sparse binary entity commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  0.00046488444010416664  mins\n",
      "\n",
      "\tStart constructing tweet-word-tweet commuting matrix ...\n",
      "\t\t\tStart constructing tweet-word matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.0005652228991190593  mins\n",
      "\n",
      "\t\t\tConverting to Sparse matrix ...\n",
      "\t\t\tDone. Time elapsed:  0.0001827677090962728  mins\n",
      "\n",
      "\t\t\tTransposing ...\n",
      "\t\t\tDone. Time elapsed:  0.0  mins\n",
      "\n",
      "\t\t\tCalculating tweet-word * word-tweet ...\n",
      "\t\t\tDone. Time elapsed:  1.662572224934896e-05  mins\n",
      "\n",
      "\t\t\tSaving ...\n",
      "Sparse binary word commuting matrix saved.\n",
      "\t\t\tDone. Time elapsed:  9.975035985310872e-05  mins\n",
      "\n",
      "\tComputing tweet-tweet adjacency matrix ...\n",
      "Sparse binary userid commuting matrix loaded.\n",
      "Sparse binary entity commuting matrix loaded.\n",
      "Sparse binary word commuting matrix loaded.\n",
      "\t\t\tDone. Time elapsed:  0.0007193644841512044  mins\n",
      "\n",
      "\tOver all time elapsed:  0.0170853058497111  mins\n",
      "\n",
      "Sparse binary adjacency matrix saved.\n",
      "Sparse binary adjacency matrix loaded.\n",
      "We have 2950 nodes.\n",
      "We have 208246 edges\n",
      "\n",
      "Initial graph saved\n",
      "Labels saved.\n",
      "Features saved.\n",
      "Time spent on heterogeneous -> homogeneous graph conversions:  [0.0170853058497111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# load combined features\n",
    "# the dimension of combined_feature is 302 in this dataset: document_features-300 + time_features-2\n",
    "combined_features = np.load(save_path + '/combined_features_embeddings.npy')  # (11971, 302)\n",
    "\n",
    "# generate test graphs, features, and labels\n",
    "message, all_graph_mins = construct_offline_dataset(df, offline_dataset_savepath, combined_features, True)\n",
    "with open(offline_dataset_savepath + 'node_edge_statistics.txt', 'w') as text_file:\n",
    "    text_file.write(message)\n",
    "np.save(offline_dataset_savepath + 'log_all_graph_min.npy', np.asarray(all_graph_mins))\n",
    "print('Time spent on heterogeneous -> homogeneous graph conversions: ', all_graph_mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1460ff81",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7c52d3b0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2012, 10, 10)], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a99adad6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "82dadfc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 18)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a193d239",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### save_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a2737b95",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse.tensor import SparseTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6a714edc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,1,2,0]).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f75d4f8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# relations_ids = ['entity', 'userid', 'word'],分别读取这三个文件\n",
    "# 从稀疏矩阵s_m_tid_entity_tid_matrix.npz等三个矩阵中，提取非零edge，这个edge是邻接矩阵形式的edge。\n",
    "def sparse_trans(datapath = None):\n",
    "    relation = sparse.load_npz(datapath)  # tid_entity_tid_matrix,(11971, 11971)\n",
    "    all_edge_index = torch.tensor([], dtype=int)\n",
    "    for node in range(relation.shape[0]):\n",
    "        '''\n",
    "        # IntTensor是torch定义的7中cpu tensor类型之一；\n",
    "        # relation matrix, (11971, 11971), relation[0]表示第一行向量\n",
    "        # squeeze对数据维度进行压缩，删除所有为1的维度\n",
    "        '''\n",
    "        neighbor = torch.IntTensor(relation[node].toarray()).squeeze()  # 单行向量, (11971,)\n",
    "        # del self_loop in advance\n",
    "        neighbor[node] = 0  # 对角线元素先置0，后面设置为1\n",
    "        '''\n",
    "        稀疏矩阵neighbor，非零元素==edge，它的索引就表示(node, index)那条边\n",
    "        '''\n",
    "        # step1: nonzero()返回非零元素的索引，(1381, 1), 得到index列表，tensor([[   25], [   54],[   88],...,[11947],[11956],[11960]])\n",
    "        neighbor_idx = neighbor.nonzero()\n",
    "        # step2：是要获得等量的node列表\n",
    "        neighbor_sum = neighbor_idx.size(0)  # 表示第0维度的数据量, 1381\n",
    "        loop = torch.tensor(node).repeat(neighbor_sum, 1)  # 单个值的tensor，repeat表示沿着指定的维度重复neighbor_sum次数; (1381, 1)\n",
    "        # step3：将node list与index list组合成坐标形式 <-邻接矩阵\n",
    "        # 点node非零单行向量和构造的node单行向量，进行列拼接，\n",
    "        edge_index_i_j = torch.cat((loop, neighbor_idx), dim=1).t()  # cat表示拼接；t表示对二维矩阵进行转置, (2,1381)\n",
    "        # step4：再加上对角线的坐标元素\n",
    "        self_loop = torch.tensor([[node], [node]])   # （2,1）tensor([[9],[9]])\n",
    "        # all_edge_index表示前面所有node的edge list；edge_index_i_j和self_loop表示当前点的edge list；将它们全加起来\n",
    "        all_edge_index = torch.cat((all_edge_index, edge_index_i_j, self_loop), dim=1) # 列拼接：(2,9)、(2,1381)、(2,1)\n",
    "        del neighbor, neighbor_idx, loop, self_loop, edge_index_i_j\n",
    "    return all_edge_index  # 该属性稀疏矩阵下所有的edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4a6eb7ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save edge_index_[entity, userid, word].pt 文件\n",
    "relations = ['entity', 'userid', 'word']\n",
    "for relation in relations:\n",
    "    relation_edge_index = sparse_trans(os.path.join(offline_dataset_savepath, 's_m_tid_%s_tid_matrix.npz' % relation))\n",
    "    torch.save(relation_edge_index, offline_dataset_savepath + '/edge_index_%s.pt' % relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd09919",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FinEvent Model Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cb4fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fundemental models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265ad59",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "61021ca8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.functional import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv  # PyG封装好的GATConv函数\n",
    "from torch.nn import Linear, BatchNorm1d, Sequential, ModuleList, ReLU, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c066594",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### GAT model for mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2f1a8a7e",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    '''\n",
    "    adopt this module when using mini-batch\n",
    "    '''\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, heads) -> None:\n",
    "        super(GAT, self).__init__()\n",
    "        self.GAT1 = GATConv(in_channels=in_dim, out_channels=hid_dim, heads=heads, add_self_loops=False)  # 输入节点的特征维度，隐藏层节点的维度\n",
    "        self.GAT2 = GATConv(in_channels=hid_dim*heads, out_channels=out_dim, add_self_loops=False)  # 隐藏层维度，输出维度\n",
    "        self.layers = ModuleList([self.GAT1, self.GAT2])\n",
    "        self.norm = BatchNorm1d(heads * hid_dim)  # 将num_features那一维进行归一化，防止梯度扩散\n",
    "    \n",
    "    def forward(self, x, adjs, device):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs): # 返回一个可遍历对象，同时列出数据和数据下标\n",
    "            # x: Tensor, edge_index: Tensor\n",
    "            x, edge_index = x.to(device), edge_index.to(device)\n",
    "            x_target = x[:size[1]]  # Target nodes are always placed first\n",
    "            x = self.layers[i]((x,x_target), edge_index)\n",
    "            if i == 0:\n",
    "                x = self.norm(x)  # 归一化操作，防止梯度散射\n",
    "                x = F.elu(x)  # 非线性激活函数elu\n",
    "                x = F.dropout(x, training=self.training)\n",
    "            del edge_index\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd62de1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Intra_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ba7f1766",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# GAT model\n",
    "class Intra_AGG(nn.Module):  # intra-aggregation\n",
    "    def __init__(self, GAT_args):\n",
    "        super(Intra_AGG, self).__init__()\n",
    "        in_dim, hid_dim, out_dim, heads = GAT_args\n",
    "        self.gnn = GAT(in_dim, hid_dim, out_dim, heads)\n",
    "    \n",
    "    def forward(self, x, adjs, device):\n",
    "        x = self.gnn(x, adjs, device)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abb144",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Inter_AGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0328ec46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mlp model\n",
    "class Inter_AGG(nn.Module):  # inter-aggregation\n",
    "    def __init__(self, mlp_args=None):\n",
    "        super(Inter_AGG, self).__init__()\n",
    "        if mlp_args is not None:\n",
    "            hid_dim, out_dim = mlp_args\n",
    "            self.mlp = nn.Sequential(\n",
    "                        Linear(hid_dim, hid_dim),\n",
    "                        BatchNorm1d(hid_dim),\n",
    "                        ReLU(inplace=True),\n",
    "                        Dropout(),\n",
    "                        Linear(hid_dim, out_dim),\n",
    "                        )\n",
    "    def forward(self, features, thresholds, inter_opt):\n",
    "        batch_size = features[0].size(0)\n",
    "        features = torch.transpose(features, dim0=0, dim1=1)\n",
    "        if inter_opt == 'cat_wo_avg':\n",
    "            features = features.reshape(batch_size, -1)\n",
    "        elif inter_opt == 'cat_w_avg':\n",
    "            # weighted average and concatenate\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "        elif inter_opt == 'cat_w_avg_mlp':\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "            features = self.mlp(features)\n",
    "        elif inter_opt == 'cat_wo_avg_mlp':\n",
    "            features = torch.mul(features, thresholds).reshape(batch_size, -1)\n",
    "            features = self.mlp(features)\n",
    "        elif inter_opt == 'add_wo_avg':\n",
    "            features = features.sum(dim=1)\n",
    "        elif inter_opt == 'add_w_avg':\n",
    "            features = torch.mul(features, thresholds).sum(dim=1)\n",
    "        return features\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d44c28",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### TripletLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ee84cde8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c3cf771b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Applies an average on seq, of shape(nodes, features)\n",
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgReadout, self).__init__()\n",
    "    def forward(self, seq):\n",
    "        return torch.mean(seq, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2dd4e451",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):  # 鉴别器\n",
    "    def __init__(self, n_h):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)  # 双向现行变换x1*A*x2\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "    \n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, m.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)  # 权值初始化方法，均分分布\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n",
    "        c_x = torch.unsqueeze(c, 0)\n",
    "        c_x = c_x.expand_as(h_pl)  # torch.randn(size*)生成size维数组；expand是扩展到size_new数组；expand_as是扩展到像y的数组\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 1)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 1)\n",
    "        if s_bias1 is not None:\n",
    "            sc_1 += s_bias1\n",
    "        if s_bias2 is not None:\n",
    "            sc_2 += s_bias2\n",
    "        logits = torch.cat((sc_1, sc_2), 0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f03e8c26",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TripletSelector:\n",
    "    '''\n",
    "    Implementation should return indices of anchors, positive and negative samples\n",
    "    return np array of shape [N_triplets * 3]\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        raise NotImplementedError  # 如果这个方法没有被子类重写，但是调用了，就会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ab874ae9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 矩阵计算\n",
    "def distance_matrix_computation(vectors):\n",
    "    distance_matrix=-2*vectors.mm(torch.t(vectors))+vectors.pow(2).sum(dim=1).view(1,-1)+vectors.pow(2).sum(dim=1).view(-1,1)\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6d119",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### negative_triplet_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4fed9b07",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 具体实现三元损失函数triplets_loss，返回某标签下ith元素和jth元素，其最大loss对应的其他标签元素索引\n",
    "\n",
    "class FunctionNegativeTripletSelector(TripletSelector):\n",
    "    '''\n",
    "    For each positive pair, takes the hardes negative sample (with the greatest triplet loss value) to create a triplet\n",
    "    Margin should match the margin userd in triplet loss.\n",
    "    negative_selection_fn should take array of loss_values for a given anchor-positive pair and all negative samples\n",
    "    and return a negative index for that pair\n",
    "    '''\n",
    "    def __init__(self, margin, negative_selection_fn, cpu=True):\n",
    "        super(FunctionNegativeTripletSelector, self).__init__()\n",
    "        self.cpu = cpu\n",
    "        self.margin = margin\n",
    "        self.negative_selection_fn = negative_selection_fn  # 返回loss_values最大元素值的index的selector\n",
    "    \n",
    "    def get_triplets(self, embeddings, labels):\n",
    "        if self.cpu:\n",
    "            embeddings = embeddings.cpu()\n",
    "        distance_matrix = distance_matrix_computation(embeddings)  # 计算distance matrix\n",
    "        distance_matrix = distance_matrix.cpu()  \n",
    "        \n",
    "        labels = labels.cpu().data.numpy()\n",
    "        triplets = []\n",
    "        \n",
    "        # embedding计算的distance matrix与labels计算loss，取最大loss_index\n",
    "        # 对于每个标签label\n",
    "        for label in set(labels):\n",
    "            label_mask = (labels == label)  # numpy array([True, False, True, True])\n",
    "            label_indices = np.where(label_mask)[0]  # 标签索引, label_index, array([0, 2, 3], dtype=int64)\n",
    "            if len(label_indices) < 2:\n",
    "                continue\n",
    "            negative_indices = np.where(np.logical_not(label_mask))[0]  # 其他标签索引, not_label_index, array([1], dtype=int64)\n",
    "            anchor_pos_list = list(combinations(label_indices, 2)) # 2个元素的标签索引组合, [(0, 2), (0, 3), (2, 3)]\n",
    "            anchor_pos_list = np.array(anchor_pos_list)  # 转换成np.array才能进行slice切片操作\n",
    "            \n",
    "            # 按照anchor_positive index从距离矩阵中抽取distance；0-index，array([0, 0, 2]);\n",
    "            # 提取标签label的i-element与j-element距离。\n",
    "            anchor_p_distances = distance_matrix[anchor_pos_list[:,0], anchor_pos_list[:,1]] #类似组成坐标，tensor([-1.1761,-0.8381,0.0099])\n",
    "            for anchor_positive, ap_distance in zip(anchor_pos_list, anchor_p_distances): # 每个标签下，元素组合、元素距离\n",
    "                # 0表示ith元素到各个其他标签元素的距离。\n",
    "                # 同一标签下(ith,jth)距离 - ith元素到其他标签元素的距离 + self.margin边际收益\n",
    "                loss_values = ap_distance - distance_matrix[  \n",
    "                    torch.LongTensor(np.array([anchor_positive[0]])), torch.LongTensor(negative_indices)] + self.margin\n",
    "                loss_values = loss_values.data.cpu().numpy()\n",
    "                hard_neg_max_index = self.negative_selection_fn(loss_values)  # hard返回最大loss的索引\n",
    "                if hard_neg_max_index is not None:  # if 最大loss值非空，则返回其他标签元素的索引\n",
    "                    hard_negative = negative_indices[hard_neg_max_index] \n",
    "                    # 对于谋标签下ith元素和jth元素，其最大loss对应的其他标签元素索引\n",
    "                    triplets.append([anchor_positive[0], anchor_positive[1], hard_negative]) \n",
    "        \n",
    "        if len(triplets) == 0:\n",
    "            triplets.append([anchor_positive[0], anchor_positive[1], negative_indices[0]])\n",
    "        \n",
    "        triplets = np.array(triplets)\n",
    "        return torch.LongTensor(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3672739a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 随机-loss随机负值\n",
    "def random_hard_negative(loss_values):\n",
    "    hard_negatives = np.where(loss_values > 0)[0]\n",
    "    return np.random.choice(hard_negatives) if len(hard_negatives) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1f967984",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 硬-loss最大负值\n",
    "def hardest_negative(loss_values):\n",
    "    hard_negative = np.argmax(loss_values)\n",
    "    return hard_negative if loss_values[hard_negative] > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ef5942",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### hard_tri-loss_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3db1ae3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 硬三元损失函数\n",
    "def HardestNegativeTripletSelector(margin, cpu=False):\n",
    "    return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=hardest_negative, cpu=cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce64d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### random_tri-loss_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d19d6c08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 随机三元损失函数\n",
    "def RandomNegativeTripletSelector(margin, cpu=False):\n",
    "    return FunctionNegativeTripletSelector(margin=margin, negative_selection_fn=random_hard_negative, cpu=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fef0a5e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9772]],\n",
       "\n",
       "        [[0.9142]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e90faf63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0929, -0.4480,  1.6901],\n",
       "         [-0.5728,  0.3484, -1.0627],\n",
       "         [ 0.4017,  0.4830,  0.0340]],\n",
       "\n",
       "        [[ 1.4821,  0.1549, -0.2971],\n",
       "         [ 0.2167, -0.1918, -0.7099],\n",
       "         [ 0.7191, -0.3415, -0.1926]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b74ba8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### triplet_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "58d1a389",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 计算triplet_loss损失函数\n",
    "class OnlineTripletLoss(nn.Module):\n",
    "    '''\n",
    "    Online Triplets loss\n",
    "    Takes a batch of embeddings and corresponding labels\n",
    "    Triplets are generated using triplet_selector objects that take embeddings and targets and return indices of triplets\n",
    "    '''\n",
    "    def __init__(self, margin, triplet_selector):\n",
    "        super(OnlineTripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.triplet_selector = triplet_selector  # selector选择器对象，含有get_triplets方法\n",
    "    \n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)  # 根据embeddings和labels返回最大loss index list\n",
    "        # if embeddings.is_cuda():\n",
    "        #     triplets = triplets.cuda()\n",
    "        # embeddings矩阵索引是单个元素，取行向量，多个行向量又组成矩阵！！\n",
    "        ap_distances = (embeddings[triplets[:,0]] - embeddings[triplets[:,1]]).pow(2).sum(1) # .pow(.5); \n",
    "        an_distances = (embeddings[triplets[:,0]] - embeddings[triplets[:,2]]).pow(2).sum(1) # .pow(.5)\n",
    "        losses = F.relu(ap_distances - an_distances + self.margin)\n",
    "        \n",
    "        return losses.mean(), len(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024f7ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### NeighborRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0935aeaa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.functional import Tensor\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6203a30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### cal_similarity_node_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1c344fe5",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# multi_r_data,entity、userid、word三种边的索引列表，edge是邻接矩阵对称边；combine_features_embeddings\n",
    "# 对称edge、edge index最大不超过tweet data index 11971.\n",
    "def cal_similarity_node_neighbors(multi_r_data, features, save_path=None): \n",
    "    '''\n",
    "    This is used to culculate the similarity between node and its neighbors in advance \n",
    "    in order to avoid the repetitive computation.\n",
    "    Args:\n",
    "        multi_r_data ([type]): [description]\n",
    "        features ([type]): [description]\n",
    "        save_path ([type], optional): [description]. Defaults to None.\n",
    "    '''\n",
    "    relation_config: Dict[str, Dict[int, Any]] = {}\n",
    "    for relation_id, r_data in enumerate(multi_r_data):  # entity edge list(2,3716829), userid, word.\n",
    "        node_config: Dict[int, Any] = {}\n",
    "        r_data: Tensor  # 边\n",
    "        unique_nodes = r_data[1].unique()  # r_data,(2,3716829),所有邻接矩阵对称边edge的终点索引index，11971\n",
    "        num_nodes = unique_nodes.size(0)   # 有edge的节点数，11971\n",
    "        '''\n",
    "        # 第一个点  node值与edge索引是一样的吗？\n",
    "        因为edge是从tid_entity_tid中提取的索引，所以entity、userid、word三种relation的索引都是基于tweet data index计量的，也就是说最大不超过11971.\n",
    "        '''\n",
    "        for node in range(num_nodes):  # 以node为终点的edge\n",
    "            # get neighbors' index\n",
    "            neighbors_idx = torch.where(r_data[1]==node)[0]  # where返回满足条件tuple形式的r_data索引，[0]提取符合条件的index 数组。\n",
    "            # get neghbors\n",
    "            neighbors = r_data[0, neighbors_idx]          # 获取edge起点的index list\n",
    "            num_neighbors = neighbors.size(0)             # neighbors_num\n",
    "            neighbors_features = features[neighbors, :]   # 根据edge起点index获取相应的combined features embeddings\n",
    "            target_features = features[node, :]           # 获取中心节点node的combine features embeddings\n",
    "            # calculate enclidean distance with broadcast\n",
    "            dist: Tensor = torch.norm(neighbors_features - target_features, p=2, dim=1)  # torch.norm求a列维度(dim指定)的2(p指定)范数(长度)\n",
    "            # smaller is better and we use 'top p' in our paper\n",
    "            # (threshold * num_neighbors) see RL_neighbor_filter for details\n",
    "            sorted_neighbors, sorted_index = dist.sort(descending=False) # 返回：升序排列的tensor、tensor_index-> 以select top-pneighbors\n",
    "            node_config[node] = {'neighbors_idx': neighbors_idx,      # 中心节点node在edge matrix r_data中的索引\n",
    "                                'sorted_neighbors': sorted_neighbors, # 欧式距离，node和neighbors\n",
    "                                'sorted_index': sorted_index,         # 对neighbors_idx重新排序的sorted index，不是11971\n",
    "                                'num_neighbors': num_neighbors}       \n",
    "        relation_config['relation_%d' % relation_id] = node_config\n",
    "    if save_path is not None:\n",
    "        print(save_path)\n",
    "        save_path = os.path.join(save_path, 'relation_top_p_neighbors.npy')\n",
    "        np.save(save_path, relation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9de83e14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6]])\n",
    "b=torch.tensor([1,1,1])\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db06b89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### RL_neighbor_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "71a8616b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 返回filtered neighbor index\n",
    "def RL_neighbor_filter(multi_r_data, RL_thtesholds, load_path):  # RL_thresholds: [[0.2],[0.2],[0.2]]\n",
    "    load_path = os.path.join(load_path, 'relation_top_p_neighbors.npy')\n",
    "    relation_config = np.load(load_path, allow_pickle=True)\n",
    "    relation_config = relation_config.tolist()  # dict: 3\n",
    "    relations = list(relation_config.keys())    # list: 3, ['relation_0', 'relation_1', 'relation_2']\n",
    "    multi_remain_data = []\n",
    "    \n",
    "    for i in range(len(relations)):   # relations: entity、userid、word\n",
    "        edge_index: Tensor = multi_r_data[i]   # edge_index_entity,(2,3716829);\n",
    "        unique_nodes = edge_index[1].unique()  # 11971\n",
    "        num_nodes = unique_nodes.size(0)\n",
    "        remain_node_index = torch.tensor([])\n",
    "        for node in range(num_nodes):  \n",
    "            # extract config\n",
    "            neighbors_idx = relation_config[relations[i]][node]['neighbors_idx']\n",
    "            num_neighbors = relation_config[relations[i]][node]['num_neighbors']\n",
    "            sorted_neighbors = relation_config[relations[i]][node]['sorted_neighbors']\n",
    "            sorted_index = relation_config[relations[i]][node]['sorted_index']\n",
    "            \n",
    "            if num_neighbors < 5:\n",
    "                remain_node_index = torch.cat((remain_node_index, neighbors_idx))\n",
    "                continue  # add limitations\n",
    "            \n",
    "            threshold = float(RL_thtesholds[i])\n",
    "            \n",
    "            num_kept_neighbors = math.ceil(num_neighbors * threshold) + 1\n",
    "            filtered_neighbors_idx = neighbors_idx[sorted_index[:num_kept_neighbors]]\n",
    "            remain_node_index = torch.cat((remain_node_index, filtered_neighbors_idx))\n",
    "            \n",
    "        remain_node_index = remain_node_index.type('torch.LongTensor')\n",
    "        edge_index = edge_index[:, remain_node_index]  # 邻接矩阵转换成的edge index matrix\n",
    "        multi_remain_data.append(edge_index)\n",
    "    \n",
    "    return multi_remain_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ada47",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# FinEvent Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071df23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## gen_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a7f3789e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.coo import coo_matrix\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from scipy import sparse\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_sparse.tensor import SparseTensor\n",
    "# from .utils import generateMasks, gen_offline_masks，是指从utils.py文件中导入函数: generatemasks, gen_offline_masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43511c93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create homodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bbae31c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "mode: (train_i, i)\n",
    "message block 0-train_i, as training dataset\n",
    "random selection from training dataset, as validation dataset\n",
    "other message blocks between train_i and i, having no labels\n",
    "message block i, as test dataset\n",
    "'''\n",
    "# 返回training, validation, test data\n",
    "def create_homodataset(loadpath, mode, valid_percent=0.2):\n",
    "    features = np.load(os.path.join(loadpath, 'features_embeddings.npy'))  # features embeddings\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features loaded')\n",
    "    labels = np.load(os.path.join(loadpath, 'sorted_labels.npy'))\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    \n",
    "    data = Data(x=features, edge_index=None, y=labels)  # torch_geometric提供的图数据类型Data，x表示tensor矩阵，\n",
    "                                                        # 形状为[num_nodes, num_node_features]; \n",
    "                                                        # edge_index表示coo格式的图的边关系，形状为[2, num_edge]\n",
    "    data_split = np.load(os.path.join(loadpath, 'data_split.npy'))\n",
    "    # load number of message in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    train_i, i = mode[0], mode[1]\n",
    "    if train_i == i:\n",
    "        data.train_mask, data.val_mask = generateMasks(len(labels), data_split, train_i, i, valid_percent)\n",
    "    else:\n",
    "        data.test_mask = generateMasks(len(labels), data_split, train_i, i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "82a47b47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 18)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2d86d2e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac79406",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create_offline_homodataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "17f7ccfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch_geometric提供了一种使用多属性表示图的数据类型Data\\n    x，tensor类型，形状[num_nodes, num_node_features]\\n    edge_index，coo格式的图的边关系，形状为[2, num_edges]\\n    pos: 存储节点的坐标，形状是[num_nodes, num_dimensions]\\n    y: 存储样本标签。如果是每个节点都有标签，那么形状是[num_nodes, *]; 如果是整张图只有一个标签，那么形状是[1, *]。\\n    edge_attr: 存储边的特征。形状是[num_edges, num_edge_features]。\\n'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "torch_geometric提供了一种使用多属性表示图的数据类型Data\n",
    "    x，tensor类型，形状[num_nodes, num_node_features]\n",
    "    edge_index，coo格式的图的边关系，形状为[2, num_edges]\n",
    "    pos: 存储节点的坐标，形状是[num_nodes, num_dimensions]\n",
    "    y: 存储样本标签。如果是每个节点都有标签，那么形状是[num_nodes, *]; 如果是整张图只有一个标签，那么形状是[1, *]。\n",
    "    edge_attr: 存储边的特征。形状是[num_edges, num_edge_features]。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2ecc93b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gen_offline_masks(length, validation_percent=0.2, test_percent=0.1):\n",
    "    test_length = int(length * test_percent)            # 1197\n",
    "    valid_length = int(length * validation_percent)     # 2394\n",
    "    train_length = length - valid_length - test_length  # 8380\n",
    " \n",
    "    samples = torch.randperm(length)  #  length=11971，返回随机打散的0~n-1的tensor数组\n",
    "    train_indices = samples[:train_length]\n",
    "    valid_indices = samples[train_length: train_length + valid_length]\n",
    "    test_indices = samples[train_length + valid_length:]\n",
    "    \n",
    "    return train_indices, valid_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "09409dd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 形成模型数据，train、validation、test mask。\n",
    "def create_offline_homodataset(loadpath, savepath, mode):\n",
    "    features = np.load(os.path.join(loadpath, 'sorted_combined_features_embeddings.npy'))  # (11971, 302)\n",
    "    features = torch.FloatTensor(features)\n",
    "    print('features loaded')\n",
    "    labels = np.load(os.path.join(loadpath, 'sorted_labels.npy'))  # (11971, )\n",
    "    print('labels loaded')\n",
    "    labels = torch.LongTensor(labels)\n",
    "    data = Data(x=features, edge_index=None, y=labels)\n",
    "    data.train_mask, data.val_mask, data.test_mask = gen_offline_masks(len(labels))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b12a7a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create_multi_relational_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "946dca64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load edge data\n",
    "def create_multi_relational_graph(loadpath, relations, mode):\n",
    "    multi_relation_edge_index = [torch.load(loadpath + '/edge_index_%s.pt' % relation) for relation in relations]\n",
    "    print('sparse trans...')\n",
    "    print('edge index loaded')\n",
    "    \n",
    "    return multi_relation_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "96c12141",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1],\n",
       "        [5],\n",
       "        [7],\n",
       "        [2]]),\n",
       " array([[0, 3, 1, 2]]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ix_([1,5,7,2],[0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e696c241",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_multi_relational_graph(loadpath, relations, mode):\n",
    "    for relation in relations:\n",
    "        relation_edge_index = sparse_trans(os.path.join(loadpath, str(mode[1]), 's_m_tid_%s_tid.npz' % relation))\n",
    "        torch.save(relation_edge_index, loadpath + '/' + str(mode[1]) + '/edge_index_%s.pt' % relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "70577d01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f977bbf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### generateMasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7436d150",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 返回training，validation, test的索引indices\n",
    "def generateMasks(length, data_split, train_i, i, validation_percent=0.2, save_path=None, remove_absolete=2):\n",
    "    '''    \n",
    "    Intro:\n",
    "    This function generates train and validation indices for initial/maintenance epochs and test indices for inference(prediction) epochs\n",
    "    If remove_obsolete mode 0 or 1:\n",
    "    For initial/maintenance epochs:\n",
    "    - The first (train_i + 1) blocks (blocks 0, ..., train_i) are used as training set (with explicit labels)\n",
    "    - Randomly sample validation_percent of the training indices as validation indices\n",
    "    For inference(prediction) epochs:\n",
    "    - The (i + 1)th block (block i) is used as test set.\n",
    "    \n",
    "    Note that other blocks (block train_i + 1, ..., i - 1) are also in the graph (without explicit labels, only their features and structural info are leveraged)\n",
    "\n",
    "    :param length: the length of label list\n",
    "    :param data_split: loaded splited data (generated in custom_message_graph.py)\n",
    "    :param train_i, i: flag, indicating for initial/maintenance stage if train_i == i and inference stage for others\n",
    "    :param validation_percent: the percent of validation data occupied in whole dataset\n",
    "    :param save_path: path to save data\n",
    "    :param num_indices_to_remove: number of indices ought to be removed\n",
    "    :returns train indices, validation indices or test indices\n",
    "    '''\n",
    "    # step1: verify total number of nodes\n",
    "    assert length == data_split[i] # 500\n",
    "    \n",
    "    # step2.0: if is in initial/maintenance epochs, generate train and validation indices\n",
    "    if train_i == i:\n",
    "        # step3: randomly shuffle the graph indices\n",
    "        train_indices = torch.randperm(length)  # 返回一个随机打散的0-n-1 tensor数组\n",
    "        # step4: get total number of validation indices\n",
    "        n_validation_samples = int(length * validation_percent)\n",
    "        # step5: sample n_validation_samples validation indices and use the rest as training indices\n",
    "        validation_indices = train_indices[:n_validation_samples]\n",
    "        train_indices = train_indices[n_validation_samples:]\n",
    "        # step6: save indices\n",
    "        if save_path is not None:\n",
    "            torch.save(train_indices, save_path + '/train_indices.pt')\n",
    "            torch.save(validation_indices, save_path + '/validation_indices.pt')\n",
    "        return train_indices, validation_indices\n",
    "    # step2.1: if is in inference(prediction) epochs, generate test indices\n",
    "    else:\n",
    "        test_indices = torch.arange(0, (data_split[i]), dtype=torch.long)\n",
    "        if save_path is not None:\n",
    "            torch.save(test_indices, save_path + '/test_indices.pt')\n",
    "        return test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1b57ac2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models/result/FinEvent result/'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d824b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### mysampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "feb9e96e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from typing import List, Optional, Tuple, NamedTuple, Union, Callable\n",
    "from scipy import sparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor\n",
    "from torch_geometric.loader import NeighborSampler, RandomNodeSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fcac323d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NeighborSampler返回结果：batch_size, n_id,adjs(edge_index,e_id,size)\n",
    "class MySampler(object):\n",
    "    def __init__(self, sampler) -> None:\n",
    "        super().__init__()\n",
    "        self.sampler = sampler\n",
    "    \n",
    "    def sample(self, multi_relational_edge_index: List[Tensor], node_idx, sizes, batch_size):\n",
    "        if self.sampler == 'RL_sampler':\n",
    "            return self._RL_sample(multi_relational_edge_index, node_idx, sizes, batch_size)\n",
    "        elif self.sampler == 'randdom_sampler':\n",
    "            return self._random_sample(multi_relational_edge_index, node_idx, batch_size)\n",
    "        elif self.sampler == 'const_sampler':\n",
    "            return self._const_sample(multi_relational_edge_index, node_idx, batch_size)\n",
    "    \n",
    "    def _RL_sample(self, multi_relational_edge_index: List[Tensor], node_idx, sizes, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        for id, edge_index in enumerate(multi_relational_edge_index):  # 返回数据和数据下标,0: (2,761215); 1:(2,23565); 2:(2,36183)\n",
    "            # NeighborSampler,给定mini-batch的节点和图卷积的层数L，以及每一层需要采样的邻居数目sizes\n",
    "            loader = NeighborSampler(edge_index=edge_index, \n",
    "                                     sizes=sizes, \n",
    "                                     node_idx=node_idx, \n",
    "                                     return_e_id=False,\n",
    "                                     batch_size=batch_size, \n",
    "                                     num_workers=0)  \n",
    "            '''\n",
    "            采样完成后，返回结果(batch_size, n_id, adjs)，\n",
    "                其中batch_size就是mini-batch的节点数目，\n",
    "                n_id是包含所有在L层卷积中遇到的节点的list，且target节点在n_id前几位。\n",
    "                adjs是一个list，包含了从第L层到第1层采样的结果，所以adjs中的子图是从大到小的。每一层采样返回的结果具体形式为 (edge_index, e_id, size)。\n",
    "                    edge_index是采样得到的bipartite子图中source节点到target节点的边。\n",
    "                    e_id是edge_index的边在原始大图中的IDs，\n",
    "                    size就是bipartite子图的shape。\n",
    "            '''\n",
    "            # NeighborSampler返回结果：batch_size-100, n_id,adjs(edge_index,e_id,size)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):  \n",
    "                outs.append(adjs)  # adjs包括：edge_index, bipartite子图中source节点到target节点的边，e_id是在原始图中的id，size是子图shape\n",
    "                all_n_ids.append(n_ids)  # n_ids是包含所有在L层卷积中遇到的节点的list，且target节点在n_ids前几位\n",
    "            \n",
    "            assert id == 0  # 断言，条件为false时触发，中断程序\n",
    "        return outs, all_n_ids\n",
    "    \n",
    "    def _random_sample(self, multi_relational_edge_index: List[Tensor], node_idx, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        sizes = [random.randint(10,100), random.randint(10,50)]\n",
    "        for edge_index in multi_relational_edge_index:\n",
    "            loader = NeighborSampler(edge_index=edge_index, sizes=sizes, node_idx=node_idx, return_e_id=False,\n",
    "                                    batch_size=batch_size, num_workers=0)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):\n",
    "                outs.append(adjs)\n",
    "                all_n_ids.append(n_ids)\n",
    "            assert id == 0\n",
    "        return outs, all_n_ids\n",
    "\n",
    "    def _const_sample(self, multi_relational_edge_index: List[Tensor], node_idx, batch_size):\n",
    "        outs = []\n",
    "        all_n_ids = []\n",
    "        sizes = [25, 15]\n",
    "        for edge_index in multi_relational_edge_index:\n",
    "            loader = NeighborSampler(edge_index=edge_index, sizes=sizes, node_idx=node_idx, return_e_id=False,\n",
    "                                    batch_size=batch_size, num_workers=0)\n",
    "            for id, (_, n_ids, adjs) in enumerate(loader):\n",
    "                outs.append(adjs)\n",
    "                all_n_ids.append(n_ids)\n",
    "            assert id == 0\n",
    "        return outs, all_n_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37081a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### save_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "3dc97cb7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_embeddings(extracted_features, save_path):\n",
    "    torch.save(extracted_features, save_path + '/final_embeddings.pt')\n",
    "    print('extracted features saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05947705",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## MarGNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "870be71e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.functional import Tensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3e9386ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# MarGNN model 返回node embedding representation\n",
    "class MarGNN(nn.Module):\n",
    "    # GNN_args=(feat_dim-302, args.hidden_dim-128, args.out_dim-64, args.heads-4);num_relations=3;inter_opt='cat_w_avg';heads=4\n",
    "    def __init__(self, GNN_args, num_relations, inter_opt, is_shared=False):\n",
    "        super(MarGNN, self).__init__()\n",
    "        \n",
    "        self.num_relations = num_relations  # 3\n",
    "        self.inter_opt = inter_opt          # \n",
    "        self.is_shared = is_shared\n",
    "        # relation 内\n",
    "        if not self.is_shared:\n",
    "            self.intra_aggs = torch.nn.ModuleList([Intra_AGG(GNN_args) for _ in range(self.num_relations)])  # 输出向量64维，3 relations\n",
    "        else:\n",
    "            self.intra_aggs = Intra_AGG(GNN_args) # shared parameters\n",
    "        # relation 间\n",
    "        if self.inter_opt == 'cat_w_avg_mlp' or 'cat_wo_avg_mlp':\n",
    "            in_dim, hid_dim, out_dim, heads = GNN_args\n",
    "            mlp_args = self.num_relations * out_dim, out_dim\n",
    "            self.inter_agg = Inter_AGG(mlp_args)\n",
    "        else:\n",
    "            self.inter_agg = Inter_AGG()\n",
    "    \n",
    "    def forward(self, x, adjs, n_ids, device, RL_thresholds):\n",
    "        # RL_threshold: tensor([[.5], [.5], [.5]])\n",
    "        if RL_thresholds is None:\n",
    "            RL_thresholds = torch.FloatTensor([[1.], [1.], [1.]])\n",
    "        if not isinstance(RL_thresholds, Tensor):\n",
    "            RL_thresholds = torch.FloatTensor(RL_thresholds)\n",
    "        RL_thresholds = RL_thresholds.to(device)\n",
    "        \n",
    "        features = []\n",
    "        for i in range(self.num_relations):  \n",
    "            if not self.is_shared:\n",
    "                # print('Intra Aggregation of relation %d' % i)\n",
    "                features.append(self.intra_aggs[i](x[n_ids[i]], adjs[i], device))\n",
    "            else:\n",
    "                # shared parameters\n",
    "                # print('Shared Intra Aggregation ...')\n",
    "                features.append(self.intra_aggs(x[n_ids[i]], adjs[i], device))\n",
    "        \n",
    "        features = torch.stack(features, dim=0)    # (3, 100, 64)\n",
    "        features = self.inter_agg(features, RL_thresholds, self.inter_opt)\n",
    "        \n",
    "        return features  # tensor, (100,192)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e77a91",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FinEvent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b044c2e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import gc  # garbage cleaning package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "505fb925",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models\\\\FinEvent Models'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8391b856",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FinEvent():\n",
    "    def __init__(self, args) -> None:\n",
    "        # register args\n",
    "        self.args = args\n",
    "    \n",
    "    def inference(self,  # inference = prediction\n",
    "                 train_i, i,\n",
    "                 metrics,\n",
    "                 embedding_save_path,\n",
    "                 loss_fn,\n",
    "                 model: MarGNN,\n",
    "                 RL_thresholds=None,\n",
    "                 loss_fn_dgi=None):\n",
    "        # make dir for graph i\n",
    "        # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "        save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "        if not os.path.isdir(save_path_i):\n",
    "            os.mkdir(save_path_i)\n",
    "         \n",
    "        # load data\n",
    "        relation_ids: List[str] = ['entity', 'userid', 'word']  # typing package\n",
    "        homo_data = create_homodataset(self.args.data_path, [train_i, i], self.args.validation_percent) # get training,validation,test数据\n",
    "        multi_r_data = create_multi_relational_graph(self.args.data_path, relation_ids, [train_i, i])  # load relation data\n",
    "        num_relations = len(multi_r_data)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() and self.args.use_cuda else 'cpu')\n",
    "        \n",
    "        # input dimension (300 in our paper)\n",
    "        features = homo_data.x  # x是features embeddings\n",
    "        feat_dim = features.size(1)\n",
    "        \n",
    "        # prepare graph configs for node filtering\n",
    "        if self.args.is_initial:\n",
    "            print('prepare node configures...')\n",
    "            pre_node_dist(multi_r_data, homo_data.x, save_path_i)\n",
    "            filter_path = save_path_i\n",
    "        else:\n",
    "            filter_path = self.args.data_path + str(i)\n",
    "        \n",
    "        if model is None:\n",
    "            assert 'Cannot fine pre-trained model'\n",
    "        \n",
    "        # directly predict\n",
    "        message = '\\n-----------------Directly predict on block' + str(i) + '-----------------\\n'\n",
    "        print(message)\n",
    "        print('RL Threshold using in this block:', RL_thresholds)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        test_indices, labels = homo_data.test_mask, homo_data.y\n",
    "        test_num_samples = test_indices.size(0)\n",
    "        \n",
    "        sampler = MySampler(self.args.sampler)\n",
    "        \n",
    "        # filter neighbor in advance to fit with neighbor sampling\n",
    "        filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) if RL_thresholds is not None and \\\n",
    "                                self.args.sampler == 'RL_sampler' else multi_r_data\n",
    "        \n",
    "        # batch testing\n",
    "        extract_features = torch.FloatTensor([])\n",
    "        num_batches = int(test_num_samples / self.args.batch_size) + 1\n",
    "        with torch.no_grad():  # 在该模块下，所有计算得出的tensor的requires_grad都自动设置为False，不自动反向传播求导\n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                \n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch + 1) * self.args.batch_size, test_num_samples)\n",
    "                batch_nodes = test_indices[i_start:i_end]\n",
    "                \n",
    "                # sampling neighbors of batch nodes\n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx= batch_nodes, sizes=[-1, -1], \n",
    "                                             batch_size= self.args.batch_size)\n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                batch_seconds_spent = time.time() - start_batch\n",
    "                \n",
    "                # for we haven't shuffle the test indices(see utils.py)\n",
    "                # the output embeddings can be simply stacked together\n",
    "                extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "                \n",
    "                del pred\n",
    "                gc.collect()  # 清除缓存\n",
    "        \n",
    "        save_embeddings(extract_features, save_path_i)\n",
    "        # 返回评价指标nmi，ami，ari\n",
    "        test_nmi = evaluate(extract_features,\n",
    "                           labels,\n",
    "                           indices=test_indices,\n",
    "                           epoch=-1, # just for test\n",
    "                           num_isolated_nodes=0,\n",
    "                           save_path= save_path_i,\n",
    "                           is_validation= False,\n",
    "                           cluster_type= self.args.cluster_type)\n",
    "        del homo_data, multi_r_data, features, filtered_multi_r_data\n",
    "        torch.cuda.empty_cache()  # 释放显存\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # train on initial/maintenance graphs, t==0 or t % window_size == 0 in this paper\n",
    "    def initial_maintain(self,\n",
    "                        train_i, i,\n",
    "                        metrics,\n",
    "                        embedding_save_path,\n",
    "                        loss_fn,\n",
    "                        model=None,\n",
    "                        loss_fn_dgi=None):\n",
    "        '''\n",
    "        :param i:\n",
    "        :param data_split:\n",
    "        :param metrics:\n",
    "        :param embedding_save_path:\n",
    "        :param loss_fn:\n",
    "        :param model:\n",
    "        :param loss_fn_dgi:\n",
    "        :return:\n",
    "        '''\n",
    "        # make dir for graph i\n",
    "        # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "        save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "        if not os.path.isdir(save_path_i):\n",
    "            os.mkdir(save_path_i)\n",
    "        \n",
    "        # load data\n",
    "        relation_ids: List[str] = ['entity', 'userid', 'word']\n",
    "        homo_data = create_homodataset(self.args.data_path, [train_i, i], self.args.validation_percent)\n",
    "        multi_r_data = create_multi_relational_graph(self.args.data_path, relation_ids, [train_i, i])  # relation data\n",
    "        num_relations = len(multi_r_data)\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() and self.args.use_cuda else 'cpu')\n",
    "        \n",
    "        # input dimension (300 in our paper)\n",
    "        num_dim = homo_data.x.size(0)  # embeddings num\n",
    "        feat_dim = homo_data.x.size(1) # embeddings dimension\n",
    "        \n",
    "        # prepare graph configs for node filtering\n",
    "        if self.args.is_initial:\n",
    "            print('prepare node %configures...')\n",
    "            cal_similarity_node_neighbors(multi_r_data, homo_data.x, save_path_i)\n",
    "            filter_path = save_path_i\n",
    "        else:\n",
    "            filter_path = self.args.data_path + str(i)\n",
    "        \n",
    "        if model is None: # pre-training stage in our paper\n",
    "            # print('Pre-Train Stage')\n",
    "            model = MarGNN((feat_dim, self.args.hidden_dim, self.args.out_dim, self.args.heads),\n",
    "                          num_relations=num_relations, inter_opt=self.args.inter_opt, is_shared=self.args.is_shared)\n",
    "        \n",
    "        # define sampler\n",
    "        sampler = MySampler(self.args.sampler)  # top-p neighbors\n",
    "        # load model to device\n",
    "#         model.to(device)\n",
    "        \n",
    "        # initialize RL thresholds\n",
    "        RL_thresholds = torch.FloatTensor(self.args.threshold_start0)  # [[0.2],[0.2],[0.2]]\n",
    "        \n",
    "        # define optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=self.args.lr, weight_decay=1e-4)\n",
    "        \n",
    "        # record training log\n",
    "        message = '\\n------------- Start initial training / maintaining using block ' + str(i) + '----------\\n'\n",
    "        print(message)\n",
    "        with open(save_path_i + '/log.txt', 'a') as f:\n",
    "            f.write(message)\n",
    "        \n",
    "        # record the highest validation nmi ever got for early stopping\n",
    "        best_vali_nmi = 1e-9\n",
    "        best_epoch = 0\n",
    "        wait = 0\n",
    "        # record validation nmi of all epochs before early stop\n",
    "        all_vali_nmi = []\n",
    "        # record the time spent in seconds on each batch of all training/maintaining epochs\n",
    "        seconds_train_batches = []\n",
    "        # record the time spent in mins on each epoch\n",
    "        mins_train_epochs = []\n",
    "        \n",
    "        # step13: start epoch training\n",
    "        for epoch in range(self.args.n_epochs):  # n_epochs=50\n",
    "            start_epoch = time.time()\n",
    "            losses = []\n",
    "            total_loss = 0.0\n",
    "            \n",
    "            for metric in metrics:\n",
    "                metric.reset()\n",
    "                \n",
    "            # Multi-Agent\n",
    "            \n",
    "            # filter neighbor in advance to fit with neighbor sampling\n",
    "            if epoch >= self.args.RL_start0 and self.args.sampler == 'RL_sampler':  # RL_start0=0\n",
    "                filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) \n",
    "            else:\n",
    "                filtered_multi_r_data = multi_r_data\n",
    "                \n",
    "            model.train()\n",
    "            train_num_samples, valid_num_samples = homo_data.train_mask.size(0), homo_data.val_mask.size(0)\n",
    "            all_num_samples = train_num_samples + valid_num_samples\n",
    "            \n",
    "            # mini-batch training------------------------------------------------------------------\n",
    "            num_batches = int(train_num_samples / self.args.batch_size) + 1  # batch_size=100\n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch + 1) * self.args.batch_size, train_num_samples)\n",
    "                batch_nodes = homo_data.train_mask[i_start:i_end]  # 从training data中取出mini-batch用于训练\n",
    "                batch_labels = homo_data.y[batch_nodes]\n",
    "                \n",
    "                # sampling neighobrs from mini-batch nodes \n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_ids=batch_nodes, sizes=[-1,-1], batch_size=self.args.batch_size)\n",
    "                \n",
    "                optimizer.zero_grad() \n",
    "                \n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                \n",
    "                loss_outputs = loss_fn(pred, batch_labels)\n",
    "                \n",
    "                loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "                \n",
    "                losses.append(loss.item())\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                for metric in metrics:\n",
    "                    metric(pred, batch_labels, loss_outputs)\n",
    "                    \n",
    "                if batch % self.args.log_interval == 0:\n",
    "                    message = 'Train: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(batch * self.args.batch_size, train_num_samples, 100. * batch / ((train_num_samples // self.args.batch_size) + 1), np.mean(losses))\n",
    "                    \n",
    "                    for metric in metrics:\n",
    "                        message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "                    \n",
    "                    with open(save_path_i + '/log.txt', 'a') as f:\n",
    "                        f.write(message)\n",
    "                    losses = []\n",
    "                del pred, loss_outputs\n",
    "                gc.collect()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()  # 更新参数\n",
    "                \n",
    "                batch_seconds_spent = time.time() - start_batch\n",
    "                seconds_train_batches.append(batch_seconds_spent)\n",
    "                \n",
    "                del pred\n",
    "                gc.collect()\n",
    "            \n",
    "            # step 14: print loss\n",
    "            total_loss /= (batch + 1)\n",
    "            message = 'Epoch: {}/{}. Average loss: {:.4f}'.format(epoch, self.args.n_epochs, total_loss)\n",
    "            for metric in metrics:\n",
    "                message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "            mins_spent = (time.time() - start_epoch) / 60\n",
    "            message += '\\nThis epoch took {:.2f} mins'.format(mins_spent)\n",
    "            message += '\\n'\n",
    "            print(message)\n",
    "            \n",
    "            with open(save_path_i + '/log.txt', 'a') as f:\n",
    "                f.write(message)\n",
    "            mins_train_epochs.append(mins_spent)\n",
    "            \n",
    "            # validation-------------------------------------------------------------------------\n",
    "            # infer the representation of all tweets\n",
    "            model.eval()\n",
    "            \n",
    "            # we recommand to forward all nodes and select the validation indices instead\n",
    "            extract_features = torch.FloatTensor([])\n",
    "            \n",
    "            num_batches = int(all_num_samples / self.args.batch_size) + 1\n",
    "            \n",
    "            # all mask are then splited into mini-batch in order\n",
    "            all_mask = torch.arange(0, num_dim, dtype=torch.long)\n",
    "            \n",
    "            for batch in range(num_batches):\n",
    "                start_batch = time.time()\n",
    "                # split batch\n",
    "                i_start = self.args.batch_size * batch\n",
    "                i_end = min((batch+1) * self.args.batch_size, all_num_samples)\n",
    "                batch_nodes = all_mask[i_start:i_end]  # \n",
    "                batch_labels = homo_data.y[batch_nodes]\n",
    "                \n",
    "                # sampling neighbors of batch nodes\n",
    "                adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=self.args.batch_size)\n",
    "                \n",
    "                pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "                \n",
    "                extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "                del pred\n",
    "                gc.collect()\n",
    "            # save_embeddings(extract_reatures, save_path_i)\n",
    "            # evaluate the model: conduct kMeans clustering on the validation and report NMI\n",
    "            validation_nmi = evaluate(extract_features[homo_data.val_mask],\n",
    "                                     homo_data.y,\n",
    "                                     epoch=epoch,\n",
    "                                     num_isolated_nodes=0,\n",
    "                                     save_path=save_path_i,\n",
    "                                     is_validation=True,\n",
    "                                     cluster_type=self.args.cluster_type)\n",
    "            all_vali_nmi.append(validation_nmi)\n",
    "            \n",
    "            # step16: early stop\n",
    "            if validation_nmi > best_vali_nmi:\n",
    "                best_vali_nmi = validation_nmi\n",
    "                best_epoch = epoch\n",
    "                wait = 0\n",
    "                # save model\n",
    "                model_path = save_path_i + '/models'\n",
    "                if (epoch == 0) and (not os.path.isdir(model_path)):\n",
    "                    os.mkdir(model_path)\n",
    "                p = model_path + '/best.pt'\n",
    "                torch.save(model.state_dict(), p)  # 保存模型，OrderDict存储网络结构的名字和对应的参数\n",
    "                print('Best model saved after epoch ', str(epoch))\n",
    "            else:\n",
    "                wait += 1\n",
    "            if wait >= self.args.patience:\n",
    "                print('Saved all_mins_spent')\n",
    "                print('Early stopping at epoch ', str(epoch))\n",
    "                print('Best model was at epoch ', str(best_epoch))\n",
    "                break\n",
    "            # end one epoch\n",
    "        \n",
    "        # save all validation mi\n",
    "        np.save(save_path_i + '/all_vali_nmi.npy', np.asarray(all_vali_nmi))\n",
    "        # save time spent on epochs\n",
    "        np.save(save_path_i + '/mins_train_epochs.npy', np.asarray(mins_train_epochs))\n",
    "        print('Saved mins_train_epochs')\n",
    "        # save time spent on batches\n",
    "        np.save(save_path_i + '/seconds_train_batches.npy', np.asarray(seconds_train_batches))\n",
    "        print('Best model loaded.')\n",
    "        \n",
    "        del homo_data, multi_r_data\n",
    "        torch.cuda.empty_cache()  # 释放显存\n",
    "        \n",
    "        return model, RL_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "24e986c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 1, 0])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e48b2eb2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2,43,2,42,12,454])[0]\n",
    "np.where(a<5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb96f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "142b5964",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# utility，功能\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "dd4a1249",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 交集\n",
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cd340",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### run kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "76afe613",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_kmeans(extract_features, extract_labels, indices, isoPath=None):\n",
    "    # extract the features and labels of the test tweets\n",
    "    if isoPath is not None:\n",
    "        # Remove isolated points\n",
    "        temp = torch.load(isoPath)\n",
    "        temp = temp.cpu().detach().numpy()  # detach()阻断反向传播，返回值为tensor；numpy()将tensor转换为numpy\n",
    "        non_isolated_index = list(np.where(temp != 1)[0]) # np.where返回符合条件元素的索引index\n",
    "        indices = intersection(indices, non_isolated_index)  # 取交集\n",
    "    # Extract labels\n",
    "    extract_labels = extract_labels.cpu().numpy()\n",
    "    labels_true = extract_labels[indices]\n",
    "    \n",
    "    # Extrac features\n",
    "    X = extract_features.cpu().detach().numpy()\n",
    "    assert labels_true.shape[0] == X.shape[0]  # assert断言，在判断式false时触发异常\n",
    "    n_test_tweets = X.shape[0]  # 100\n",
    "    \n",
    "    # Get the total number of classes\n",
    "    n_classes = len(set(labels_true.tolist()))  # unique()和nunique()不香吗？\n",
    "    \n",
    "    # k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_classes, random_state=0).fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    nmi = metrics.normalized_mutual_info_score(labels_true, labels)  # 计算归一化互信息\n",
    "    ami = metrics.adjusted_mutual_info_score(labels_true, labels)\n",
    "    ari = metrics.adjusted_rand_score(labels_true, labels)  # 计算兰德系数\n",
    "    \n",
    "    # Return number of test tweets, number of classes covered by the test tweets, and KMeans clustering NMI\n",
    "    return n_test_tweets, n_classes, nmi, ami, ari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c9b60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b2f25",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### metrics operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ce1718f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d7d6ffa5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        raise NotImplementedError  # 没有重写，就会报错\n",
    "    \n",
    "    def reset(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def value(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def name(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b7a5ca",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### accumulate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "531135fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 累加平均metrics\n",
    "class AccumulateAccuracy(Metric):\n",
    "    '''\n",
    "    works with classification model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        pred = outputs[0].data.max(1, keepdim=True)[1]\n",
    "        self.correct += pred.eq(target[0].data.view_as(pred)).cpu().sum()\n",
    "        self.total += target[0].size(0)\n",
    "        return self.value()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "    \n",
    "    def value(self):\n",
    "        return 100 * float(self.correct) / self.total\n",
    "    \n",
    "    def name(self):\n",
    "        return 'Accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f913ab",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### average metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e64e0f3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 非零平均\n",
    "class AverageNonzeroTripletsMetric(Metric):\n",
    "    '''\n",
    "    Counts average number of nonzero triplets found in minibatches\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.values = []\n",
    "    \n",
    "    def __call__(self, outputs, target, loss):\n",
    "        self.values.append(loss[1])\n",
    "        return self.value()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.values = []\n",
    "    \n",
    "    def value(self):\n",
    "        return np.mean(self.values)\n",
    "    \n",
    "    def name(self):\n",
    "        return 'Average nonzero triplets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f1e24a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "29dad01a",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(extract_features, extract_labels, indices, epoch, num_isolated_nodes, save_path,\n",
    "             is_validation=True, cluster_type='kmeans'):\n",
    "    message = ''\n",
    "    message += '\\nEpoch '\n",
    "    message += str(epoch)\n",
    "    message += '\\n'\n",
    "    \n",
    "    # with isolated nodes\n",
    "    if cluster_type == 'kmeans':\n",
    "        n_tweets, n_classes, nmi, ami, ari = run_kmeans(extract_features, extract_labels, indices)\n",
    "    elif cluster_type == 'dbscan':\n",
    "        pass\n",
    "    \n",
    "    if is_validation:\n",
    "        mode = 'validation'\n",
    "    else:\n",
    "        mode = 'test'\n",
    "    message += '\\tNumber of ' + mode + ' tweets: '\n",
    "    message += str(n_tweets)\n",
    "    message += '\\n\\tNumber of classes covered by ' + mode + ' tweets: '\n",
    "    message += str(n_classes)\n",
    "    message += '\\n\\t' + mode + ' NMI: '\n",
    "    message += str(nmi)\n",
    "    message += '\\n\\t' + mode + 'AMi: '\n",
    "    message += str(ami)\n",
    "    message += '\\n\\t' + mode + 'ARI'\n",
    "    message += str(ari)\n",
    "    if cluster_type == 'dbscan':\n",
    "        message += '\\n\\t' + mode + ' best_eps: '\n",
    "        message += '\\n\\t' + mode + ' best_min_Pts: '\n",
    "    \n",
    "    if num_isolated_nodes != 0:\n",
    "        # without isolated nodes\n",
    "        message += '\\n\\tWithout isolated nodes:'\n",
    "        n_tweets, n_classes, nmi, ami, ari = run_kmeans(extract_features, extract_labels, indices, \n",
    "                                                       save_path + '/isolated_nodes.pt')\n",
    "        message += '\\tNumber of ' + mode + 'tweets: '\n",
    "        message += str(n_tweets)\n",
    "        message += '\\n\\tNumber of classes covered by ' + mode + ' tweets'\n",
    "        message += str(n_classes)\n",
    "        message += '\\n\\t' + mode + 'NMI: '\n",
    "        message += str(nmi)\n",
    "        message += '\\n\\t' + mode + 'AMI: '\n",
    "        message += str(ami)\n",
    "        message += '\\n\\t' + mode + 'ARI: '\n",
    "        message += str(ari)\n",
    "    message += '\\n'\n",
    "    \n",
    "    with open(save_path + '/evaluate.txt', 'a') as f:\n",
    "        f.write(message)\n",
    "    print(message)\n",
    "    \n",
    "    np.save(save_path + '/%s_metric.npy' % mode, np.asarray([nmi, ami, ari]))\n",
    "    if is_validation:\n",
    "        return nmi\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9823d054",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Run_FinEvent_Offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fdaee841",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstep 1. run utils/generate_initial_features.py to generate the initial features for the messages\\n\\nstep 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\\n\\nstep 3. run utils/save_edge_index.py in advance to acclerate the training process.\\n\\nstep 4. run offline.py\\n'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "step 1. run utils/generate_initial_features.py to generate the initial features for the messages\n",
    "\n",
    "step 2. run utils/custom_message_graph.py to construct incremental message graphs. To construct small message graphs for test purpose, set test=True when calling construct_incremental_dataset_0922(). To use all the messages (see Appendix of the paper for a statistic of the number of messages in the graphs), set test=False.\n",
    "\n",
    "step 3. run utils/save_edge_index.py in advance to acclerate the training process.\n",
    "\n",
    "step 4. run offline.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "802957b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "from time import localtime, strftime  # strftime() 函数用于格式化时间，返回以可读字符串表示的当地时间\n",
    "\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import time \n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0185ca5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## define paramerters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fb42f7bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def args_register():\n",
    "    parser = argparse.ArgumentParser()  # 创建参数对象\n",
    "    # 添加参数\n",
    "    parser.add_argument('--n_epochs', default=5, type=int, help='Number of initial-training/maintenance-training epochs.')\n",
    "    parser.add_argument('--window_size', default=3, type=int, help='Maintain the model after predicting window_size blocks.')\n",
    "    parser.add_argument('--patience', default=5, type=int, help='Early stop if perfermance did not improve in the last patience epochs.')\n",
    "    parser.add_argument('--margin', default=3, type=float, help='Margin for computing triplet losses')  # 收益\n",
    "    parser.add_argument('--lr', default=1e-3, type=float, help='Learning rate')\n",
    "    \n",
    "    parser.add_argument('--batch_size', default=100, type=int, help='Batch size (number of nodes sampled to compute triplet loss in each batch)')\n",
    "    parser.add_argument('--hidden_dim', default=128, type=int, help='Hidden dimension')\n",
    "    parser.add_argument('--out_dim', default=64, type=int, help='Output dimension of tweet representation')\n",
    "    parser.add_argument('--heads', default=4, type=int, help='Number of heads used in GAT')\n",
    "    parser.add_argument('--validation_percent', default=0.2, type=float, help='Percentage of validation nodes(tweets)')\n",
    "    parser.add_argument('--use_hardest_neg', dest='use_hardest_neg', default=False, action='store_true', \n",
    "                        help='If true, use hardest negative messages to form triplets. Otherwise use random ones')\n",
    "    parser.add_argument('--is_shared', default=False)\n",
    "    parser.add_argument('--inter_opt', default='cat_w_avg')\n",
    "    parser.add_argument('--is_initial', default=True)\n",
    "    parser.add_argument('--sampler', default='RL_sampler')\n",
    "    parser.add_argument('--cluster_type', default='kmeans', help='Types of clustering algorithms') # DBSCAN\n",
    "    \n",
    "    # RL-0，第一个强化学习是learn the optimal neighbor weights\n",
    "    parser.add_argument('--threshold_start0', default=[[0.2],[0.2],[0.2]], type=float, \n",
    "                        help='The initial value of the filter threshold for state1 or state3')\n",
    "    parser.add_argument('--RL_step0', default=0.02, type=float, help='The starting epoch of RL for state1 or state3')\n",
    "    parser.add_argument('--RL_start0', default=0, type=int, help='The starting epoch of RL for state1 or state3')\n",
    "    \n",
    "    # RL-1，第二个强化学习是learn the optimal DBSCAN params.\n",
    "    parser.add_argument('--eps_start', default=0.001, type=float, help='The initial value of the eps for state2')\n",
    "    parser.add_argument('--eps_step', default=0.02, type=float, help='The step size of eps for state2')\n",
    "    parser.add_argument('--min_Pts_start', default=2, type=int, help='The initial value of the min_Pts for state2')\n",
    "    parser.add_argument('--min_Pts_step', default=1, type=int, help='The step size of min_Pts for state2')\n",
    "    \n",
    "    # other arguments\n",
    "    parser.add_argument('--use_cuda', dest='use_cuda', default=True, action='store_true', help='Use cuda')\n",
    "    parser.add_argument('--data_path', default=project_path + '/result/FinEvent result/offline dataset/', type=str, help='graph data path')\n",
    "    parser.add_argument('--result_path', default=project_path + '/result/FinEvent result/offline result/', type=str, help='Path of features, labels and edges')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--mask_path', default=None, type=str, help='File path that contains the training, validation and test masks')\n",
    "    # format: './incremental_0808/incremental_graphs_0808/embeddings_XXXX'\n",
    "    parser.add_argument('--log_interval', default=10, type=int, help='Log interval')\n",
    "    \n",
    "    args = parser.parse_args(args=[])  # 解析参数\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6d36e98a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\PycharmProjects\\\\GNN_Event_Detection_models'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826bc9e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## offline FinEvent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "21115429",
   "metadata": {
    "code_folding": [
     171
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def offline_FinEvent_model(train_i, i,\n",
    "                 args,\n",
    "                 metrics,\n",
    "                 embedding_save_path,\n",
    "                 loss_fn,\n",
    "                 model=None,\n",
    "                 loss_fn_dgi=None):\n",
    "    # step1: make dir for graph i\n",
    "    # ./incremental_0808//embeddings_0403005348/block_xxx\n",
    "    save_path_i = embedding_save_path + '/block_' + str(i)\n",
    "    if not os.path.isdir(save_path_i):\n",
    "        os.mkdir(save_path_i)\n",
    "    \n",
    "    # step2: load data\n",
    "    # 创建offline数据集\n",
    "    homo_data = create_offline_homodataset(args.data_path, args.result_path, [train_i, i])\n",
    "    # 加载edge数据，返回一个edge list: 3，包含[entity_relation_edge, userid_relation_edge, word_relation_edge]\n",
    "    # shape分别是：tensor:(2,3716829)、tensor:(2, 56229)、tensor(2, 122969)\n",
    "    relation_ids: List[str] = ['entity', 'userid', 'word']\n",
    "    multi_r_data = create_multi_relational_graph(args.data_path, relation_ids, [train_i, i])\n",
    "    num_relations = len(multi_r_data)  # 3\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() and args.use_cuda else 'cpu')\n",
    "    \n",
    "    # input dimension (300 in our paper)\n",
    "    num_dim = homo_data.x.size(0)   # 输入数据的行，代表节点数\n",
    "    feat_dim = homo_data.x.size(1)  # 输入数据的列，代表embedding dimension\n",
    "    \n",
    "    # prepare graph configs for node filtering\n",
    "    if args.is_initial:\n",
    "        print('prepare node configures...')\n",
    "        cal_similarity_node_neighbors(multi_r_data, homo_data.x, save_path_i)\n",
    "        filter_path = save_path_i\n",
    "    else:\n",
    "        filter_path = args.data_path + str(i)\n",
    "    \n",
    "    if model is None:  # pre-training stage in our paper\n",
    "        print('Pre-Train Stage...')\n",
    "        model = MarGNN((feat_dim, args.hidden_dim, args.out_dim, args.heads), \n",
    "                      num_relations=num_relations, inter_opt=args.inter_opt,is_shared=args.is_shared)\n",
    "    \n",
    "    # define sampler\n",
    "    sampler = MySampler(args.sampler)  # 'RL_sampler'\n",
    "    # load model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # initialize RL thresholds\n",
    "    RL_thresholds = torch.FloatTensor(args.threshold_start0)  # [[0.2],[0.2],[0.2]]\n",
    "    \n",
    "    # define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay=1e-4)\n",
    "    \n",
    "    # record training log\n",
    "    message = '\\n------Start initial training /maintaining using block' + str(i) + '------\\n'\n",
    "    print(message)\n",
    "    with open(save_path_i + '/log.txt', 'a') as f:\n",
    "        f.write(message)\n",
    "    \n",
    "    # step12.0: record the highest validation nmi ever got for early stopping\n",
    "    best_vali_nmi = 1e-9\n",
    "    best_epoch = 0\n",
    "    wait = 0\n",
    "    # step12.1: record validation nmi of all epochs before early stop\n",
    "    all_vali_nmi = []\n",
    "    # step12.2: record the time spent in seconds on each batch of all training/maintaining epochs\n",
    "    seconds_train_batches = []\n",
    "    # step12.3: record the time spent in mins on each epoch\n",
    "    mins_train_epochs = []\n",
    "    \n",
    "    # step13: start training------------------------------------------------------------\n",
    "    print('----------------------------------training----------------------------')\n",
    "    for epoch in range(args.n_epochs):  # n_epochs=50\n",
    "        start_epoch = time.time()\n",
    "        losses = []\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for metric in metrics:\n",
    "            metric.reset()\n",
    "        \n",
    "        # Multi-Agent\n",
    "        \n",
    "        # filter neighbor in adbvance to fit with neighbor sampling, return filtered neighbor index\n",
    "        if epoch >= args.RL_start0 and args.sampler == 'RL_sampler':  # RL_start0=0.02\n",
    "            filtered_multi_r_data = RL_neighbor_filter(multi_r_data, RL_thresholds, filter_path) # list:3,(2,761215),(2,23565),(2,36183)\n",
    "        else:\n",
    "            filtered_multi_r_data = multi_r_data\n",
    "        \n",
    "        # step13.0: forward\n",
    "        model.train()\n",
    "        \n",
    "        #     data.train_mask, data.val_mask, data.test_mask = gen_offline_masks(len(labels))\n",
    "        '''train: 8380, val: 2394, test:1197'''\n",
    "        train_num_samples, valid_num_samples, test_num_samples = homo_data.train_mask.size(0), homo_data.val_mask.size(0), homo_data.test_mask.size(0)\n",
    "        all_num_samples = train_num_samples + valid_num_samples + test_num_samples\n",
    "        \n",
    "        torch.save(homo_data.train_mask, save_path_i + '/train_mask.pt')\n",
    "        torch.save(homo_data.val_mask, save_path_i + '/valid_mask.pt')\n",
    "        torch.save(homo_data.test_mask, save_path_i + '/test_mask.pt')\n",
    "        \n",
    "        # mini-batch training\n",
    "        num_batches = int(train_num_samples / args.batch_size) + 1  # batch_size=100\n",
    "        for batch in range(num_batches):\n",
    "            start_batch = time.time()\n",
    "            # split batch\n",
    "            i_start = args.batch_size * batch\n",
    "            i_end = min((batch + 1) * args.batch_size, train_num_samples)\n",
    "            batch_nodes = homo_data.train_mask[i_start:i_end]\n",
    "            batch_labels = homo_data.y[batch_nodes]\n",
    "            \n",
    "            # sampling neighbors of batch nodes\n",
    "            '''\n",
    "            filtered_multi_r_data,list:3,(2,761215),(2,23565),(2,36183)\n",
    "            batch_nodes: 是100个train_indices 索引\n",
    "            n_ids: list:3. tensor(7325,),(722,),(463,)。n_ids是包含所有在L层卷积中遇到的节点的list，且target节点在n_ids前几位\n",
    "            adjs: list:3. edgeindex。adjs是一个list，包含了从第L层到第1层采样的结果\n",
    "                edge_index是采样得到的bipartite子图中source节点到target节点的边。\n",
    "                e_id是edge_index的边在原始大图中的IDs，\n",
    "                size就是bipartite子图的shape。\n",
    "            '''\n",
    "            adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1],batch_size=args.batch_size)\n",
    "            '''0:edge_index(2,1798),size(265,164);1:edge_index()'''\n",
    "            optimizer.zero_grad()  # 将参数置0\n",
    "            # ------------------embedding和y计算loss--------------------\n",
    "            pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds) #根据302维doc_embeddings生成的(100,192),100个192维的node embeddings\n",
    "            \n",
    "            loss_outputs = loss_fn(pred, batch_labels)   # tensor(85706, grad_fn=<MeanBacward0>), 377\n",
    "            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs\n",
    "            losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # step13.1: metrics\n",
    "            for metric in metrics:\n",
    "                metric(pred, batch_labels, loss_outputs)\n",
    "            if batch % args.log_interval == 0:\n",
    "                message = 'Train: [{}/{} ({:.0f}%)] \\tloss: {:.6f}'.format(batch * args.batch_size, train_num_samples,\n",
    "                          100. * batch / ((train_num_samples // args.batch_size) + 1), np.mean(losses))\n",
    "                for metric in metrics:\n",
    "                    message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "                # print(message)\n",
    "                with open(save_path_i + '.log.txt', 'a') as f:\n",
    "                    f.write(message)\n",
    "                losses = []\n",
    "            \n",
    "            # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "            del pred, loss_outputs\n",
    "            gc.collect()\n",
    "            \n",
    "            # step13.2: backward\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_seconds_spent = time.time() - start_batch\n",
    "            seconds_train_batches.append(batch_seconds_spent)\n",
    "            \n",
    "            del loss\n",
    "            gc.collect()\n",
    "        \n",
    "        # step14: print loss\n",
    "        total_loss /= (batch + 1)\n",
    "        message = 'Epoch: {}/{}. Average loss: {:.4f}'.format(epoch, args.n_epochs, total_loss)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            message += '\\t{}: {:.4f}'.format(metric.name(), metric.value())\n",
    "        mins_spent = (time.time() - start_epoch) / 60\n",
    "        message += '\\nThis epoch took {:.2f} mins'.format(mins_spent)\n",
    "        message += '\\n'\n",
    "        print(message)\n",
    "        with open(save_path_i + '/log.txt', 'a') as f:\n",
    "            f.write(message)\n",
    "        mins_train_epochs.append(mins_spent)\n",
    "        \n",
    "        # step15: validation--------------------------------------------------------\n",
    "        print('---------------------validation-------------------------------------')\n",
    "        # inder the representations of all tweets\n",
    "        model.eval()\n",
    "        \n",
    "        # we recommend to forward all nodes and select the validation indices instead\n",
    "        extract_features = torch.FloatTensor([])\n",
    "        num_batches = int(all_num_samples / args.batch_size) + 1\n",
    "        \n",
    "        # all mask are then splited into mini-batch in order\n",
    "        all_mask = torch.arange(0, num_dim, dtype=torch.long)\n",
    "        # 计算所有数据的tweet node embeddings\n",
    "        for batch in range(num_batches):\n",
    "            start_batch = time.time()\n",
    "            \n",
    "            # split batch\n",
    "            i_start = args.batch_size * batch\n",
    "            i_end = min((batch + 1) * args.batch_size, all_num_samples)\n",
    "            batch_nodes = all_mask[i_start:i_end]\n",
    "            \n",
    "            # sampling neighbors of batch nodes\n",
    "            adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=args.batch_size)\n",
    "            \n",
    "            pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "            \n",
    "            extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "            \n",
    "            del pred\n",
    "            gc.collect()\n",
    "        '''\n",
    "        extract_features: tweet node embeddings, (11971, 192)\n",
    "        '''\n",
    "        # evaluate the model: conduct kMeans clustering on the validation and report NMI\n",
    "        validation_nmi = evaluate(extract_features[homo_data.val_mask],\n",
    "                                 homo_data.y,\n",
    "                                 indices=homo_data.val_mask,\n",
    "                                 epoch=epoch,\n",
    "                                 num_isolated_nodes=0,\n",
    "                                 save_path=save_path_i,\n",
    "                                 is_validation=True,\n",
    "                                 cluster_type=args.cluster_type)\n",
    "        all_vali_nmi.append(validation_nmi)\n",
    "        \n",
    "        # step16: early stop\n",
    "        if validation_nmi > best_vali_nmi:\n",
    "            best_vali_nmi = validation_nmi\n",
    "            best_epoch = epoch\n",
    "            wait = 0\n",
    "            # save model\n",
    "            model_path = save_path_i + '/models'\n",
    "            if (epoch == 0) and (not os.path.isdir(model_path)):\n",
    "                os.mkdir(model_path)\n",
    "            p = model_path + '/best.pt'\n",
    "            torch.save(model.state_dict(), p)\n",
    "            print('Best model was at epoch ', str(best_epoch))\n",
    "        else:\n",
    "            wait += 1\n",
    "        if wait >= args.patience:\n",
    "            print('Saved all_mins_spent')\n",
    "            print('Early stopping at epoch ', str(epoch))\n",
    "            print('Best model was at epoch ', str(best_epoch))\n",
    "            break\n",
    "        # end one epoch\n",
    "    \n",
    "    # step17: save all validation nmi\n",
    "    np.save(save_path_i + '/all_vali_nmi.npy', np.asarray(all_vali_nmi))\n",
    "    # save time spent on epochs\n",
    "    np.save(save_path_i + '/mins_train_epochs.npy', np.asarray(mins_train_epochs))\n",
    "    print('Saved mins_train_epochs.')\n",
    "    # save time spent on batches\n",
    "    np.save(save_path_i + '/seconds_train_batches.npy', np.asarray(seconds_train_batches))\n",
    "    print('Saved seconds_train_batches.')\n",
    "    \n",
    "    # step18: load the best model of the current block\n",
    "    best_model_path = save_path_i + '/models/best.pt'\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print('Best model loaded.')\n",
    "    \n",
    "    # del homo_data, multi_r_data\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # test--------------------------------------------------------\n",
    "    print('--------------------test----------------------------')\n",
    "    model.eval()\n",
    "    \n",
    "    # we recommend to forward all nodes and select the validation indices instead\n",
    "    extract_features = torch.FloatTensor([])\n",
    "    num_batches = int(all_num_samples /args.batch_size) + 1\n",
    "    \n",
    "    # all mask are then splited into mini-batch in order\n",
    "    all_mask = torch.arange(0, num_dim, dtype= torch.long)\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        start_batch = time.time()\n",
    "        \n",
    "        # split batch\n",
    "        i_start = args.batch_size * batch\n",
    "        i_end = min((batch +1) * args.batch_size, all_num_samples)\n",
    "        batch_nodes = all_mask[i_start:i_end]\n",
    "        batch_labels = homo_data.y[batch_nodes]\n",
    "        \n",
    "        # sampling neighbors of batch nodes\n",
    "        adjs, n_ids = sampler.sample(filtered_multi_r_data, node_idx=batch_nodes, sizes=[-1,-1], batch_size=args.batch_size)\n",
    "        \n",
    "        pred = model(homo_data.x, adjs, n_ids, device, RL_thresholds)\n",
    "        \n",
    "        extract_features = torch.cat((extract_features, pred.cpu().detach()), dim=0)\n",
    "        del pred\n",
    "        gc.collect()\n",
    "        \n",
    "    save_embeddings(extract_features, save_path_i)\n",
    "    \n",
    "    test_nmi = evaluate(extract_features[homo_data.test_mask],\n",
    "                       homo_data.y,\n",
    "                       indices=homo_data.test_mask,\n",
    "                       epoch=-1,\n",
    "                       num_isolated_nodes=0,\n",
    "                       save_path=save_path_i,\n",
    "                       is_validation=False,\n",
    "                       cluster_type=args.cluster_type)\n",
    "                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f7d87",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## run offline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0c71060e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "Batch Size: 100\n",
      "Intra Agg Mode: False\n",
      "Inter Agg Mode: cat_w_avg\n",
      "Reserve node config? True\n",
      "features loaded\n",
      "labels loaded\n",
      "sparse trans...\n",
      "edge index loaded\n",
      "prepare node configures...\n",
      "D:\\PycharmProjects\\GNN_Event_Detection_models/result/FinEvent result/offline result/offline_embeddings/block_0\n",
      "Pre-Train Stage...\n",
      "\n",
      "------Start initial training /maintaining using block0------\n",
      "\n",
      "----------------------------------training----------------------------\n",
      "Epoch: 0/5. Average loss: 7.5877\tAverage nonzero triplets: 222.0000\n",
      "This epoch took 0.53 mins\n",
      "\n",
      "---------------------validation-------------------------------------\n",
      "\n",
      "Epoch 0\n",
      "\tNumber of validation tweets: 590\n",
      "\tNumber of classes covered by validation tweets: 28\n",
      "\tvalidation NMI: 0.7717897631207566\n",
      "\tvalidationAMi: 0.7260860413255181\n",
      "\tvalidationARI0.5914377388833472\n",
      "\n",
      "Best model was at epoch  0\n",
      "Epoch: 1/5. Average loss: 6.7139\tAverage nonzero triplets: 125.7619\n",
      "This epoch took 0.53 mins\n",
      "\n",
      "---------------------validation-------------------------------------\n",
      "\n",
      "Epoch 1\n",
      "\tNumber of validation tweets: 590\n",
      "\tNumber of classes covered by validation tweets: 28\n",
      "\tvalidation NMI: 0.8096617102596864\n",
      "\tvalidationAMi: 0.7716749710252493\n",
      "\tvalidationARI0.6616855062755435\n",
      "\n",
      "Best model was at epoch  1\n",
      "Epoch: 2/5. Average loss: 5.6501\tAverage nonzero triplets: 85.0476\n",
      "This epoch took 0.53 mins\n",
      "\n",
      "---------------------validation-------------------------------------\n",
      "\n",
      "Epoch 2\n",
      "\tNumber of validation tweets: 590\n",
      "\tNumber of classes covered by validation tweets: 28\n",
      "\tvalidation NMI: 0.8396496920761356\n",
      "\tvalidationAMi: 0.8074276473870966\n",
      "\tvalidationARI0.7221234907074708\n",
      "\n",
      "Best model was at epoch  2\n",
      "Epoch: 3/5. Average loss: 4.9548\tAverage nonzero triplets: 67.8571\n",
      "This epoch took 0.53 mins\n",
      "\n",
      "---------------------validation-------------------------------------\n",
      "\n",
      "Epoch 3\n",
      "\tNumber of validation tweets: 590\n",
      "\tNumber of classes covered by validation tweets: 28\n",
      "\tvalidation NMI: 0.8540710482044999\n",
      "\tvalidationAMi: 0.8250631166270107\n",
      "\tvalidationARI0.7651228315991204\n",
      "\n",
      "Best model was at epoch  3\n",
      "Epoch: 4/5. Average loss: 4.6203\tAverage nonzero triplets: 54.3333\n",
      "This epoch took 0.54 mins\n",
      "\n",
      "---------------------validation-------------------------------------\n",
      "\n",
      "Epoch 4\n",
      "\tNumber of validation tweets: 590\n",
      "\tNumber of classes covered by validation tweets: 28\n",
      "\tvalidation NMI: 0.8506874968881506\n",
      "\tvalidationAMi: 0.8213677488153802\n",
      "\tvalidationARI0.7112408551134916\n",
      "\n",
      "Saved mins_train_epochs.\n",
      "Saved seconds_train_batches.\n",
      "Best model loaded.\n",
      "--------------------test----------------------------\n",
      "extracted features saved.\n",
      "\n",
      "Epoch -1\n",
      "\tNumber of test tweets: 295\n",
      "\tNumber of classes covered by test tweets: 28\n",
      "\ttest NMI: 0.852311988314029\n",
      "\ttestAMi: 0.7964683955589342\n",
      "\ttestARI0.6973350055453018\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [200]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# pre-train stage: train on initial graph\u001b[39;00m\n\u001b[0;32m     39\u001b[0m train_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 40\u001b[0m model, RL_thresholds \u001b[38;5;241m=\u001b[39m offline_FinEvent_model(train_i\u001b[38;5;241m=\u001b[39mtrain_i,\n\u001b[0;32m     41\u001b[0m                                     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m     42\u001b[0m                                     i\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     43\u001b[0m                                     metrics\u001b[38;5;241m=\u001b[39mBCL_metrics,\n\u001b[0;32m     44\u001b[0m                                     embedding_save_path\u001b[38;5;241m=\u001b[39membedding_save_path,\n\u001b[0;32m     45\u001b[0m                                     loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,\n\u001b[0;32m     46\u001b[0m                                     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest finished\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # define args\n",
    "    args = args_register()\n",
    "    \n",
    "    # check CUDA\n",
    "    print('Using CUDA:', torch.cuda.is_available())\n",
    "    \n",
    "    # create working path\n",
    "    if not os.path.exists(args.result_path):\n",
    "        os.mkdir(args.result_path)\n",
    "    embedding_save_path = args.result_path + 'offline_embeddings'\n",
    "    if not os.path.exists(embedding_save_path):\n",
    "        os.mkdir(embedding_save_path)\n",
    "        \n",
    "    # record hyper-parameters\n",
    "    with open(embedding_save_path + '/args.txt', 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2)  # __dict__将模型参数保存成字典形式；indent缩进打印\n",
    "    \n",
    "    print('Batch Size:', args.batch_size)\n",
    "    print('Intra Agg Mode:', args.is_shared)\n",
    "    print('Inter Agg Mode:', args.inter_opt)\n",
    "    print('Reserve node config?', args.is_initial)\n",
    "    \n",
    "    # load number of message in each blocks\n",
    "    # e.g. data_split = [  500  ,   100, ...,  100]\n",
    "    #                    block_0  block_1    block_n\n",
    "    # define loss function，调用forward(embeddings, labels)方法，最终loss返回单个值\n",
    "    # contrastive loss in our paper\n",
    "    if args.use_hardest_neg:\n",
    "        # HardestNegativeTripletSelector返回某标签下ith元素和jth元素，其最大loss对应的其他标签元素索引\n",
    "        loss_fn = OnlineTripletLoss(args.margin, HardestNegativeTripletSelector(args.margin))  # margin used for computing tripletloss\n",
    "    else:\n",
    "        loss_fn = OnlineTripletLoss(args.margin, RandomNegativeTripletSelector(args.margin))  # margin=3；\n",
    "    # define evaluation metrics\n",
    "    BCL_metrics = [AverageNonzeroTripletsMetric()]\n",
    "    # define detection stage\n",
    "    Streaming = FinEvent(args)\n",
    "    # pre-train stage: train on initial graph\n",
    "    train_i = 0\n",
    "    model, RL_thresholds = offline_FinEvent_model(train_i=train_i,\n",
    "                                        args=args,\n",
    "                                        i=0,\n",
    "                                        metrics=BCL_metrics,\n",
    "                                        embedding_save_path=embedding_save_path,\n",
    "                                        loss_fn=loss_fn,\n",
    "                                        model=None)\n",
    "    print('test finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba06243e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "480px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "41a4b0350e1457ef5178032865923a48b9ea5a7e4b0371894b5e037efd84882a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
